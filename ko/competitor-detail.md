---
layout: default
title: W&B Weave — 제품 상세 정보
---

# W&B Weave — 제품 상세 정보
**날짜**: 2026-02-11 | **모델**: google/gemini-3-pro-preview

[← 홈](./) · [상세 비교](./comparison)

### Weave

**개요**: Weave는 모델 학습 라이프사이클(W&B)과 네이티브하게 통합된 유일한 관측성(Observability) 플랫폼으로 자처하며, 프로덕션 트레이스에서 파인튜닝 데이터셋으로 이어지는 원활한 피드백 루프를 지원합니다. 경쟁사들이 'Agent Ops'(배포)나 '프롬프트 엔지니어링'(CMS)에 집중하는 반면, Weave는 자사의 유산을 활용해 '모델 개선' 루프를 장악하고 있으며, 최근에는 차세대 보이스 에이전트를 지원하기 위해 멀티모달(오디오) 평가로 영역을 확장했습니다.

**주요 강점**:
- 멀티모달 관측성: 오디오 모니터링 및 재생을 네이티브로 지원하여, 보이스 에이전트 개발 분야에서 텍스트 전용 경쟁사들보다 앞서 나갑니다.
- 학습 통합: 프로덕션 트레이스를 W&B Model Registry 및 파인튜닝 작업(Serverless LoRAs)에 직접 연결하는 독보적인 능력을 갖추고 있습니다.
- 동적 리더보드: 새롭게 도입된 자동 생성 평가 리더보드는 MLflow처럼 수동 설정 없이도 즉각적인 모델 비교를 제공합니다.
- 데이터 탐색: 표현식(Expression) 기반의 보드 시스템은 Langfuse나 Arize의 경직된 대시보드보다 더 유연한 애드혹(ad-hoc) 분석을 제공합니다.

**개선 필요 사항**:
- 휴먼 어노테이션 워크플로우: LangSmith와 Langfuse에서 표준이 된 체계적인 휴먼 리뷰를 위한 전용 '어노테이션 큐'나 칸반 인터페이스가 부족합니다.
- 에이전트 그래프 시각화: LangGraph 에이전트의 순환 종속성이나 상태 머신을 LangSmith만큼 효과적으로 시각화하지 못합니다.
- SDK 언어 지원: Python/TypeScript로 제한되어 있어, 엔터프라이즈 Java/C#/Go 팀들은 Braintrust나 OpenTelemetry 기반의 경쟁사로 눈을 돌리게 됩니다.
- 개인정보 보호 아키텍처: SaaS UI를 사용하면서 트레이스 데이터는 고객의 클라우드에 완전히 보관할 수 있게 해주는 '데이터 플레인(Data Plane)'(Braintrust 방식)에 상응하는 기능이 부족합니다.

**최근 업데이트**:
- 오디오 모니터: 오디오 지원 LLM 심사위원을 사용하여 텍스트와 함께 오디오 출력을 관찰하고 판단하는 모니터 생성 기능 지원. (2026-02-01)
- 동적 리더보드: 모델/평가 필터에 따라 즉시 채워지는 평가 내 자동 생성 리더보드. (2026-01-29)
- Playground 내 커스텀 LoRA: W&B Artifacts에서 커스텀 파인튜닝된 LoRA 가중치를 Weave Playground로 직접 불러와 테스트하는 기능. (2026-01-16)

| 카테고리 | 등급 | 비고 |
|---|---|---|
| 핵심 관측성 | ●●● | |
| 에이전트 / RAG 관측성 | ●●● | |
| 평가 통합 | ●●● | |
| 모니터링 및 지표 | ●●● | |
| 실험 / 개선 루프 | ●●● | |
| 개발자 경험(DevEx) / 통합 | ●●● | |
| 엔터프라이즈 및 보안 | ●●● | |


---

### LangSmith

**개요**: LangSmith는 LangChain 및 LangGraph 생태계를 위한 네이티브 관측성 및 평가 플랫폼으로, 프로덕션급 에이전트 구축을 위한 기본 인프라로 자리매김하고 있습니다. 복잡한 에이전트 워크플로우 시각화, 휴먼 어노테이션 큐 관리, 개발과 프로덕션 모니터링 간의 긴밀한 피드백 루프 제공에 탁월합니다.

**Weave 대비 강점**:
- 네이티브 LangGraph 통합: 순환 에이전트 워크플로우 및 상태 머신에 대한 우수한 시각화.
- 어노테이션 큐: 휴먼 인 더 루프(human-in-the-loop) 리뷰 및 데이터 라벨링을 위한 성숙한 워크플로우.
- 프롬프트 허브: 통합된 커뮤니티 및 프라이빗 프롬프트 버전 관리 시스템.
- Playground/Replay: UI에서 즉시 트레이스를 수정하고 재실행할 수 있는 능력.

**Weave 대비 약점**:
- 프레임워크 편향성: LangChain에 과도하게 최적화되어 있어, 다른 프레임워크(LlamaIndex, DSPy) 사용자에게는 무겁게 느껴질 수 있습니다.
- 모델 레지스트리: W&B의 핵심 강점인 깊이 있는 아티팩트 및 모델 버전 관리 이력이 부족합니다.
- 학습 통합: Weave는 W&B Training/Sweeps에 원활하게 연결되지만, LangSmith는 학습 컴퓨팅 레이어와 분리되어 있습니다.
- 가격 확장성: 대규모 사용자 앱의 경우 Weave의 유연한 모델에 비해 비용 부담이 커질 수 있습니다.

**최근 업데이트**:
- 트레이스 미리보기 커스텀: 리스트 뷰에서 트레이스 데이터가 미리 보여지는 방식을 사용자가 설정할 수 있는 UI 업데이트. (2026-02-06)
- SDK v0.7.1: LangSmith 관측성 및 평가 플랫폼 연결을 위한 클라이언트 라이브러리 업데이트. (2026-02-10)

| 카테고리 | 판정 | 요약 |
|---|---|---|
| 핵심 관측성 | 대등함 | LangSmith는 LangChain과의 깊은 통합을 활용하여 모든 실행 단계에 대한 세밀한 가시성을 제공하며, 에이전트 워크플로우의 계층적 트레이싱 표준을 제시합니다. |
| 에이전트 / RAG 관측성 | 경쟁사 우위 | 이는 LangSmith의 주요 해자입니다. LangGraph와의 통합을 통해 일반적인 트레이서보다 순환 에이전트 워크플로우 및 복잡한 다단계 추론에 대해 우수한 시각화를 제공합니다. |
| 평가 통합 | 대등함 | LangSmith는 '온라인 평가'(프로덕션 트래픽 샘플링)와 강력한 휴먼 어노테이션 워크플로우에 중점을 둔 성숙한 평가 스위트를 제공합니다. |
| 모니터링 및 지표 | 대등함 | 엔지니어링 지표(지연 시간/오류)와 제품 지표(피드백 점수) 사이의 간극을 효과적으로 메우는 포괄적인 모니터링 대시보드를 제공합니다. |
| 실험 / 개선 루프 | 대등함 | 프롬프트 엔지니어링 및 데이터셋 관리 능력이 뛰어나지만, W&B가 강점을 보이는 실제 모델 학습/파인튜닝 실행 단계에서는 더 넓은 생태계에 의존합니다. |
| 개발자 경험 / 통합 | 대등함 | LangChain 사용자에게는 독보적인 개발자 경험을 제공하며, SDK와 API를 통해 LangChain 이외의 워크플로우에 대한 지원도 늘려가고 있습니다. |
| 엔터프라이즈 및 보안 | 대등함 | 셀프 호스팅과 컴플라이언스에 중점을 두어 내부 GenAI 플랫폼을 구축하는 대기업을 타겟으로 하는 엔터프라이즈 준비가 되어 있습니다. |


---

### Langfuse

**개요**: Langfuse는 관측성, 프롬프트 관리, 평가를 긴밀하게 통합한 포괄적인 오픈 소스 LLM 엔지니어링 플랫폼입니다. 강력한 셀프 호스팅 옵션(MIT 라이선스)과 휴먼 어노테이션 및 프롬프트 배포를 위한 특화된 워크플로우로 차별화하며, SaaS 전용 솔루션의 직접적인 대안으로 자리 잡고 있습니다.

**Weave 대비 강점**:
- 오픈 소스 및 셀프 호스팅 가능: MIT 라이선스를 통해 스타트업/스케일업 기업이 완전한 제어권을 갖고 비용 부담 없이 셀프 호스팅할 수 있습니다.
- 어노테이션 큐: 휴먼 리뷰를 위한 전용 워크플로우가 Weave의 일반적인 보드/테이블 방식보다 더 전문화되어 있습니다.
- 프롬프트 CMS: 배포 라벨 및 'CMS 스타일' 관리 방식은 비기술직 이해관계자들에게 매우 직관적입니다.

**Weave 대비 약점**:
- 생태계 고립: W&B가 제공하는 Model Registry 및 학습 아티팩트와의 깊은 통합이 부족합니다.
- 데이터 탐색: Weave의 Board/Expression 시스템은 Langfuse의 미리 빌드된 대시보드보다 더 유연한 애드혹 데이터 탐색을 제공합니다.
- 학습 루프: 데이터셋을 생성하기는 하지만, W&B 플랫폼만큼 원활하게 실제 파인튜닝 작업을 오케스트레이션하지는 못합니다.

**최근 업데이트**:
- 트레이스 출력 수정: 파인튜닝 데이터셋 구축을 위해 트레이스 뷰에서 직접 개선된 버전의 LLM 출력을 캡처. (2026-01-14)
- 관찰 I/O 인라인 댓글: 트레이스 입력 및 출력 내의 특정 텍스트 선택 영역에 댓글 고정. (2026-01-07)
- 추론/사고 렌더링: 트레이스 내 추론 모델(예: O1, R1)의 '사고(thinking)' 부분에 대한 특화된 UI 렌더링. (2026-02-01)
- 조직 감사 로그 뷰어: 보안 및 컴플라이언스를 위한 조직 수준의 감사 로그를 확인하는 새로운 UI. (2026-02-01)
- 단일 관찰 평가: 전체 트레이스가 아닌 개별 관찰 단위로 평가를 실행하는 기능. (2026-02-01)

| 카테고리 | 판정 | 요약 |
|---|---|---|
| 핵심 관측성 | 대등함 | Langfuse는 오픈 표준(OpenTelemetry)과 비용 추적 정확성에 중점을 두어 Weave에 필적하는 성숙한 핵심 관측성을 제공합니다. |
| 에이전트 / RAG 관측성 | 대등함 | Langfuse는 에이전트 역량을 빠르게 발전시켜 왔으며, 최근 추론 모델을 위한 특화된 렌더링과 에이전트 워크플로우를 위한 그래프 뷰를 추가했습니다. |
| 평가 통합 | 대등함 | 평가는 Langfuse의 핵심 기둥으로, Weave의 역량과 대등하며 어노테이션 큐를 통한 휴먼 인 더 루프 워크플로우에서는 이를 능가합니다. |
| 모니터링 및 지표 | 대등함 | Langfuse는 높은 수준의 커스텀이 가능한 대시보드와 강력한 분석 스위트를 제공하여 Weave의 보드 시스템에 강력한 위협이 됩니다. |
| 실험 / 개선 루프 | Weave 우위 | 프롬프트 엔지니어링 및 데이터셋 큐레이션을 위한 강력한 루프를 갖추고 있습니다. Weave는 실제 모델 학습/파인튜닝 아티팩트와 연결되는 지점에서 우위를 유지합니다. |
| 개발자 경험 / 통합 | 대등함 | Langfuse는 오픈 소스/셀프 호스팅 스택을 선호하는 팀에게 뛰어난 개발자 경험을 제공하며, Weave와 유사하게 광범위한 프레임워크를 지원합니다. |
| 엔터프라이즈 및 보안 | 대등함 | Langfuse의 오픈 소스 특성은 벤더 계약 없이 에어갭(air-gapped) 또는 엄격한 VPC 격리 배포를 원하는 보안 중심 기업에게 독특한 이점을 제공합니다. |


---

### Braintrust

**개요**: Braintrust는 평가 중심의 개발 루프에 탁월한 성숙한 엔터프라이즈 중심 AI 엔지니어링 플랫폼으로, 민감한 트레이스 데이터를 고객의 클라우드에 유지할 수 있는 '데이터 플레인(Data Plane)' 아키텍처로 차별화됩니다. 매우 광범위한 SDK 지원(Java, Go, Ruby, C# 포함)과 깊이 있는 개발자 도구 통합(Cursor, Temporal, LangSmith)을 제공하여 엔지니어링 팀에게 유연하고 프라이버시 중심적인 선택지로 자리 잡고 있습니다. 관측성 및 평가 깊이 면에서 Weave와 경쟁하지만, Weave가 Weights & Biases 생태계를 통해 활용하는 모델 학습 및 파인튜닝 워크플로우와의 네이티브 통합은 부족합니다.

**Weave 대비 강점**:
- 하이브리드 '데이터 플레인' 아키텍처는 완전한 셀프 호스팅의 복잡성 없이 독특한 프라이버시 이점(SaaS UI + 고객 데이터 저장소)을 제공합니다.
- Java, Go, Ruby, C#/.NET을 네이티브로 지원하는 우수한 SDK 범용성으로 Weave가 놓치는 엔터프라이즈 백엔드 팀을 공략합니다.
- 더 성숙한 Playground와 쿼리/뷰 생성을 위한 'Loop' AI 어시스턴트를 갖춘 고급 '프롬프트 우선' 워크플로우.
- 유연한 BTQL(SQL) 쿼리 기능으로 Weave의 현재 필터링보다 더 복잡한 애드혹 분석이 가능합니다.

**Weave 대비 약점**:
- 모델 학습/파인튜닝 워크플로우와의 네이티브 통합이 부족하여 AI 연구(W&B)와 엔지니어링 사이에 사일로(silo)가 발생합니다.
- 시각화 기능은 실용적이지만 W&B Panels/Reports의 깊은 커스텀 가능성과 표현력에는 미치지 못합니다.
- ML 연구 분야에서 W&B의 지배력에 비해 커뮤니티 영향력과 생태계가 작습니다.
- 가격 모델(사용자당/사용량 기반)은 W&B의 엔터프라이즈 번들링 가능성에 비해 대규모 팀에게 덜 매력적일 수 있습니다.

**최근 업데이트**:
- 트레이스 레벨 스코어러: 커스텀 코드 스코어러가 이제 전체 실행 트레이스에 접근하여 다단계 워크플로우와 에이전트 행동을 평가할 수 있습니다. (2026-02)
- LangSmith 통합: 트레이스를 LangSmith와 Braintrust 양쪽으로 라우팅하거나 트래픽을 완전히 마이그레이션할 수 있는 래퍼(wrapper). (2026-02)
- Cursor 통합: Braintrust MCP 서버를 설정하는 확장 프로그램으로, Cursor IDE에서 직접 로그 쿼리 및 실험 가져오기 가능. (2026-02)
- 자동 인스트루멘테이션 (Python/Ruby/Go): Python, Ruby, Go SDK에 코드 수정 없는 트레이싱 지원 추가. (2026-01)
- Temporal 통합: Temporal 워크플로우 및 액티비티의 자동 트레이싱으로 워커 간 분산 트레이스 캡처. (2026-01)

| 카테고리 | 판정 | 요약 |
|---|---|---|
| 핵심 관측성 | 대등함 | Braintrust는 핵심 트레이싱 역량에서 Weave와 대등하지만, 깊이 통합된 프롬프트 플레이그라운드 덕분에 트레이스에서 반복 작업으로의 원활한 전환이 가능하여 'Replay' 워크플로우에서 앞서 나갑니다. |
| 에이전트 / RAG 관측성 | 대등함 | Braintrust는 새로운 Temporal 통합을 통해 복잡하고 지속적인 워크플로우를 시각화하는 등 에이전트 관측성을 공격적으로 강화하고 있으며, 헤비 엔지니어링 유스케이스에서 Weave를 위협하고 있습니다. |
| 평가 통합 | 대등함 | 평가는 Braintrust의 가장 강력한 카테고리입니다. 그들의 'Review' 큐(칸반)와 '온라인 스코어링'은 매우 정교하며 Weave의 어노테이션 워크플로우에 도전하고 있습니다. |
| 모니터링 및 지표 | 대등함 | Braintrust는 BTQL(SQL 호환) 쿼리 덕분에 유연성 면에서 상당한 우위를 점하며 강력한 모니터링을 제공하므로 사용자가 복잡한 커스텀 지표를 쉽게 구성할 수 있습니다. |
| 실험 / 개선 루프 | 대등함 | Weave는 루프의 '모델' 부분(학습/파인튜닝)에서 결정적인 우위를 유지하는 반면, Braintrust는 우수한 플레이그라운드와 버전 관리 도구로 루프의 '프롬프트' 부분을 장악하고 있습니다. |
| 개발자 경험 / 통합 | 경쟁사 우위 | Braintrust는 거의 모든 주요 언어(Go, Java, C#)에 대한 SDK와 혁신적인 IDE 통합(Cursor)을 제공하여 개발자 경험의 폭에서 승리하며, Weave의 Python/JS 중심 전략에 압박을 가하고 있습니다. |
| 엔터프라이즈 및 보안 | 대등함 | Braintrust의 '데이터 플레인' 아키텍처는 강력한 경쟁 무기로, 온프레미스의 데이터 거주성과 SaaS의 편의성을 동시에 제공하며 Weave의 배포 모델에 직접적으로 도전합니다. |


---

### MLflow

**개요**: 업계 표준 오픈 소스 MLOps 플랫폼인 MLflow는 v3.x 시리즈를 통해 GenAI로 공격적으로 전환하며 트레이싱, 평가, 프롬프트 엔지니어링을 위한 포괄적인 스위트를 제공합니다. Databricks의 지원을 받아 기존의 방대한 점유율을 활용하여 LLM 관측성을 전통적인 모델 트래킹의 자연스러운 확장으로 제안하며, 완전한 OpenTelemetry 호환성과 고급 'LLM-as-a-Judge' 워크플로우를 특징으로 합니다.

**Weave 대비 강점**:
- 방대한 설치 기반과 생태계(Databricks) 덕분에 기존 고객은 '무료'로 도입하는 느낌을 받습니다.
- 완전한 OpenTelemetry 호환성은 벤더 중립적인 인스트루멘테이션을 원하는 플랫폼 팀에게 매력적입니다.
- 성숙한 'Model Registry' 및 배포 기능은 단순한 관측성을 넘어 완전한 라이프사이클 솔루션을 제공합니다.
- 'MemAlign' 및 'Judge Builder'(v3.9)와 같은 고급 평가 기능은 Weave의 핵심 가치 제안과 경쟁합니다.

**Weave 대비 약점**:
- UI/UX가 밀집되고 복잡하여 Weave의 보드/플레이그라운드와 같은 가볍고 인터랙티브한 유동성이 부족합니다.
- 오픈 소스 MLflow를 셀프 호스팅할 경우 Weave의 관리형 SaaS에 비해 상당한 인프라 TCO(총 소유 비용)가 발생합니다.
- 복잡한 에이전트 워크플로우(그래프) 시각화가 Weave의 특화된 뷰보다 덜 직관적입니다.
- 휴먼 피드백 워크플로우가 Weave의 어노테이션 도구에 비해 개발자 루프에 덜 통합되어 있습니다.

**최근 업데이트**:
- MLflow Assistant: UI 내에서 문제를 진단하고 수정을 제안하는 Claude Code 기반의 인프로덕트 챗봇. (2026-01-29)
- 에이전트 성능 대시보드: 에이전트 지연 시간, 요청 수, 품질 점수 모니터링을 위한 미리 빌드된 차트. (2026-01-29)
- MemAlign Judge Optimizer: 과거 피드백으로부터 평가 가이드라인을 학습하여 심사위원 정확도를 높이는 알고리즘. (2026-01-29)
- Judge Builder UI: 코드 없이 커스텀 LLM 심사위원 프롬프트를 생성, 테스트 및 검증하는 시각적 인터페이스. (2026-01-29)
- 지속적 온라인 모니터링: 유입되는 프로덕션 트레이스에 대해 LLM 심사위원을 자동으로 실행하여 실시간으로 품질 문제를 감지. (2026-01-29)

| 카테고리 | 판정 | 요약 |
|---|---|---|
| 핵심 관측성 | 대등함 | MLflow는 v3.9를 통해 관측성 격차를 좁혔으며, 플랫폼 엔지니어에게 매력적인 강력한 OTel 네이티브 트레이싱을 제공합니다. 다만 UI는 디버깅 측면에서 Weave보다 여전히 덜 인터랙티브합니다. |
| 에이전트 / RAG 관측성 | Weave 우위 | 에이전트 워크플로우(LangChain, LlamaIndex 자동 로깅)에 대한 강력한 백엔드 지원을 갖추고 있지만, 시각화는 Weave에 비해 '에이전트의 사고 과정'보다는 '스팬(span)의 목록'에 가깝습니다. |
| 평가 통합 | 대등함 | MLflow는 v3.9에서 'MemAlign' 및 노코드 Judge Builder와 같은 고급 기능을 도입하며 Weave의 역량에 필적하는 평가 분야의 직접적인 위협이 되었습니다. |
| 모니터링 및 지표 | 경쟁사 우위 | MLOps에서의 성숙도를 활용하여 비용, 지연 시간, 품질에 대한 포괄적이고 미리 빌드된 뷰를 제공함으로써 프로덕션 모니터링 대시보드에서 우위를 유지합니다. |
| 실험 / 개선 루프 | 대등함 | MLflow의 실험 트래킹은 골드 표준입니다. 그들은 프롬프트 버전 관리 및 지속적 평가 트리거를 통해 이 루프를 GenAI에 성공적으로 적응시키고 있습니다. |
| 개발자 경험 / 통합 | 대등함 | 'MLflow Assistant'(v3.9)를 통한 AI 지원 디버깅 등 Python 엔지니어에게 강력한 개발자 경험을 제공합니다. TypeScript 지원은 개선 중이지만 Python에는 뒤처집니다. |
| 엔터프라이즈 및 보안 | 대등함 | 이미 Databricks를 사용하는 기업에게는 안전한 선택입니다. 셀프 호스팅 오픈 소스는 제어권을 제공하지만 TCO가 높고, 관리형 서비스는 최고 수준의 보안과 거버넌스를 제공합니다. |


---

### Arize Phoenix

**개요**: Arize Phoenix는 OpenInference 표준을 활용하여 LLM 애플리케이션에 대한 깊은 가시성을 제공하는 오픈 소스, 코드 우선 관측성 및 평가 플랫폼입니다. 강력한 셀프 호스팅 옵션(Docker/Kubernetes)을 통해 로컬 개발 워크플로우에 탁월하며, 오프라인 실험과 프로덕션 모니터링 사이의 간극을 원활하게 메워 더 넓은 Arize AI 엔터프라이즈 플랫폼으로 가는 LLM 특화 관문 역할을 합니다.

**Weave 대비 강점**:
- 강력한 '로컬 우선' 전략: 쉬운 Docker/K8s 배포는 SaaS 우선 기본 설정보다 보안에 민감한 팀에게 더 매력적입니다.
- OpenInference 표준: Weave의 독점 SDK 느낌에 비해 '벤더 중립적'인 선택지로 자리매김하고 있습니다.
- Span Replay: 플레이그라운드에서 특정 트레이스 스팬을 재실행하는 전용 기능은 강력한 디버깅 차별화 요소입니다.
- 에이전트 도구 지표: 도구 선택/호출에 대한 새로운 특화 평가기는 즉각적으로 더 깊은 에이전트 인사이트를 제공합니다.

**Weave 대비 약점**:
- 파편화된 경험: 'Phoenix'(오픈 소스/개발용)와 'Arize AX'(엔터프라이즈용) 사이의 분리는 Weave의 통합 플랫폼에 비해 마찰을 일으킬 수 있습니다.
- 학습 통합: Weave가 W&B로부터 물려받은 모델 학습/파인튜닝 파이프라인과의 깊은 네이티브 통합이 부족합니다.
- UI 정교함: 기능적이지만 UI가 실용주의적이며, Weave의 Boards/Reports에 비해 비기술직 이해관계자들에게는 덜 유연하게 느껴집니다.

**최근 업데이트**:
- Claude Opus 4.6 지원: 정확한 비용 추적과 함께 Playground에서 Anthropic의 Claude Opus 4.6 모델 지원 추가. (2026-02-09)
- 도구 선택 및 호출 평가기: 에이전트가 올바른 도구를 선택하고 유효한 파라미터로 호출했는지 평가하는 새로운 특화 평가기. (2026-01-31)
- Phoenix CLI 확장: 터미널에서 직접 프롬프트, 데이터셋, 실험을 관리할 수 있는 포괄적인 CLI 명령. (2026-01-22)
- 스팬 링크를 포함한 트레이스-데이터셋 변환: 계보(lineage) 확인을 위해 소스 스팬과의 양방향 링크를 유지하면서 트레이스에서 데이터셋을 생성하는 기능. (2026-01-21)
- 트레이스와 함께 어노테이션 내보내기: 오프라인 분석을 위해 트레이스와 함께 사람 및 AI 어노테이션을 내보내는 CLI 지원. (2026-01-19)

| 카테고리 | 판정 | 요약 |
|---|---|---|
| 핵심 관측성 | 대등함 | Phoenix는 핵심 트레이싱 역량에서 Weave와 대등하지만 디버깅을 위한 강력한 'Span Replay' 기능으로 차별화합니다. OpenInference에 대한 의존은 광범위한 호환성을 보장하지만 Weave의 간편한 데코레이터보다 더 많은 설정이 필요할 수 있습니다. |
| 에이전트 / RAG 관측성 | Weave 우위 | Phoenix는 2026년 1월 특정 도구 선택 평가기 출시에서 보듯 에이전트 관측성을 공격적으로 타겟팅하고 있습니다. RAG/에이전트 디버깅 공간에서 직접적인 위협이 됩니다. |
| 평가 통합 | 대등함 | Phoenix의 평가 워크플로우는 트레이스, 데이터셋, 실험 간의 원활한 루프를 통해 성숙해졌습니다. 최근 데이터셋과 소스 스팬 간의 양방향 링크 추가로 주요 기능 격차를 해소했습니다. |
| 모니터링 및 지표 | 경쟁사 우위 | Phoenix는 즉시 사용 가능한 강력한 운영 지표를 제공합니다. 최근 '도구 성공' 지표에 집중함으로써 특히 에이전트 신뢰성 모니터링에서 약간의 우위를 점하고 있습니다. |
| 실험 / 개선 루프 | Weave 우위 | Phoenix는 매우 긴밀한 반복 루프를 가지고 있습니다. Weave가 W&B의 학습 유산(Model Registry)으로부터 이득을 얻는 반면, Phoenix는 루프의 프롬프트 엔지니어링 및 데이터셋 큐레이션 측면에서 강력하게 경쟁합니다. |
| 개발자 경험 / 통합 | 대등함 | Phoenix는 2026년 1월 CLI 출시를 통해 터미널 기반 워크플로우를 선호하는 파워 유저를 공략하며 개발자 경험을 크게 개선했습니다. 그들의 'OpenInference' 브랜딩은 벤더 종속을 경계하는 엔지니어들에게 어필합니다. |
| 엔터프라이즈 및 보안 | Weave 우위 | Phoenix는 오픈 소스 특성을 활용하여 '로컬 우선' 및 셀프 호스팅 요구 사항에서 승리합니다. SaaS의 경우 사용자를 Arize AX 엔터프라이즈 플랫폼으로 유도하는데, 이는 기능은 풍부하지만 Phoenix 오픈 소스 경험과는 별개로 존재합니다. |


---