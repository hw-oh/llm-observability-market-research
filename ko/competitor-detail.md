---
layout: default
title: LLM Observability — 제품 상세 정보
---

# LLM Observability — 제품 상세 정보
**날짜**: 2026-02-23 | **모델**: google/gemini-3-pro-preview

### W&B Weave

**개요**: W&B Weave는 Weights & Biases MLOps 플랫폼에 깊이 통합된 개발자 중심의 Observability 및 Eval 툴킷입니다. 에이전트 및 멀티모달 애플리케이션을 위한 프로그래밍 방식의 Tracing에 강점이 있으며, 강력한 엔터프라이즈 인프라를 제공하는 동시에 다이내믹 리더보드 및 Judge 위저드와 같은 로우코드 Eval 도구로 확장하고 있습니다.

**강점**:
- 엔드 투 엔드 MLOps를 위한 W&B 에코시스템(Experiments, Models)과의 깊은 통합
- 멀티모달 Tracing 및 Eval(오디오, 이미지, 비디오) 기본 지원
- 강력한 엔터프라이즈 컴플라이언스(SOC2, HIPAA, GDPR) 및 유연한 배포 옵션
- Model Context Protocol (MCP) Tracing에 대한 퍼스트 클래스 지원
- 새로운 노코드 위저드 옵션을 통한 강력한 프로그래밍 방식의 Eval 기능

**약점**:
- 큐(Queue) 및 검토자 할당과 같은 전용 어노테이션 워크플로우 기능 부족
- 네이티브 프롬프트 최적화 또는 DSPy 통합 부재
- 경쟁사 대비 제한적인 '노코드' 프롬프트 관리(CMS)
- 클러스터 분석을 위한 임베딩 공간 시각화 부재

**최근 업데이트**:
- 오디오 모니터: 텍스트와 함께 오디오 출력을 관찰하고 판단하는 모니터 생성 지원으로 보이스 에이전트 Eval 가능 (2026-02-01)
- 다이내믹 리더보드: 수동 설정 대신 필터링 및 커스터마이징 기능이 포함된 Eval 결과 기반 리더보드 자동 생성 (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Weave는 강력한 멀티모달 지원 및 자동 Instrumentation과 함께 견고한 핵심 Tracing을 제공합니다. OpenTelemetry와 원활하게 통합되지만, 특정 Streaming 메트릭 및 토큰 정확도 세부 사항은 덜 강조됩니다. |
| 에이전트 & RAG 특화 | ●●● | Weave는 강력한 실행 그래프, 도구 호출 렌더링 및 네이티브 MCP 통합을 통해 에이전트 Observability에서 뛰어난 성능을 발휘합니다. RAG 시각화는 전문화된 검색 UI보다는 일반적인 Tracing을 통해 지원됩니다. |
| Eval & 품질 | ●●○ | 새로운 노코드 Judge 위저드, 온라인 Eval 지원 및 다이내믹 리더보드를 특징으로 하는 Eval 기능이 강력합니다. 프롬프트 최적화 및 팀 기반 어노테이션 워크플로우에는 여전히 공백이 있습니다. |
| Guardrails & 안전 | ●●● | Weave는 프로그래밍 가능한 정책 관리를 통해 강력한 PII 및 환각 탐지 등 견고한 Guardrails를 제공합니다. 토픽 및 탈옥(Jailbreak) 방지 기능이 존재하지만 전문 보안 도구보다는 덜 특화되어 있습니다. |
| Analytics & Dashboard | ●●○ | W&B의 Dashboard 강점을 활용하여 비용, 토큰 사용량 및 커스텀 메트릭에 대한 강력한 Analytics를 제공합니다. 지연 시간 히트맵 및 임베딩 클러스터와 같은 고급 시각화는 현재 제공되지 않습니다. |
| 개발 라이프사이클 | ●●○ | Weave는 W&B 플랫폼 통합을 통해 강력한 실험 추적 및 Playground를 제공하며 개발 라이프사이클을 잘 지원합니다. 프롬프트 관리는 기능적이지만 개발자 중심 워크플로우에 치우쳐 있습니다. |
| 통합 & DX | ●●○ | Python/TypeScript 에코시스템 및 인기 있는 LLM 프레임워크에 대한 통합이 강력합니다. Proxy 모드와 Go SDK의 부재로 인해 일부 인프라 중심 환경에서의 확장이 제한됩니다. |
| 엔터프라이즈 & 인프라 | ●●● | 엔터프라이즈 인프라는 W&B의 성숙한 컴플라이언스, 배포 및 보안 기능을 상속받은 주요 강점입니다. 엄격한 데이터 주권 및 액세스 제어가 필요한 규제 산업에 적합합니다. |


---

### LangSmith

**개요**: LangSmith는 LangChain 에코시스템 내에서 심층적인 Observability, Eval 및 프롬프트 엔지니어링을 전문으로 하는 LLM 애플리케이션용 종합 DevOps 플랫폼입니다. 계층적 Trace를 통해 복잡한 에이전트 워크플로우를 시각화하는 데 탁월하며 데이터셋 관리, 회귀 테스트 및 휴먼 리뷰를 위한 강력한 도구를 제공합니다. 개발 및 모니터링에는 강력하지만, 현재 일부 경쟁사에서 볼 수 있는 네이티브 런타임 Guardrails 및 Proxy 기반 보안 기능은 부족합니다.

**강점**:
- 복잡한 에이전트 워크플로우 및 RAG Tracing을 위한 LangChain과의 깊은 통합
- LLM-as-a-judge 및 어노테이션 큐를 포함한 포괄적인 Eval 스위트
- 하이브리드 및 자체 호스팅 VPC를 포함한 강력한 엔터프라이즈 배포 옵션
- Run Trees를 통한 중첩된 체인 및 도구 호출의 계층적 시각화

**약점**:
- Proxy 기반 경쟁사 대비 네이티브 런타임 Guardrails(PII, 탈옥, 토픽) 부족
- 현재 멀티모달 Tracing 지원(이미지/오디오) 없음
- 수동 Instrumentation 없이는 LangChain 이외의 프레임워크에 대한 네이티브 지원 제한
- RAG 분석을 위한 임베딩 공간 시각화 부재

**최근 업데이트**:
- Trace 미리보기 커스터마이징: LangSmith UI에서 Trace 미리보기를 커스터마이징하는 기능 추가 (2026-02-06)
- Python 비동기용 샌드박스 엔드포인트: Python 비동기 실행을 위한 샌드박스 엔드포인트 지원 추가 (2026-02-05)
- 비 OTEL Google ADK 래퍼: Google ADK를 위한 비 OpenTelemetry 래퍼 추가 (2026-02-02)
- Google Gen AI 래퍼 내보내기: SDK에서 Google Gen AI 래퍼를 내보냄 (2026-01-31)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | LangSmith는 강력한 엔드 투 엔드 가시성, 계층적 Run Trees 및 자동 Instrumentation을 통해 핵심 Tracing에서 뛰어난 성능을 보입니다. OpenTelemetry와 원활하게 통합되며 강력한 메타데이터 필터링을 제공하지만 멀티모달 Tracing은 아직 지원되지 않습니다. |
| 에이전트 & RAG 특화 | ●●● | 이 플랫폼은 검색, 도구 호출 및 에이전트 그래프에 대한 상세한 시각화를 제공하여 에이전트 및 RAG 애플리케이션에 대한 강력한 Observability를 제공합니다. 세션 재생 및 실패 강조 표시를 통해 복잡한 워크플로우를 효과적으로 처리합니다. |
| Eval & 품질 | ●●● | LangSmith는 LLM-as-a-Judge, 데이터셋 및 회귀 테스트를 위한 강력한 기능을 갖춘 포괄적인 Eval 스위트를 제공합니다. 휴먼 리뷰 워크플로우는 견고하지만 프롬프트 최적화에는 심층적인 DSPy 통합이 부족합니다. |
| Guardrails & 안전 | ○○○ | Guardrails 및 안전 기능은 거의 없으며, 플랫폼은 능동적 보호보다는 Observability에 집중합니다. 사용자는 PII 마스킹 및 안전 점검을 위해 외부 통합에 의존해야 합니다. |
| Analytics & Dashboard | ●●● | 강력한 Analytics는 토큰, 지연 시간 및 오류를 추적하기 위한 사전 구축된 커스텀 Dashboard를 제공합니다. 프로덕션 모니터링은 강력하지만 고급 임베딩 공간 시각화가 부족합니다. |
| 개발 라이프사이클 | ●●● | 이 플랫폼은 강력한 프롬프트 관리, 실험 및 버전 제어 도구를 통해 개발 라이프사이클에서 탁월한 성능을 발휘합니다. Fine-tuning 지원은 데이터 내보내기를 통해 제공되지만 다른 기능만큼 통합되어 있지는 않습니다. |
| 통합 & DX | ●●○ | LangSmith는 특히 LangChain 사용자에게 강력한 SDK 지원 및 API 액세스를 제공합니다. 그러나 Proxy 기반 Tracing 모드가 부족하고 LangChain 이외의 프레임워크에 대한 네이티브 지원이 제한적입니다. |
| 엔터프라이즈 & 인프라 | ●●● | 엔터프라이즈 인프라는 강점이며, 자체 호스팅 VPC 옵션과 강력한 컴플라이언스 지원을 포함한 유연한 배포 모델을 갖추고 있습니다. 데이터 내보내기 및 감사 로그는 견고하지만 플랫폼이 오픈 소스는 아닙니다. |


---

### Langfuse

**개요**: Langfuse는 OpenTelemetry 기반 Tracing을 강력한 Eval 및 프롬프트 관리 도구와 결합한 선도적인 오픈 소스 LLM 엔지니어링 플랫폼입니다. 복잡한 RAG 및 에이전트 워크플로우에 대한 세밀한 가시성을 제공하는 데 탁월하며, 멀티테넌트 SaaS부터 완전 자체 호스팅 엔터프라이즈 환경까지 유연한 배포 옵션을 제공합니다.

**강점**:
- 완전 오픈 소스 및 자체 호스팅 가능으로 완벽한 데이터 주권 제공
- Eval 워크플로우(LLM-as-a-judge)를 Tracing 데이터와 직접 강력하게 통합
- 비기술적 협업을 위한 견고한 프롬프트 관리 및 버전 관리 시스템(CMS)
- 속성을 포함한 포괄적인 비용 및 토큰 사용량 Analytics
- 표준 준수 Observability를 보장하는 네이티브 OpenTelemetry 지원

**약점**:
- 네이티브 멀티모달 Tracing 기능 부족
- 중앙 집중식 트래픽 관리를 위한 내장 AI 게이트웨이 또는 Proxy 모드 없음
- 보안 중심 경쟁사 대비 제한된 자동 Guardrails(PII, 탈옥)
- 공식 Go SDK 부재로 Go 기반 백엔드 서비스 지원 제한
- Fine-tuning 파이프라인 통합 현재 누락됨

**최근 업데이트**:
- Single Span Evals (오픈 베타): 전체 Trace가 아닌 개별 Span에 대해 Eval을 실행할 수 있음 (2026-02-23)
- Observation 기반 LLM-as-a-Judge: 특정 Observation에 대해 직접 LLM-as-a-judge 평가기를 실행하는 기능 지원 (2026-02-23)
- 추론/생각 Trace 렌더링: 모델 출력의 '생각(thinking)' 및 추론 부분(예: 추론 모델용)을 렌더링하기 위한 UI 지원 (2026-02-06)
- 조직 감사 로그 뷰어: 조직 수준의 감사 로그를 보기 위한 새로운 UI (2026-02-06)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Langfuse는 계층적 시각화, Streaming 및 OpenTelemetry 표준을 강력하게 지원하는 견고한 핵심 Tracing을 제공합니다. 텍스트 기반 LLM Observability에는 탁월하지만 현재 멀티모달 Tracing에 대한 명시적 지원은 부족합니다. |
| 에이전트 & RAG 특화 | ●●○ | 이 플랫폼은 상세한 검색 Tracing 및 세션 재생을 통해 RAG Observability에서 뛰어난 성능을 보입니다. 최근 업데이트로 추론 모델에 대한 지원이 개선되었지만 에이전트 워크플로우를 위한 시각적 실행 그래프는 부족합니다. |
| Eval & 품질 | ●●○ | Langfuse는 LLM-as-a-Judge 및 회귀 테스트를 중심으로 한 포괄적인 Eval 스위트를 제공합니다. Single-span Eval 및 Observation 수준의 판정과 같은 최근 기능은 세분성을 크게 강화했습니다. |
| Guardrails & 안전 | ●●○ | 안전 기능은 주로 Observability 중심이며 팀이 Guardrail 메트릭을 추적하고 Scoring할 수 있도록 합니다. 외부 보안 라이브러리와 잘 통합되지만 네이티브 자동 적용 또는 마스킹 기능은 부족합니다. |
| Analytics & Dashboard | ●●○ | 유연한 커스텀 Dashboard를 통해 비용 및 토큰 사용량에 대한 강력한 Analytics를 제공합니다. 필수 메트릭은 잘 다루지만 임베딩 공간 클러스터링이나 상세한 지연 시간 히트맵과 같은 고급 시각화는 부족합니다. |
| 개발 라이프사이클 | ●●● | Langfuse는 CMS와 유사한 프롬프트 관리자, Playground 및 실험 추적을 통해 견고한 개발 루프를 제공합니다. 프롬프트 엔지니어링과 프로덕션 배포 사이의 간극을 효과적으로 메웁니다. |
| 통합 & DX | ●●○ | 우수한 프레임워크 지원과 함께 Python 및 JavaScript 에코시스템에 대한 통합이 강력합니다. 네이티브 게이트웨이 및 공식 Go SDK의 부재는 일부 인프라 설정에서 주목할 만한 제한 사항입니다. |
| 엔터프라이즈 & 인프라 | ●●● | Langfuse는 확장성이 뛰어나고 엔터프라이즈에 적합하며 자체 호스팅을 포함한 유연한 배포 모델을 제공합니다. RBAC 및 감사 로그와 같은 고급 거버넌스 기능은 제공되지만 엔터프라이즈 라이선스로 제한됩니다. |


---

### Braintrust

**개요**: Braintrust는 Eval 중심의 개발 라이프사이클을 강조하는 개발자 중심 AI Observability 및 Eval 플랫폼입니다. 견고한 핵심 Tracing 및 실험 추적을 엔터프라이즈급 보안 및 배포 옵션과 결합하여 프로덕션 LLM 애플리케이션을 구축하는 엔지니어링 팀에 매우 적합합니다. 오프라인 Eval 및 프롬프트 관리에는 탁월하지만, 현재 실시간 Proxy 기반 Guardrails 및 광범위한 사전 구축 에이전트 시각화 도구는 부족합니다.

**강점**:
- 커스텀 Scorer 및 회귀 테스트를 포함한 강력한 Eval 프레임워크
- 견고한 프롬프트 관리 및 Playground 통합
- 하이브리드 배포 및 컴플라이언스(HIPAA/SOC2)를 갖춘 엔터프라이즈 지원
- Python, TypeScript 및 Go를 위한 고품질 SDK

**약점**:
- Guardrails를 위한 실시간 Proxy/게이트웨이 부족
- 휴먼 리뷰 워크플로우를 위한 전용 어노테이션 큐 UI 없음
- 에이전트 그래프 및 임베딩을 위한 기본 시각화 제한적
- 내장된 Fine-tuning 파이프라인 통합 없음

**최근 업데이트**:
- 실험 태그: SDK를 통해 실험 생성 시 태그를 전달할 수 있는 기능 (2026-02-23)
- 스레드 검색: Python SDK에서 스레드 세부 정보를 가져오는 기능 추가 (2026-02-12)
- OpenAI 에이전트 통합: OpenAI 에이전트 통합을 위해 모든 Span 유형을 처리하도록 Python SDK 업데이트 (2026-02-05)
- 리뷰 Span 유형: 어노테이션 워크플로우를 위해 SDK에 특정 'review' Span 유형 추가 (2026-02-05)
- 분류 필드: Python SDK에 분류(classifications) 필드 추가 (2026-01-31)
- Eval 캐시 제어: Eval 중 캐싱을 끌 수 있는 옵션 추가 (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Braintrust는 멀티모달 데이터 및 계층적 Span을 강력하게 지원하여 Tracing을 위한 견고한 토대를 제공합니다. 자동 Instrumentation 및 메타데이터 기능은 강력하지만 Streaming 및 OTEL 지원은 네이티브 표준보다는 통합 기반입니다. |
| 에이전트 & RAG 특화 | ●●○ | 이 플랫폼은 함수 호출 및 검색 데이터의 명확한 렌더링을 제공하여 RAG 및 도구 사용을 잘 처리합니다. 그러나 에이전트 실행 그래프와 같은 고급 시각화가 부족하며 대신 Trace 기반 디버깅 및 실패 분석에 집중합니다. |
| Eval & 품질 | ●●○ | Braintrust는 커스텀 Scorer, 회귀 테스트 및 데이터셋 관리를 위한 강력한 도구를 제공하는 Eval 분야의 리더입니다. 노코드 위저드보다 코드 기반 유연성을 우선시하여 엔지니어링 주도의 품질 보증에 이상적입니다. |
| Guardrails & 안전 | ●●○ | 안전 기능은 실시간 차단보다는 주로 Eval 프레임워크를 통해 구현됩니다. 플랫폼은 즉시 사용 가능한 활성 Guardrails를 제공하기보다는 컴플라이언스(HIPAA/GDPR) 및 안전 점검의 반복적 개선에 집중합니다. |
| Analytics & Dashboard | ●●○ | Analytics 스위트는 토큰 사용량, 오류 및 성능에 대한 필수 가시성을 제공합니다. 커스텀 Dashboard를 효과적으로 지원하지만 다른 도구에서 볼 수 있는 지연 시간 히트맵 및 임베딩 클러스터와 같은 일부 고급 시각화는 누락되었습니다. |
| 개발 라이프사이클 | ●●○ | Braintrust는 특히 프롬프트 엔지니어링 및 실험을 위한 개발 라이프사이클에서 빛을 발합니다. Playground와 프롬프트 CMS가 긴밀하게 통합되어 프로토타이핑에서 프로덕션으로의 원활한 전환이 가능하지만 Fine-tuning 지원은 없습니다. |
| 통합 & DX | ●●○ | 강력한 SDK 및 API 액세스를 통해 개발자 경험을 우선시합니다. 통합은 Proxy 구성보다는 코드 수준 구현(SDK)에 크게 의존하며 프레임워크 지원은 LangChain 및 Vercel AI SDK에 집중되어 있습니다. |
| 엔터프라이즈 & 인프라 | ●●○ | Braintrust는 강력한 보안, 컴플라이언스 및 유연한 배포 모델을 제공하여 엔터프라이즈 요구 사항에 맞게 구축되었습니다. 하이브리드 아키텍처를 통해 엄격한 데이터 주권 요구 사항을 수용하지만 오픈 소스 구성 요소 및 직접적인 데이터 웨어하우스 내보내기 기능은 부족합니다. |


---

### MLflow

**개요**: 강력한 Tracing, Eval 및 실험 추적을 통해 GenAI Observability로 크게 확장한 지배적인 오픈 소스 머신러닝 라이프사이클 플랫폼입니다. 코드 중심 워크플로우, 자동 Instrumentation 및 주요 프레임워크와의 통합이 뛰어나지만, 틈새 경쟁사에 비해 전문화된 에이전트 시각화 및 네이티브 안전 Guardrails가 현재 부족합니다.

**강점**:
- 표준을 제시하는 실험 추적 기능을 갖춘 거대한 오픈 소스 에코시스템
- 주요 GenAI 프레임워크를 위한 한 줄 자동 Instrumentation
- 'LLM-as-a-Judge' 및 회귀 테스트를 포함한 강력한 Eval 프레임워크
- 자체 호스팅 및 관리형 클라우드 환경 전반의 유연한 배포 옵션

**약점**:
- 제한된 네이티브 Guardrails 및 안전 기능
- 실행 그래프와 같은 고급 에이전트 시각화 부족
- 비기술적 사용자를 위한 내장 노코드 Playground 없음
- 네이티브 데이터 웨어하우스 내보내기 기능 부재

**최근 업데이트**:
- 조직 지원: 실험 및 리소스를 논리적으로 격리하기 위한 멀티 워크스페이스 환경 지원 (2026-02-20)
- MLflow Assistant: UI에서 직접 문제를 진단하고 해결하는 데 도움이 되는 Claude Code 기반의 인프로덕트 챗봇 (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●○ | MLflow는 강력한 자동 Instrumentation 및 메타데이터 처리를 통해 견고하고 표준을 준수하는 Tracing 기반을 제공합니다. OpenTelemetry 에코시스템과 호환성이 높지만 현재 Streaming 및 멀티모달 데이터에 대한 특정 기능은 부족합니다. |
| 에이전트 & RAG 특화 | ○○○ | 에이전트 및 RAG 지원은 기능적이지만 기본적이며 전문화된 에이전트 시각화보다는 일반적인 Tracing 뷰에 크게 의존합니다. LlamaIndex와 같은 라이브러리와 잘 통합되지만 실행 그래프 및 세션 재생과 같은 고급 디버깅 도구는 부족합니다. |
| Eval & 품질 | ●●○ | MLflow는 강력한 데이터셋 관리 및 회귀 테스트 기능을 갖춘 강력한 코드 우선 Eval 프레임워크를 제공합니다. 엔지니어링 팀에는 적합하지만 비기술적 이해관계자를 위한 위저드 및 어노테이션 큐와 같은 로우코드 도구는 부족합니다. |
| Guardrails & 안전 | ○○○ | 안전 기능은 최소한이며 대부분 수동으로 커스텀 Hook이나 외부 통합에 의존합니다. MLflow는 네이티브하고 포괄적인 Guardrails 레이어를 제공하기보다는 Observability에 집중합니다. |
| Analytics & Dashboard | ●●○ | Analytics는 특히 토큰, 오류 및 커스텀 정의와 같은 운영 메트릭에서 강점입니다. 에이전트 Dashboard는 이러한 인사이트를 중앙 집중화하지만 비용 속성 및 임베딩과 같은 고급 시각화는 제한적입니다. |
| 개발 라이프사이클 | ●●○ | MLflow는 실험 추적 및 버전 제어의 골드 표준으로 남아 있습니다. 최근 업데이트로 프롬프트 관리 기능이 도입되어 GenAI 워크플로우의 간극을 메웠지만 여전히 전용 대화형 Playground는 부족합니다. |
| 통합 & DX | ●●○ | 광범위한 프레임워크 지원 및 자동 Instrumentation을 통해 Python 및 JS 사용자에게 우수한 개발자 경험을 제공합니다. 통합은 주로 SDK 기반이며 Proxy 기반 모드나 사전 구축된 CI/CD 워크플로우는 부족합니다. |
| 엔터프라이즈 & 인프라 | ●●○ | MLflow는 다양한 배포 모델을 지원하여 엔터프라이즈 인프라에 매우 적합합니다. 오픈 소스 코어는 강력하지만 RBAC 및 감사 로그와 같은 고급 거버넌스 기능은 일반적으로 관리형 서비스나 클라우드 제공업체로 위임됩니다. |


---

### Arize Phoenix

**개요**: Arize Phoenix는 LLM 애플리케이션 엔지니어링을 위해 특별히 설계된 오픈 소스, OpenTelemetry 네이티브 Observability 및 Eval 플랫폼입니다. RAG 검색 및 도구 실행을 포함한 복잡한 에이전트 워크플로우 Tracing에 탁월하며 강력한 코드 우선 Eval 기능을 제공하지만 상용 경쟁사에서 볼 수 있는 일부 비기술적 협업 기능은 부족합니다.

**강점**:
- 벤더 중립적 Tracing 및 쉬운 통합을 보장하는 네이티브 OpenTelemetry (OTLP) 지원
- 검색 청크 및 실행 그래프를 포함한 에이전트 RAG를 위한 고급 시각화
- 유연한 자체 호스팅 배포 옵션을 갖춘 강력한 오픈 소스 기반
- 커스텀 Scorer를 지원하는 포괄적인 코드 우선 Eval 라이브러리

**약점**:
- 어노테이션 큐 및 노코드 위저드와 같은 비기술적 협업 기능 부족
- 코어 제품에 엔터프라이즈 거버넌스 기능(RBAC, SSO, 감사 로그) 누락
- 내장된 비용 속성 또는 재무 Analytics 없음
- 전용 Go SDK 부재

**최근 업데이트**:
- 간결성 분류 평가기: 응답의 간결성을 측정하기 위한 새로운 평가기 추가 (2026-02-20)
- AWS Bedrock 교차 리전 지원: AWS Bedrock 교차 리전 추론 모델 접두사에 대한 기본 설정 지원 추가 (2026-02-19)
- Eval 프롬프트 자동 완성: LLM Eval 프롬프트 편집기에 자동 완성 기능 추가 (2026-02-13)
- 도구 응답 평가기 템플릿: 도구 응답 처리를 위해 특별히 설계된 새로운 평가기 템플릿 도입 (2026-02-13)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Phoenix는 강력한 OpenTelemetry 기반을 갖춘 핵심 Tracing에서 탁월하며 상세한 중첩 뷰 및 자동 Instrumentation을 제공합니다. 엔지니어링 디버깅에 매우 효과적이지만 Streaming 및 멀티모달 시각화는 덜 강조됩니다. |
| 에이전트 & RAG 특화 | ●●● | 이 플랫폼은 검색 청크, 도구 호출 및 실행 그래프에 대한 전문화된 시각화를 제공하여 에이전트 및 RAG Observability에 특히 강력합니다. 에이전트 추론 및 세션 흐름에 대한 심층적인 가시성을 제공합니다. |
| Eval & 품질 | ●●● | Phoenix는 코드 기반 Scorer, 회귀 테스트 및 온라인 모니터링을 중심으로 강력한 Eval 도구를 제공합니다. 어노테이션 큐 및 노코드 위저드가 부족하여 비기술적 팀에는 덜 적합합니다. |
| Guardrails & 안전 | ●●○ | 안전 기능은 임베딩 기반 탈옥 탐지 및 코드 정의 정책에 집중합니다. PII 마스킹 및 환각 탐지는 네이티브 실시간 Guardrails보다는 통합 또는 사후 Eval에 의존합니다. |
| Analytics & Dashboard | ●●○ | Analytics는 토큰 사용량 및 커스텀 메트릭에는 강력하지만 재무 인사이트(비용 속성) 및 고급 지연 시간 시각화가 부족합니다. 최근 업데이트에서 핵심 메트릭에 집중하기 위해 임베딩 공간 시각화가 제거되었습니다. |
| 개발 라이프사이클 | ●●○ | 강력한 실험 추적 기능이 반복적인 개발을 지원합니다. 그러나 프롬프트 관리 및 Playground 기능은 더 개발자 중심적이며 일부 경쟁사의 세련된 CMS 경험이 부족합니다. |
| 통합 & DX | ●●● | 강력한 OTLP 지원 및 프레임워크 자동 Instrumentation을 통한 통합이 돋보입니다. Python 및 JS는 잘 지원되지만 Go는 누락되었습니다. API 우선 접근 방식은 커스텀 파이프라인 통합을 용이하게 합니다. |
| 엔터프라이즈 & 인프라 | ●●○ | Phoenix는 인프라 유연성과 오픈 소스의 자유로움이 뛰어나 자체 호스팅 요구 사항에 이상적입니다. 그러나 RBAC, SSO 및 감사 로그와 같은 표준 엔터프라이즈 거버넌스 기능은 코어 제품에 거의 없습니다. |


---