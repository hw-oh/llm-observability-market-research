---
layout: default
title: LLM Observability — 제품 상세 정보
---

# LLM Observability — 제품 상세 정보
**날짜**: 2026-02-25 | **모델**: google/gemini-3-pro-preview

### W&B Weave

**개요**: W&B Weave는 Weights & Biases의 강력한 기반을 활용하여 경량 Tracing 도구에서 포괄적인 LLM ops 플랫폼으로 빠르게 진화했습니다. 2026년 초의 최신 업데이트를 통해 오디오 모니터, 동적 리더보드, 엔터프라이즈급 Trace 분석 등을 도입하며 기능 격차를 크게 줄였습니다. 강력한 멀티모달 지원, W&B의 트레이닝/Fine-tuning 생태계와의 긴밀한 통합, 그리고 강화된 Guardrails(PII, 환각)를 갖추어 실험부터 프로덕션까지 엔드투엔드 가시성이 필요한 개발자들에게 최상위 선택지로 자리매김하고 있습니다. 독립형 프록시 게이트웨이나 고급 임베딩 시각화 기능은 부족하지만, 개발자 중심의 SDK와 Eval 및 모니터링을 위한 매끄러운 워크플로우가 강점입니다.

**강점**:
- W&B Experiments와의 매끄러운 통합으로 트레이닝에서 프로덕션으로의 원활한 전환 지원.
- 새로운 오디오 모니터링 기능을 포함한 네이티브 멀티모달 지원.
- 강력한 엔터프라이즈 컴플라이언스(SOC2/HIPAA) 및 유연한 배포 방식(SaaS/On-Prem).
- 코드 기반 및 LLM 기반 Scoring을 모두 지원하는 유연한 Eval 프레임워크.
- 주요 데이터 웨어하우스(Snowflake, BigQuery)로의 강력한 데이터 내보내기 기능.

**약점**:
- SDK 코드 삽입 없이 모델 라우팅을 수행할 수 있는 독립형 API 프록시/게이트웨이 부재.
- 수동적인 어노테이션 워크플로우 및 대규모 팀을 위한 고급 큐 관리 기능 부족.
- 시맨틱 클러스터링을 위한 네이티브 임베딩 공간 시각화 부재.
- 자동화된 프롬프트 최적화 또는 후보 생성 미지원.

**최신 업데이트**:
- Trace 분석 개요: 요청 수, Latency 백분위수, 토큰 사용량 및 비용을 보여주는 프로젝트 개요 기능. (2026-02-23)
- Trace 비교 요약: 집계된 도구 사용량, Scoring 결과 및 비용을 한눈에 비교할 수 있는 플랫 뷰(Flattened views). (2026-02-23)
- 오디오 모니터: LLM Judge를 사용하여 오디오 입력을 관찰하고 판별하는 모니터 생성 지원. (2026-02-01)
- 동적 리더보드: Eval 결과로부터 자동 생성되는 리더보드로, 영구적인 커스터마이징 및 CSV 내보내기 지원. (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Weave는 강력한 멀티모달 기능과 OTel 호환성을 갖춘 견고한 Tracing 코어를 제공하며, 네이티브 오디오 지원으로 차별화됩니다. |
| 에이전트 및 RAG 특화 | ●●● | 복잡한 에이전트 및 RAG 파이프라인 디버깅에 강력하며, 최근 루프 시각화 및 MPC 통합 기능이 개선되었습니다. |
| Eval 및 품질 | ●●● | 코드 우선 방식과 GUI 도구가 혼합된 포괄적인 Eval 제품군을 제공하지만, 자동화된 프롬프트 최적화 기능은 부족합니다. |
| Guardrails 및 안전 | ●●● | Weave는 PII 마스킹과 프로그래밍 방식으로 관리 가능한 광범위한 Guardrails를 통해 견고한 안전망을 제공합니다. |
| 분석 및 Dashboard | ●●● | 분석 기능은 주요 강점으로, 비용과 성능에 대한 깊은 가시성을 제공하지만 시맨틱 임베딩 프로젝션 기능은 빠져 있습니다. |
| 개발 라이프사이클 | ●●● | 프로덕션 모니터링을 트레이닝 및 Fine-tuning과 연결하여 광범위한 ML 개발 라이프사이클에 타의 추종을 불허하는 통합을 제공합니다. |
| 통합 및 DX | ●●● | 강력한 SDK와 프레임워크 지원으로 우수한 개발자 경험을 제공하지만, 프록시 모드 부재로 인해 일부 아키텍처 선택이 제한될 수 있습니다. |
| 엔터프라이즈 및 인프라 | ●●● | W&B 표준에 부합하는 최상위 컴플라이언스, 보안 및 유연한 배포 모델을 갖춘 엔터프라이즈급 솔루션입니다. |


---

### LangSmith

**개요**: LangSmith는 LangChain 생태계와 깊이 통합된 전문 Observability 및 Eval 플랫폼으로서의 역할을 유지하면서, OpenTelemetry를 통해 일반적인 LLM 엔지니어링 지원을 확장하고 있습니다. 이 플랫폼은 복잡한 에이전트 워크플로우 시각화에 탁월하며, 중첩된 Span, 도구 사용 및 Retrieval 단계에 대한 세밀한 Tracing을 제공합니다. 최근의 개발 동력은 에이전트 실행을 위한 샌드박스 환경 강화와 커스터마이징 가능한 Trace 뷰를 통한 개발자 편의성 개선에 집중되었습니다. 어노테이션 큐 및 Pairwise 비교를 포함한 강력한 'Human-in-the-loop' Eval 기능으로 차별화되며, 엔터프라이즈를 위한 셀프 호스팅 배포 옵션도 제공합니다.

**강점**:
- 에이전트 궤적 시각화를 위한 LangChain 및 LangGraph와의 깊은 네이티브 통합.
- 어노테이션 큐 및 충돌 관리를 포함한 강력한 'Human-in-the-loop' 워크플로우.
- SaaS, 하이브리드, 셀프 호스팅 VPC를 포함한 유연한 배포 모델.
- 복잡하고 중첩된 에이전트 루프를 위해 특별히 설계된 포괄적인 Tracing.
- 버전 관리 및 테스트 플레이그라운드와 통합된 강력한 프롬프트 관리.

**약점**:
- 오픈 소스 커뮤니티 에디션이 없는 독점 플랫폼.
- 네이티브 게이트웨이/프록시 서비스 부재로 인해 SDK 또는 OTEL 의존성 필요.
- 네이티브 임베딩 공간 시각화 도구(예: UMAP/t-SNE) 부재.
- 외부 웨어하우스(Snowflake/BigQuery)로의 데이터 동기화를 위한 자동화된 통합 기능 제한.
- 프록시 기반 솔루션에 비해 LangChain 이외의 프레임워크 사용 시 별도 SDK/Wrapper에 대한 의존성.

**최신 업데이트**:
- 샌드박스 예외 유형 및 플러밍: 에이전트 샌드박스의 오류 처리를 개선하기 위해 샌드박스 예외 유형과 클라이언트 플러밍 추가. (2026-02-21)
- Google Gen AI Wrapper 내보내기: Google Gen AI Wrapper 및 비 OTEL Wrapper 지원을 위한 내보내기 기능 추가. (2026-02-02)
- Trace 미리보기 커스터마이징: LangSmith UI 내에서 Trace 미리보기가 표시되는 방식을 커스터마이징하는 기능. (2026-02-06)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | 체인 실행에 대한 깊은 가시성과 완전한 OTEL 지원을 특징으로 하는 LLM 애플리케이션용 최상급 Tracing 기능을 제공합니다. |
| 에이전트 및 RAG 특화 | ●●● | 에이전트 및 RAG 디버깅에 고도로 특화되어 있으며, Retrieval 컨텍스트와 에이전트 추론 궤적을 위한 시각화 도구를 제공합니다. |
| Eval 및 품질 | ●●● | 자동화된 LLM-as-a-judge Scoring, 수동 어노테이션 워크플로우 및 데이터셋 큐레이션을 지원하는 포괄적인 Eval 제품군입니다. |
| Guardrails 및 안전 | ●●○ | 환각 및 독성 탐지 기능을 갖추고 있으며, 안전을 위해 Eval 시점의 체크에 크게 의존합니다. |
| 분석 및 Dashboard | ●●● | 커스터마이징 가능한 뷰 옵션과 함께 비용, Latency, 토큰 사용량에 초점을 맞춘 강력한 운영 분석을 제공합니다. |
| 개발 라이프사이클 | ●●● | 프롬프트 엔지니어링부터 프로덕션 모니터링까지 전체 라이프사이클을 지원하며 강력한 실험 추적 기능을 갖추고 있습니다. |
| 통합 및 DX | ●●● | 주요 LLM 프레임워크와의 뛰어난 생태계 통합을 보여주지만, 통합 프록시/게이트웨이 서비스는 부족합니다. |
| 엔터프라이즈 및 인프라 | ●●○ | 셀프 호스팅 옵션과 강력한 액세스 제어를 갖춘 엔터프라이즈급 솔루션이지만, 완전 자동화된 데이터 웨어하우스 동기화는 제한적입니다. |


---

### Langfuse

**개요**: Langfuse는 선도적인 오픈 소스 LLM 엔지니어링 플랫폼으로서의 입지를 굳혔으며, 깊이 있는 Observability(Tracing/디버깅)와 강력한 프롬프트 관리 CMS로 차별화됩니다. 2026년 초의 최신 업데이트(v3.149-v3.155)는 세밀한 Eval 기능(Single Span Evals, 관찰 데이터에 대한 LLM-as-a-judge)과 성능 향상(이벤트 기반 테이블, 블룸 필터)으로의 강력한 전환을 보여줍니다. 개발자 경험(DX), SDK 통합 및 엔터프라이즈 준비성(RBAC, SSO, SOC 2)은 뛰어나지만, 네이티브 방화벽 프록시 대신 통합 기능을 통한 Guardrails에 의존하며 현재 고급 임베딩 공간 시각화 기능은 부족합니다.

**강점**:
- 오픈 소스 및 셀프 호스팅 가능: 완전한 데이터 제어 및 유연한 배포 옵션(Docker/Cloud) 제공.
- 통합 프롬프트 관리: 플랫폼 내에서 직접 프롬프트를 버전 관리하고 편집할 수 있는 강력한 CMS 기능.
- 포괄적인 Eval 제품군: 자동화된 LLM-as-a-judge, 수동 어노테이션 큐 및 회귀 테스트 결합.
- 개발자 우선 통합: 자동 Instrumentation 및 OTEL 호환성을 갖춘 우수한 SDK 지원.
- 엔터프라이즈 준비성: SOC 2/HIPAA 컴플라이언스, SSO 및 RBAC 지원 문서화 완료.

**약점**:
- 네이티브 프록시/게이트웨이 부재: 실시간 트래픽 가로채기 및 라우팅을 위한 전용 프록시 부족.
- 제한된 Guardrails: 네이티브 방화벽 엔진보다는 안전 차단을 위해 외부 통합에 의존.
- 시각화 깊이: 전문 연구 도구에 비해 고급 임베딩 공간 시각화(UMAP/t-SNE) 기능 미비.
- Streaming 지원 세부 정보: 지원은 되지만, Streaming 로직에 대한 세밀한 분석(첫 토큰 생성 시간 등)은 일반 Tracing에 비해 덜 강조됨.

**최신 업데이트**:
- Single Span Evals: 개별 Span에 대해 Eval을 실행하는 기능(Beta)을 도입하여 품질 체크의 정밀도 향상. (2026-02-15)
- 관찰 데이터 기반 LLM-as-a-Judge: Trace 내의 특정 관찰 데이터를 대상으로 더 정밀한 자동 피드백을 제공하도록 LLM-as-a-judge 기능 확장. (2026-02-10)
- 이벤트 기반 Trace 테이블: 성능 및 필터링 개선을 위해 이벤트 기반 아키텍처를 활용하도록 Trace/관찰 테이블 최적화. (2026-02-05)
- 블룸 필터 인덱스: 대규모 데이터셋에서 검색 속도를 크게 높이기 위해 user_id 및 session_id 쿼리에 블룸 필터 인덱스 추가. (2026-02-20)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Langfuse는 OpenTelemetry와 자동 Instrumentation을 활용하여 최소한의 설정으로 복잡한 LLM 호출에 대한 깊은 가시성을 제공하는 최상위 Tracing을 제공합니다. |
| 에이전트 및 RAG 특화 | ●●● | 에이전트 워크플로우(MCP, 그래프, 도구)를 훌륭하게 지원하지만, RAG 전용 시각화는 전문 Retrieval 도구보다 약간 덜 세밀합니다. |
| Eval 및 품질 | ●●● | 온라인 Judge, 수동 어노테이션 큐, 회귀 테스트를 아우르는 포괄적인 Eval 제품군을 갖추고 있으며, 최근 Single-span Eval 기능으로 강화되었습니다. |
| Guardrails 및 안전 | ●●○ | Guardrails는 실시간 프록시 방화벽보다는 주로 통합 및 비동기적인 Scoring/Eval 축적을 통해 구현됩니다. |
| 분석 및 Dashboard | ●●● | 운영 지표(비용, Latency, 토큰) 및 품질 점수에 대한 강력한 분석 기능을 제공하지만, 고급 고차원 데이터 시각화는 부족합니다. |
| 개발 라이프사이클 | ●●● | Langfuse의 결정적인 강점은 개발 라이프사이클 제품군으로, 프롬프트를 완전한 CMS, 버전 관리 및 CI/CD 호환성을 갖춘 코드로 취급합니다. |
| 통합 및 DX | ●●● | 강력한 SDK, 자동 Instrumentation 및 광범위한 프레임워크 호환성에서 알 수 있듯이 개발자 경험이 핵심 우선순위입니다. |
| 엔터프라이즈 및 인프라 | ●●● | 컴플라이언스(SOC 2/HIPAA), 보안 인증(SSO/RBAC) 및 셀프 호스팅을 포함한 유연한 배포 모델을 제공하여 엔터프라이즈 용도로 매우 적합합니다. |


---

### Braintrust

**개요**: Braintrust는 소프트웨어 개발 라이프사이클과 긴밀하게 통합된 개발자 중심의 Eval 및 Observability 플랫폼입니다. 프롬프트 엔지니어링과 Scorer 생태를 가속화하는 AI 어시스턴트 'Loop'와 자동화된 회귀 테스트를 위한 강력한 CI/CD 통합이 특징입니다. 최근 업데이트를 통해 스레딩 및 분류를 위한 심층 SDK 기능과 보안 및 캐싱을 위한 전용 AI Proxy 도입으로 에이전트 워크플로우 지원을 강화했습니다.

**강점**:
- 자동화된 프롬프트 및 Scorer 최적화를 위한 Loop AI 어시스턴트.
- 자동화된 회귀 테스트를 위한 매끄러운 CI/CD 통합.
- 프로덕션 Trace 및 데이터셋에 직접 연결되는 통합 플레이그라운드.
- 'LLM-as-a-judge' 위저드를 활용한 Eval 우선 접근 방식.
- JS/TypeScript AI 생태계(Vercel AI SDK)에 대한 강력한 지원.

**약점**:
- 내장된 자동 PII 탐지 또는 마스킹 기능 부재.
- 데이터 탐색을 위한 임베딩 공간 시각화(예: UMAP) 부족.
- 주제 차단 또는 탈옥(Jailbreak) 방지를 위한 네이티브 실시간 Guardrails 부재.
- 통합된 Fine-tuning 파이프라인 부재(데이터를 먼저 내보내야 함).

**최신 업데이트**:
- 공용 Span 이름 속성: Trace 식별을 개선하기 위해 Python SDK의 Span 인터페이스에 공용 이름 속성 추가. (2026-02-12)
- Python 스레드 검색: Python SDK 내에서 직접 스레드 컨텍스트를 검색할 수 있는 새로운 기능. (2026-02-12)
- 분류 필드: 더 풍부한 데이터 라벨링을 위해 Python SDK에 분류(Classifications) 필드 지원 도입. (2026-01-31)
- Eval 캐시 제어: 최신 결과를 보장하기 위해 Eval 중 캐싱을 명시적으로 끌 수 있는 옵션 추가. (2026-01-29)
- 실험 태그: 더 나은 조직화를 위해 실험 생성 시 태그를 전달할 수 있도록 허용. (2026-02-25)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | Braintrust는 포괄적인 자동 Instrumentation 및 OpenTelemetry 지원과 함께 최상위 Tracing 기능을 제공합니다. Streaming 및 복잡한 중첩 Trace 처리는 상세 디버깅에 적합합니다. |
| 에이전트 및 RAG 특화 | ●●○ | 특히 도구 렌더링 및 LangGraph 통합을 통해 에이전트 디버깅을 강력하게 지원합니다. RAG 시각화는 Span 형태로 존재하지만 전문 분석 도구보다는 덜 특화되어 있습니다. |
| Eval 및 품질 | ●●● | Eval은 Braintrust의 독보적인 카테고리로, 데이터셋 생성부터 CI/CD 회귀 테스트, 자동화된 프롬프트 최적화까지 고도로 통합된 워크플로우를 특징으로 합니다. |
| Guardrails 및 안전 | ○○○ | 안전 기능은 선제적인 실시간 Guardrails 차단보다는 주로 Eval Scorer를 통해 처리됩니다. PII 마스킹 및 전문적인 탈옥 방지 기능은 눈에 띄는 공백입니다. |
| 분석 및 Dashboard | ●●● | 비용, Latency, 오류를 아우르는 견고한 운영 분석을 제공합니다. 그러나 임베딩 공간 시각화와 같은 심층 데이터 탐색 도구는 부족합니다. |
| 개발 라이프사이클 | ●●● | 강력한 프롬프트 관리, 버전 관리 및 플레이그라운드 기능을 통해 엔지니어링 팀과 제품 팀 간의 간극을 메우며 개발 라이프사이클에서 탁월한 성능을 발휘합니다. |
| 통합 및 DX | ●●● | 고품질 SDK, AI Proxy 도입, 최신 LLM 스택(LangChain, Vercel)에 대한 광범위한 지원에서 알 수 있듯이 개발자 경험이 최우선입니다. |
| 엔터프라이즈 및 인프라 | ●●○ | VPC 배포 옵션과 액세스 제어를 통해 엔터프라이즈 사용자를 타겟팅하지만, 일부 컴플라이언스 및 보안 세부 사항(예: RBAC의 세밀함)은 고급 수준이라기보다 표준적인 수준입니다. |


---

### MLflow

**개요**: MLflow는 머신러닝 라이프사이클의 사실상 오픈 소스 표준이며, 3.x 릴리스를 통해 GenAI 분야로 크게 확장하고 있습니다. OpenTelemetry를 준수하는 강력한 Tracing, 포괄적인 실험 추적 및 강력한 프롬프트 관리를 제공합니다. 최근 업데이트(v3.10)에서는 엔터프라이즈 격리 요구 사항을 해결하기 위해 멀티 워크스페이스 환경에 대한 조직 수준의 지원을 도입했습니다. Python 중심의 개발, 통합 및 데이터 주권 측면에서는 탁월하지만, 네이티브 Guardrails, 고급 비용 분석 및 협업 어노테이션 워크플로우 측면에서는 전문 상용 벤더에 비해 뒤처집니다.

**강점**:
- 20개 이상의 라이브러리에 대해 한 줄의 코드로 자동 Instrumentation이 가능한 OpenTelemetry 네이티브 Tracing.
- 타의 추종을 불허하는 오픈 소스 커뮤니티 지원 및 데이터 주권 보장.
- 버전 관리 및 모델 구성을 포함한 포괄적인 프롬프트 레지스트리.
- DSPy 지원 및 커스텀 Judge를 갖춘 강력한 Eval 프레임워크.
- 엔터프라이즈 격리를 위한 새로운 멀티 워크스페이스 조직 지원.

**약점**:
- 네이티브 주제 차단 또는 탈옥 방지 Guardrails 부재.
- 전용 비용 분석 또는 재무 귀속 기능 없음.
- 제한된 협업 어노테이션 기능(큐 없음).
- 주로 Python 및 JavaScript에 집중된 SDK 지원.
- 고급 임베딩 공간 시각화 부재.

**최신 업데이트**:
- MLflow Tracking Server의 조직 지원: 실험과 모델의 논리적 격리 및 조직화를 가능하게 하는 멀티 워크스페이스 환경 지원. (2026-02-20)
- MLflow Assistant: UI 내에서 직접 문제를 식별, 진단 및 수정할 수 있도록 Claude Code가 지원하는 인프로덕트 챗봇. (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | MLflow는 OpenTelemetry 표준에 기반한 엔터프라이즈급 Tracing을 제공하며, 뛰어난 자동 Instrumentation 및 메타데이터 기능을 갖추고 있습니다. |
| 에이전트 및 RAG 특화 | ●●○ | Trace 가시성을 통해 에이전트 및 도구 디버깅에 강력한 기능을 제공하지만, 시각화가 그래프 중심보다는 타임라인 중심입니다. |
| Eval 및 품질 | ●●● | 강력한 LLM-as-a-judge 지원과 DSPy 통합을 갖춘 Eval의 강자이지만, 수동 어노테이션 워크플로우는 기본적인 수준입니다. |
| Guardrails 및 안전 | ●●○ | PII 비식별화 및 환각 지표와 같은 기본 안전 기능은 강력하지만, 주제 차단과 같은 포괄적인 활성 Guardrails는 부족합니다. |
| 분석 및 Dashboard | ●●○ | Latency 및 오류에 대한 강력한 기술 분석을 제공하지만, 재무/비용 가시성 및 고급 임베딩 시각화는 부족합니다. |
| 개발 라이프사이클 | ●●● | 상세한 프롬프트 레지스트리와 실험 추적 기능이 돋보이는 뛰어난 라이프사이클 관리 기능을 제공합니다. |
| 통합 및 DX | ●●○ | Python GenAI 생태계와의 깊은 통합과 강력한 게이트웨이 지원을 제공하지만, SDK 커버리지는 주로 Python/JS에 집중되어 있습니다. |
| 엔터프라이즈 및 인프라 | ●●● | 최근의 멀티 워크스페이스 격리 업데이트를 통해 엔터프라이즈 환경에 적합하며, 안전한 셀프 호스팅 인프라를 위한 최선의 선택으로 남아 있습니다. |


---

### Arize Phoenix

**개요**: Arize Phoenix는 OpenInference 및 OpenTelemetry 표준을 기반으로 구축된 선도적인 오픈 소스 AI Observability 및 Eval 플랫폼입니다. 현재 13.3.0 버전인 이 플랫폼은 임베딩 클러스터 및 Retrieval 검사와 같은 심층 시각화 도구를 사용하여 복잡한 LLM 애플리케이션, RAG 파이프라인 및 에이전트 워크플로우를 Tracing하는 데 탁월합니다. LLM-as-a-judge 및 회귀 테스트를 포함한 강력한 Eval 기능을 제공하지만, 실시간 프록시 기반 Guardrails나 차단보다는 주로 Observability와 분석에 집중합니다. v13.0+의 최신 업데이트에서는 간결성(Conciseness) 평가기, 네이티브 Model Context Protocol (MCP) 통합 및 개선된 프롬프트 편집 개발자 경험을 도입했습니다.

**강점**:
- 네이티브 OpenTelemetry 통합으로 벤더 중립적인 Tracing과 광범위한 호환성 보장.
- 임베딩 공간(UMAP) 및 RAG 문서 Retrieval을 위한 동급 최강의 시각화.
- 도구 호출 및 중간 상태 Tracing을 포함한 복잡한 에이전트 워크플로우에 대한 강력한 지원.
- 로컬 배포 및 완전한 데이터 주권을 허용하는 완전 오픈 소스 코어.
- 커스텀 Python Scorer 및 엄격한 회귀 테스트를 지원하는 포괄적인 Eval 제품군.

**약점**:
- 트래픽 가로채기 또는 캐싱을 위한 실시간 프록시/게이트웨이 기능 부재.
- PII 마스킹 또는 활성 탈옥 방지를 위한 내장 Guardrails 없음.
- 멀티모달 Tracing(이미지/오디오)이 네이티브로 지원되거나 문서화되지 않음.
- Trace를 Fine-tuning 작업으로 직접 내보내기 위한 통합 파이프라인 부재.
- 주요 언어 지원이 Python/JS에 집중되어 있어 다른 언어는 수동 OTEL Instrumentation이 필요함.

**최신 업데이트**:
- 간결성 분류 평가기: LLM 출력의 간결성을 평가하기 위한 새로운 평가기 추가. (2026-02-20)
- AWS Bedrock 교차 리전 선호도: AWS Bedrock 교차 리전 Inference를 위한 모델 접두사 선호도 설정 옵션. (2026-02-19)
- 평가기 상세 정보의 모델 표시: 평가기 상세 뷰에 모델 정보를 직접 추가하여 가시성 강화. (2026-02-18)
- LLM Eval 프롬프트 에디터의 자동 완성: 더 쉬운 Eval 구성을 위해 프롬프트 에디터에 자동 완성 기능 추가. (2026-02-13)
- 도구 응답 처리 평가기: 모델이 도구 응답을 처리하는 방식을 평가하기 위한 새로운 템플릿. (2026-02-13)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Tracing & Logging | ●●● | OpenTelemetry를 기반으로 구축된 Phoenix는 Python 프레임워크에 대한 뛰어난 자동 Instrumentation과 함께 강력한 핵심 Tracing 기능을 제공하지만, 멀티모달 지원은 아직 없습니다. |
| 에이전트 및 RAG 특화 | ●●● | Phoenix는 Retrieval 전용 뷰와 새로운 MCP 통합을 포함하여 최상위 RAG 및 에이전트 시각화 도구로 차별화됩니다. |
| Eval 및 품질 | ●●● | 코드와 구성을 기반으로 하는 포괄적인 Eval 제품군으로, 오프라인 실험과 온라인 모니터링을 모두 지원합니다. |
| Guardrails 및 안전 | ●●○ | 안전 기능은 실시간 차단이나 마스킹 Guardrails보다는 Eval을 통한 탐지(예: 환각 Scorer)에 집중되어 있습니다. |
| 분석 및 Dashboard | ●●● | 기술적 성능(Latency, 오류) 및 데이터 시각화(임베딩) 분야에서 강력한 분석 기능을 제공하며 표준적인 비용 추적 기능을 갖추고 있습니다. |
| 개발 라이프사이클 | ●●○ | 프롬프트 관리 및 플레이그라운드를 포함하여 개발의 실험 단계에 적합한 훌륭한 도구를 제공하지만, 다운스트림 Fine-tuning 통합은 부족합니다. |
| 통합 및 DX | ●●○ | 강력한 SDK와 프레임워크 지원을 갖춘 개발자 중심의 통합 전략을 취하고 있지만, 프록시 기반의 드롭인 방식보다는 코드 Instrumentation이 필요합니다. |
| 엔터프라이즈 및 인프라 | ●●● | 유연한 배포 모델과 컴플라이언스 지원을 통해 개인 개발자(OSS)와 대규모 팀(SaaS) 모두를 만족시키는 강력한 엔터프라이즈 태세를 갖추고 있습니다. |


---