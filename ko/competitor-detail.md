---
layout: default
title: LLM Observability — 제품 상세 정보
---

# LLM Observability — 제품 상세 정보
**날짜**: 2026-02-12 | **모델**: google/gemini-3-pro-preview

### W&B Weave

**개요**: W&B Weave는 Weights & Biases 생태계에 통합된 포괄적인 Observability 및 Eval 플랫폼으로, LLM 애플리케이션을 추적, 평가 및 개선하도록 설계되었습니다. 실험 추적, 멀티모달 Eval(오디오 포함), 모델 레지스트리 및 학습 워크플로우와의 원활한 통합이 강점입니다.

**강점**:
- W&B 학습 및 모델 레지스트리와의 깊은 통합 (예: 커스텀 LoRA)
- 오디오 모니터를 포함한 멀티모달 Eval 지원
- 강력한 실험 추적 및 버전 관리 전통 계승
- 자동화된 모델 비교를 위한 Dynamic Leaderboards
- 온프레미스/전용 서버를 포함한 유연한 배포 옵션

**약점**:
- 문서상 PII 마스킹 및 데이터 컴플라이언스 기능 명시 부족
- Streaming Tracing 기능에 대한 상세 설명 부족
- 에이전트를 위한 메모리 Tracing 기능이 명시적으로 강조되지 않음
- 사용량/크레딧 기반의 복잡할 수 있는 요금 체계

**최근 업데이트**:
- Audio Monitors: LLM judge를 사용하여 텍스트와 함께 오디오 출력(MP3/WAV)을 관찰하고 판정하는 모니터링 기능. (2026-02-01)
- Dynamic Leaderboards: 지속적인 커스터마이징 및 CSV 내보내기가 가능한 Eval 결과 기반 자동 생성 리더보드. (2026-01-29)
- Playground 내 커스텀 LoRA: Weave Playground에서 직접 미세 조정된 커스텀 LoRA 가중치를 로드하고 테스트하는 기능. (2026-01-16)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 단순한 데코레이터를 통해 중첩된 span, 입력, 출력 및 성능 지표를 자동으로 캡처하는 강력한 핵심 Tracing 기능을 제공합니다. |
| 에이전트 / RAG Observability | ●●● | RAG 및 에이전트 워크플로우를 강력하게 지원하며, 검색 품질 평가 및 복잡한 도구 상호작용 Tracing을 위한 특정 기능을 갖추고 있습니다. |
| Eval 통합 | ●●● | Audio Monitors, Dynamic Leaderboards, 멀티모달 출력을 위한 LLM-as-a-judge의 깊은 통합 등 고급 기능을 갖춘 독보적인 카테고리입니다. |
| 모니터링 및 지표 | ●●● | 비용, Latency, 품질 지표에 대한 포괄적인 모니터링과 지속적인 Eval을 위한 온라인 모니터 실행 기능을 제공합니다. |
| 실험 / 개선 루프 | ●●● | W&B의 성숙한 버전 관리 및 실험 추적 인프라를 활용하여 Observability를 학습 및 Fine-tuning과 연결하는 뛰어난 루프 기능을 제공합니다. |
| DevEx / 통합 | ●●● | 다국어 SDK와 Playground에서 커스텀 LoRA 어댑터를 직접 테스트하는 등의 고유한 기능을 통해 강력한 개발자 경험을 제공합니다. |
| 엔터프라이즈 및 보안 | ●●○ | 엔터프라이즈 배포 옵션(SaaS, 전용, 온프레미스)은 강력하지만, PII 마스킹 및 감사 로그와 같은 특정 컴플라이언스 기능은 공개 문서에 상세히 나와 있지 않습니다. |


---

### LangSmith

**개요**: LangSmith는 LangChain 생태계에 뿌리를 둔, AI 에이전트 개발, 디버깅 및 배포를 위한 프레임워크에 구애받지 않는 포괄적인 플랫폼입니다. 강력한 Tracing, Eval 및 모니터링 기능을 통해 엔드 투 엔드 가시성을 제공하며, 기업의 요구에 맞춰 클라우드 및 셀프 호스팅 배포를 모두 지원합니다.

**강점**:
- LangChain 및 LangGraph 프레임워크와의 깊은 통합
- 포괄적인 Human-in-the-loop 어노테이션 및 Eval 큐
- 강력한 셀프 호스팅 및 엔터프라이즈 보안 옵션
- LLM, 도구, 검색 전반에 걸친 통합 비용 및 성능 추적

**약점**:
- 시트(Seat) 및 Tracing 수 기반의 요금 모델은 대규모 사용 시 비용이 많이 들 수 있음
- 프레임워크 독립적인 기능에도 불구하고 LangChain과의 강한 연관성이 타 프레임워크 사용자에게 진입 장벽이 될 수 있음
- 방대한 기능 세트로 인해 단순한 사용 사례의 경우 학습 곡선이 가파를 수 있음

**최근 업데이트**:
- Tracing 미리보기 커스터마이징: UI에서 Tracing이 미리 보이는 방식을 사용자 정의하는 기능. (2026-02-06)
- Google Gen AI 래퍼: Google의 Gen AI 모델을 위한 새로운 래퍼 지원. (2026-01-31)
- LangSmith 셀프 호스팅 v0.13: 엔터프라이즈 배포를 위한 업데이트된 셀프 호스팅 버전. (2026-01-16)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 상세한 계층적 Tracing과 디버깅을 위한 통합 Playground 기능을 통해 최상위 수준의 핵심 Observability를 제공합니다. |
| 에이전트 / RAG Observability | ●●● | 도구, 검색 및 복잡한 추론 체인에 대한 특화된 뷰를 제공하여 에이전트 및 RAG Observability에서 탁월한 성능을 보입니다. |
| Eval 통합 | ●●● | 자동화된 테스트, 휴먼 어노테이션 및 데이터셋 관리를 위한 강력한 도구를 갖춘 핵심 기둥입니다. |
| 모니터링 및 지표 | ●●● | 실시간 알림 및 세분화된 분석을 통해 비용, Latency, 오류를 포괄하는 모니터링 제품군을 제공합니다. |
| 실험 / 개선 루프 | ●●● | 통합된 프롬프트 엔지니어링, 버전 관리 및 실험 추적을 통해 개선 루프를 강력하게 지원합니다. |
| DevEx / 통합 | ●●● | 광범위한 프레임워크 지원, SDK 및 원활한 통합을 위한 CLI 도구로 뛰어난 개발자 경험을 제공합니다. |
| 엔터프라이즈 및 보안 | ●●● | 셀프 호스팅 옵션, 강력한 보안 컴플라이언스(SOC 2, HIPAA) 및 세분화된 액세스 제어를 갖춘 엔터프라이즈급 솔루션입니다. |


---

### Langfuse

**개요**: Langfuse는 Observability, 프롬프트 관리 및 Eval을 통합하는 오픈 소스 기반의 개발자 중심 LLM 엔지니어링 플랫폼입니다. 강력한 셀프 호스팅 기능, 심층적인 에이전트 Tracing(그래프 및 도구 호출 포함), 실험 실행 및 데이터셋 관리를 위한 포괄적인 제품군이 특징입니다.

**강점**:
- 완전한 오픈 소스 및 셀프 호스팅 가능으로 최대의 데이터 제어권 제공
- Observability, 프롬프트 관리, Eval을 결합한 통합 플랫폼
- 그래프 뷰 및 추론 단계 시각화를 통한 고급 에이전트 Tracing
- LLM-as-a-judge 및 휴먼 어노테이션 큐를 포함한 강력한 Eval 제품군
- 복잡한 모델 가격 책정 계층을 지원하는 정확한 비용 추적

**약점**:
- 리플레이 기능이 원클릭 즉시 Tracing 리플레이가 아닌 Playground를 통한 수동 방식임
- 대규모 셀프 호스팅 시 복잡한 인프라(ClickHouse) 관리가 필요함
- 자체적인 Fine-tuning 오케스트레이션 부재 (데이터 내보내기에 의존)

**최근 업데이트**:
- 버전 관리된 데이터셋에서 실험 실행: 특정 버전의 타임스탬프에서 데이터셋을 가져오고 재현성을 위해 과거 버전에서 실험을 실행하는 기능. (2026-02-11)
- 조직 감사 로그 뷰어: 보안 및 액세스 이벤트를 추적하기 위한 조직 수준의 감사 로그 뷰어. (2026-02-09)
- 사고/추론 렌더링: Tracing 상세 뷰에서 LLM 응답의 사고(Thinking) 및 추론 부분을 분리하여 렌더링. (2026-02-09)
- 단일 관찰 Eval: 단일 관찰(Observation)에 대해 직접 Eval을 실행하는 기능 지원. (2026-02-09)
- Tracing에 대한 수정된 출력: Fine-tuning 데이터셋 구축을 위해 Tracing 뷰에서 직접 개선된 버전의 LLM 출력을 캡처. (2026-01-14)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 강력한 타임라인 뷰를 바탕으로 중첩된 span에 대한 깊은 가시성과 정확한 토큰/비용 추적을 포함한 포괄적인 Tracing 기능을 제공합니다. |
| 에이전트 / RAG Observability | ●●● | 그래프, 도구 사용 및 다단계 추론 프로세스에 대한 특화된 시각화를 특징으로 하며 에이전트 및 RAG 모니터링에 매우 유능합니다. |
| Eval 통합 | ●●● | LLM-as-a-judge, 휴먼 어노테이션 큐 및 데이터셋 관리가 워크플로우에 직접 통합된 완전한 Eval 루프를 제공합니다. |
| 모니터링 및 지표 | ●●● | 정확한 비용 계산(가격 계층 포함)과 유연한 커스텀 Dashboard에 중점을 둔 강력한 모니터링 기능을 제공합니다. |
| 실험 / 개선 루프 | ●●● | 버전 관리된 데이터셋, 프롬프트 관리 및 체계적인 실험을 통해 엄격한 테스트를 가능하게 하여 엔지니어링 라이프사이클을 훌륭하게 지원합니다. |
| DevEx / 통합 | ●●● | 강력한 SDK, OpenTelemetry 호환성 및 유연한 API 우선 아키텍처를 갖춘 개발자 우선 설계가 돋보입니다. |
| 엔터프라이즈 및 보안 | ●●● | RBAC, 감사 로그 및 완전한 데이터 주권을 위한 셀프 호스팅 기능을 포함하여 강력한 보안 기능을 갖춘 엔터프라이즈급 솔루션입니다. |


---

### Braintrust

**개요**: Braintrust는 Cursor 및 MCP와 같은 도구를 통해 코딩 워크플로우와 긴밀하게 통합되는 개발자 중심의 AI Observability 및 Eval 플랫폼입니다. 6개 프로그래밍 언어에 걸친 포괄적인 Tracing, Tracing 수준의 Scorer를 사용한 강력한 Eval 기능, 셀프 호스팅 및 RBAC와 같은 엔터프라이즈급 기능을 제공합니다.

**강점**:
- Python, TS, Go, Java, Ruby, C#을 아우르는 광범위한 SDK 생태계
- MCP를 통해 Cursor 및 VS Code와 같은 개발자 도구와 깊은 통합
- 데이터셋, 실험 및 프로덕션 모니터링을 연결하는 통합 Eval 워크플로우
- SQL 및 BTQL을 모두 사용한 유연한 데이터 쿼리 기능
- 셀프 호스팅 및 VPC를 포함한 강력한 엔터프라이즈 배포 옵션

**약점**:
- RAG 검색 품질을 위한 특화된 시각화 위젯(예: 청크 히트맵) 부족
- Fine-tuning 또는 RLHF를 위한 내장 관리형 서비스 없음 (데이터 내보내기에 의존)
- 복잡한 메모리 상태 변화에 대한 기본 시각화 제한적
- 경쟁사 대비 PII 마스킹 기능에 대한 상세 설명 부족
- 리전 지원 관련 문서가 제한적임

**최근 업데이트**:
- 커스텀 뷰에서 첨부 파일 렌더링: 커스텀 Tracing 뷰에서 이미지, 비디오, 오디오를 직접 렌더링 지원. (2026-02-01)
- Tracing 기원으로 이동: 로그의 Tracing에서 해당 Tracing이 시작된 프롬프트 또는 데이터셋 행으로 이동. (2026-02-01)
- Tracing 수준 Scorer: 커스텀 코드 Scorer가 다단계 Eval을 위해 전체 실행 Tracing에 액세스 가능. (2026-02-01)
- LangSmith 통합: Tracing 및 Eval 호출을 LangSmith와 Braintrust 모두에 전송하는 래퍼. (2026-02-01)
- Cursor 통합: Cursor 에디터 내에서 Braintrust MCP 서버를 자동으로 구성하는 확장 프로그램. (2026-02-01)
- 이미지 렌더링 보안 제어: 로그 내 외부 이미지에 대한 구성 가능한 모드(자동 로드, 클릭 시 로드, 차단). (2026-02-01)
- 집계가 포함된 단일 Span 필터: 집계된 Tracing 분석을 위해 단일 Span 필터와 GROUP BY 결합. (2026-02-01)
- Python, Ruby, Go 자동 Instrumentation: 주요 언어에 대한 코드 수정 없는 Tracing 지원. (2026-01-29)
- Temporal 통합: Temporal 워크플로우 및 액티비티의 자동 Tracing. (2026-01-21)
- 리뷰를 위한 칸반 레이아웃: 플래그가 지정된 span 및 리뷰 관리를 위한 드래그 앤 드롭 인터페이스. (2026-01-21)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 계층적 실행에 대한 깊은 가시성, 강력한 원시 데이터 검사 및 통합된 Playground 리플레이 기능을 통해 견고한 핵심 Tracing을 제공합니다. |
| 에이전트 / RAG Observability | ●●● | 특히 최근의 MCP 및 Temporal 통합을 통해 에이전트 워크플로우 및 도구 사용을 강력하게 지원하지만, 특화된 RAG 시각화는 덜 두드러집니다. |
| Eval 통합 | ●●● | Tracing 수준 Scorer와 같은 고급 기능을 통해 Tracing, 데이터셋, Scoring 사이의 원활한 루프를 제공하는 Eval 통합의 시장 리더입니다. |
| 모니터링 및 지표 | ●●● | SQL 및 BTQL을 사용하여 커스텀 지표를 정의할 수 있는 유연성을 갖춘 포괄적인 모니터링 Dashboard를 제공합니다. |
| 실험 / 개선 루프 | ●●● | 특히 프롬프트 엔지니어링 및 데이터셋 관리에서 실험 루프를 훌륭하게 지원하지만, 관리형 모델 학습까지는 제공하지 않습니다. |
| DevEx / 통합 | ●●● | 광범위한 SDK 지원, 고유한 IDE 통합(Cursor) 및 현대적인 에이전트 프레임워크 지원으로 동급 최고의 개발자 경험을 제공합니다. |
| 엔터프라이즈 및 보안 | ●●● | 셀프 호스팅 및 강력한 액세스 제어를 갖춘 강력한 엔터프라이즈 제품으로, 보안에 민감한 조직에 적합합니다. |


---

### MLflow

**개요**: 머신러닝 라이프사이클을 위한 오픈 소스 엔드 투 엔드 플랫폼으로, GenAI Observability 및 Eval 분야로 크게 확장되었습니다. 포괄적인 Tracing, 에이전트 모니터링 Dashboard, 시각적 빌더 및 최적화 알고리즘을 포함한 고급 "LLM-as-a-Judge" 기능을 제공합니다.

**강점**:
- 전통적인 ML과 GenAI(에이전트, LLM)를 위한 통합 플랫폼
- MemAlign 최적화 도구 및 Judge Builder UI를 갖춘 강력한 "LLM-as-a-Judge" 생태계
- 완전한 OpenTelemetry 호환성을 갖춘 오픈 소스 및 벤더 중립성
- 광범위한 프레임워크 통합 (LangChain, LlamaIndex, DSPy, CrewAI)
- 멀티 워크스페이스 엔터프라이즈 관리를 위한 새로운 "Organization Support"

**약점**:
- SaaS 전용 경쟁사에 비해 셀프 호스팅 시 인프라(데이터베이스, 서버) 관리가 필요함
- UI 텔레메트리 수집이 기본으로 활성화되어 있음 (옵트아웃 가능)
- 복잡한 에이전트 Tracing에 대한 직접적인 "리플레이" 기능이 전문 도구에 비해 덜 명시적임

**최근 업데이트**:
- Organization Support: 실험 및 리소스를 구성하기 위한 멀티 워크스페이스 환경 지원. (2026-02-12)
- MLflow Assistant: 에이전트 디버깅 및 문제 해결을 돕는 Claude Code 기반의 제품 내 챗봇. (2026-01-29)
- 에이전트 성능 Dashboard: Latency, 요청 수 및 품질 점수 모니터링을 위한 사전 구축된 차트. (2026-01-29)
- MemAlign Judge Optimizer: 피드백으로부터 Eval 가이드라인을 학습하여 Judge 정확도를 높이는 알고리즘. (2026-01-29)
- Judge Builder UI: 커스텀 LLM judge 프롬프트를 생성, 테스트 및 내보내기 위한 시각적 인터페이스. (2026-01-29)
- 지속적인 온라인 모니터링: 프로덕션의 유입 Tracing에 대해 LLM judge를 자동으로 실행. (2026-01-29)
- 분산 Tracing: 컨텍스트 전파를 통해 여러 서비스에 걸친 요청 추적. (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 분산 시스템 및 복잡한 에이전트 실행에 대한 깊은 가시성을 갖춘 강력한 OpenTelemetry 호환 Tracing을 제공합니다. |
| 에이전트 / RAG Observability | ●●● | 세션, 도구 사용 및 다단계 추론을 위한 특화된 뷰를 통해 에이전트 워크플로우를 강력하게 지원합니다. |
| Eval 통합 | ●●● | 시각적 Judge Builder, 자동화된 최적화(MemAlign) 및 지속적인 온라인 모니터링을 특징으로 하는 포괄적인 Eval 제품군입니다. |
| 모니터링 및 지표 | ●●● | 실시간 모니터링 기능과 함께 에이전트 성능, 비용 및 품질에 대해 사전 구축된 자동화 Dashboard를 제공합니다. |
| 실험 / 개선 루프 | ●●● | 프롬프트, 모델 및 데이터셋에 대한 강력한 버전 관리와 프로덕션에서의 지속적인 Eval을 통해 실험을 위한 뛰어난 루프를 제공합니다. |
| DevEx / 통합 | ●●● | 광범위한 프레임워크 지원, AI 코딩 어시스턴트, Python 및 TypeScript를 위한 강력한 SDK를 갖추어 개발자 친화적입니다. |
| 엔터프라이즈 및 보안 | ●●● | 새로운 멀티 워크스페이스 조직 지원으로 엔터프라이즈 준비가 되어 있으나, 셀프 호스팅 시 인프라 관리가 필요합니다. |


---

### Arize Phoenix

**개요**: Arize Phoenix는 LLM 애플리케이션의 실험, 문제 해결 및 지속적인 개선을 위해 설계된 오픈 소스 AI Observability 및 Eval 플랫폼입니다. OpenTelemetry/OpenInference를 통한 강력한 Tracing, 포괄적인 LLM-as-a-judge Eval 기능, 프로덕션 Tracing과 Eval 데이터셋 간의 원활한 데이터 이동 워크플로우를 제공합니다.

**강점**:
- 유연한 셀프 호스팅 옵션(Docker/K8s)을 갖춘 강력한 오픈 소스 기반
- 특화된 에이전트 평가 도구(도구 선택/호출)를 포함한 포괄적인 Eval 제품군
- CLI 및 AI 코딩 어시스턴트 지원을 통한 깊은 개발자 워크플로우 통합
- 프로덕션 Tracing을 Eval 데이터셋으로 변환하는 원활한 워크플로우
- 현대적인 LLM 프레임워크(LlamaIndex, LangChain, DSPy) 및 제공업체에 대한 광범위한 지원

**약점**:
- 제공된 문서상 PII 마스킹 또는 리댁션(Redaction) 기능 명시 부족
- 타 엔터프라이즈 기능에 비해 감사 로그 기능이 명시적으로 상세하지 않음
- 대화 이력을 통한 메모리 Tracing은 지원되지만, 도구 Tracing에 비해 전용 상태 시각화가 부족함

**최근 업데이트**:
- OpenAI Responses API 유형 지원: Playground 및 커스텀 제공업체에서 OpenAI API 유형(Chat Completions vs Responses) 선택 지원. (2026-02-12)
- 데이터셋 Evaluator: 실험 중 서버 측에서 자동으로 실행되도록 데이터셋에 Evaluator를 직접 연결. (2026-02-12)
- Playground용 커스텀 제공업체: Playground 및 프롬프트에서 재사용 가능한 커스텀 AI 제공업체(OpenAI, Azure, Anthropic 등)의 중앙 집중식 구성. (2026-02-11)
- Claude Opus 4.6 지원: 확장된 Thinking 파라미터 지원과 함께 Anthropic의 Claude Opus 4.6 모델 지원 추가. (2026-02-09)
- 도구 선택 및 호출 Evaluator: 에이전트가 올바른 도구를 선택하고 유효한 파라미터로 호출했는지 평가하는 새로운 Evaluator. (2026-01-31)
- 구성 가능한 이메일 추출: JMESPath를 사용하여 OAuth2 제공업체로부터 커스텀 이메일 추출 지원. (2026-01-28)
- 프롬프트/데이터셋용 CLI 명령: AI 어시스턴트로의 파이핑을 포함하여 프롬프트, 데이터셋 및 실험을 관리하기 위한 CLI 지원. (2026-01-22)
- Tracing에서 데이터셋 생성: 양방향 연결을 위한 span 연관성을 유지하면서 프로덕션 Tracing을 데이터셋으로 변환. (2026-01-21)
- Tracing과 함께 어노테이션 내보내기: 수동 레이블 및 Eval 점수를 포함한 Tracing 내보내기를 위한 CLI 지원. (2026-01-19)
- AI 어시스턴트를 위한 CLI 터미널 액세스: AI 코딩 어시스턴트(Cursor, Windsurf)가 Phoenix 데이터를 쿼리할 수 있도록 설계된 CLI 기능. (2026-01-17)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | OpenInference를 기반으로 구축된 포괄적인 Tracing 제품군을 제공하며, 네이티브 리플레이 기능과 함께 실행 흐름, Latency 및 비용에 대한 깊은 가시성을 제공합니다. |
| 에이전트 / RAG Observability | ●●● | 도구 선택 및 호출에 대한 특정 Evaluator와 함께 RAG 검색 Tracing 및 다단계 추론 분석에 대한 강력한 지원을 통해 에이전트 Observability에서 탁월한 성능을 보입니다. |
| Eval 통합 | ●●● | Tracing과 데이터셋 간의 긴밀한 루프, 광범위한 LLM-as-a-judge 지원, 자동 및 수동 평가를 위한 도구를 갖춘 핵심 기둥입니다. |
| 모니터링 및 지표 | ●●● | 비용, Latency, 오류에 대한 필수 모니터링 Dashboard와 도구 사용 정확도와 같은 에이전트 행동에 특화된 지표를 제공합니다. |
| 실험 / 개선 루프 | ●●● | 프롬프트 버전 관리, 실험 추적 및 테스트를 위해 프로덕션 트래픽에서 직접 데이터셋을 큐레이션하는 기능을 통해 강력한 개선 루프를 촉진합니다. |
| DevEx / 통합 | ●●● | 기능이 풍부한 CLI, 광범위한 SDK 지원, 인기 있는 LLM 프레임워크 및 오케스트레이션 도구와의 깊은 통합으로 뛰어난 개발자 경험을 제공합니다. |
| 엔터프라이즈 및 보안 | ●●○ | 엔터프라이즈 배포에 적합한 강력한 셀프 호스팅 및 액세스 제어 기능을 갖추고 있지만, PII 마스킹 및 감사 로그와 같은 특정 컴플라이언스 기능은 상세히 설명되어 있지 않습니다. |


---