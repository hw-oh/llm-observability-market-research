---
layout: default
title: LLM Observability — 제품 상세 정보
---

# LLM Observability — 제품 상세 정보
**날짜**: 2026-02-12 | **모델**: google/gemini-3-pro-preview

### W&B Weave

**개요**: Weights & Biases ML 플랫폼과 깊게 통합된 생성형 AI 애플리케이션 구축, 디버깅 및 평가를 위한 포괄적인 툴킷입니다. 실험 루프와 프로덕션 모니터링을 연결하는 데 탁월하며, 멀티모달 Eval 및 동적 리더보드와 같은 고급 기능을 제공합니다.

**강점**:
- W&B의 트레이닝 및 모델 레지스트리 에코시스템과 깊은 통합.
- 동적 리더보드(Dynamic Leaderboards) 및 오디오 모니터를 포함한 고급 Eval 기능.
- 커스텀 Fine-tuning 모델(LoRA) 테스트를 위한 원활한 지원.
- 모든 아티팩트(프롬프트, 모델, 데이터셋)에 대한 강력한 버전 관리.

**약점**:
- 제공된 텍스트 내에 명시적인 PII 마스킹 및 컴플라이언스 기능 부족.
- 풀스택 APM에 비해 인프라 수준의 메트릭 강조가 적음.
- 메모리 Tracing 및 복잡한 에이전트 그래프 시각화 세부 정보가 제한적임.

**최근 업데이트**:
- 오디오 모니터: LLM 평가자를 사용하여 텍스트와 함께 오디오 출력을 관찰하고 판단하는 모니터. (2026-02-01)
- 동적 리더보드: 지속적인 커스터마이징 및 CSV 내보내기 기능이 포함된 Eval 결과 기반 자동 생성 리더보드. (2026-01-29)
- Playground 내 커스텀 LoRA: Weave Playground에서 직접 커스텀 Fine-tuning된 LoRA 가중치를 테스트하고 평가하는 기능. (2026-01-16)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | W&B의 실험 추적 유산을 활용하여 상세한 입력, 출력 및 성능 메트릭을 캡처하는 강력한 핵심 Tracing 기능. |
| 에이전트 / RAG Observability | ●●● | 검색 품질 평가 및 다단계 실행 Tracing을 위한 특정 기능을 갖춘 RAG 및 에이전트 워크플로우에 대한 강력한 지원. |
| Eval 통합 | ●●● | 동적 리더보드, 커스텀 Scoring, 고유한 멀티모달(오디오) 판단 기능을 제공하는 Eval 분야의 시장 리더. |
| 모니터링 및 메트릭 | ●●● | 커스터마이징 가능한 Dashboard 및 프로덕션 트래픽의 온라인 Eval을 가능하게 하는 견고한 모니터링 기능. |
| 실험 / 개선 루프 | ●●● | Observability를 Fine-tuning(LoRA) 및 데이터셋 큐레이션에 직접 연결하는 탁월한 개선 루프 기능. |
| DevEx / 통합 | ●●● | 강력한 SDK와 커스텀 모델 및 Fine-tuning된 가중치를 위한 고유한 통합 포인트를 갖춘 개발자 친화적 환경. |
| 엔터프라이즈 및 보안 | ●○○ | 강력한 배포 옵션(SaaS/On-prem)을 제공하지만, PII 마스킹과 같은 특정 컴플라이언스 기능에 대한 상세 문서가 부족함. |


---

### LangSmith

**개요**: LangSmith는 개발, 디버깅, 테스트 및 배포를 아우르는 LLM 애플리케이션 라이프사이클 전체를 위한 프레임워크 불가지론적(agnostic) 플랫폼입니다. LangChain 및 LangGraph와 깊게 통합되어 있으면서도 다양한 스택(OpenAI, Vercel, Pydantic AI)을 지원하며, 셀프 호스팅 및 컴플라이언스 인증과 같은 강력한 엔터프라이즈 기능을 제공합니다.

**강점**:
- 원활한 에이전트 Tracing을 위한 LangChain 및 LangGraph와의 깊은 네이티브 통합.
- Pairwise 비교 및 휴먼 어노테이션 큐를 포함한 포괄적인 Eval 스위트.
- 셀프 호스팅, SSO 및 컴플라이언스 인증(SOC 2, HIPAA)을 갖춘 강력한 엔터프라이즈 오퍼링.
- 프로덕션 Tracing을 데이터셋 및 테스트에 직접 연결하는 강력한 '루프' 기능.

**약점**:
- 프레임워크 불가지론적 역량에도 불구하고 'LangChain 전용'이라는 인식으로 인해 타 프레임워크 사용자의 진입 장벽이 될 수 있음.
- Tracing/시트 수 기반의 가격 모델은 대규모 운영 시 복잡하거나 비용이 많이 들 수 있음.
- 광범위한 기능 세트로 인해 신규 사용자에게 학습 곡선이 가파를 수 있음.

**최근 업데이트**:
- Python SDK v0.7.1: LangSmith 플랫폼 연결을 위한 클라이언트 라이브러리 업데이트. (2026-02-10)
- Tracing 미리보기 커스터마이징: UI에서 Tracing이 미리 표시되는 방식을 커스터마이징하는 기능. (2026-02-06)
- Google Gen AI Wrapper 내보내기: SDK에서 Google Gen AI 래퍼를 위한 내보내기 기능. (2026-01-31)
- LangSmith 셀프 호스팅 v0.13: 셀프 호스팅 플랫폼의 새로운 버전 출시. (2026-01-16)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 복잡한 에이전트 워크플로우와 표준 LLM 호출에 대해 세밀한 가시성을 제공하는 동급 최고의 Tracing 기능. |
| 에이전트 / RAG Observability | ●●● | 도구 사용, 검색 단계 및 다회차 추론 루프에 대한 깊은 통찰력을 제공하는 에이전트 시스템 특화 기능. |
| Eval 통합 | ●●● | 프로덕션 데이터를 테스트 워크플로우에 원활하게 연결하고 자동 및 수동 검토를 모두 지원하는 강력한 Eval 스위트. |
| 모니터링 및 메트릭 | ●●● | 비용, 지연 시간, 오류와 같은 운영 메트릭에 집중하며 커스텀 정의를 지원하는 포괄적인 모니터링 Dashboard. |
| 실험 / 개선 루프 | ●●● | 특히 프롬프트 엔지니어링 및 데이터셋 관리를 위한 반복적인 개발 루프에 대한 강력한 지원. |
| DevEx / 통합 | ●●● | 광범위한 에코시스템 지원, CLI 도구 및 기존 워크플로우로의 쉬운 통합을 통한 우수한 개발자 경험. |
| 엔터프라이즈 및 보안 | ●●● | 셀프 호스팅 역량, SSO 및 엄격한 컴플라이언스 표준을 갖춘 성숙한 엔터프라이즈 플랫폼. |


---

### Langfuse

**개요**: Langfuse는 Observability, 프롬프트 관리 및 Eval을 단일 워크플로우로 통합하는 오픈 소스 LLM 엔지니어링 플랫폼입니다. 강력한 셀프 호스팅 기능과 그래프 뷰 및 추론 Tracing을 포함한 에이전트 워크플로우에 대한 깊은 지원이 특징입니다.

**강점**:
- 완전한 오픈 소스 및 셀프 호스팅 가능으로 벤더 종속성 방지.
- 버전 관리 및 배포 기능이 통합된 프롬프트 관리.
- LLM-as-a-Judge 및 휴먼 어노테이션을 포함한 포괄적인 Eval 스위트.
- 에이전트 워크플로우(그래프, 추론 Tracing)에 대한 강력한 지원.
- 지출 알림 기능이 포함된 세밀한 비용 및 토큰 추적.

**약점**:
- RLHF/Fine-tuning 트레이닝 작업을 위한 네이티브 오케스트레이션 부족 (데이터 준비에 집중).
- 모델 버전 관리가 전체 모델 가중치 레지스트리보다는 구성/프롬프트에 국한됨.
- 고급 기능 및 셀프 호스팅을 위한 설정이 복잡할 수 있음.

**최근 업데이트**:
- 조직 감사 로그 뷰어: 조직 감사 로그를 보기 위한 새로운 UI. (2026-02-09)
- 사고/추론 부분 렌더링: Tracing 상세 정보에서 사고 및 추론 Tracing(예: 추론 모델용) 렌더링 지원. (2026-02-09)
- 단일 관찰 Eval: 개별 관찰(observation)에 Eval을 추가하는 기능. (2026-02-09)
- 이벤트 기반 Tracing 테이블: 관찰/Tracing 테이블을 위한 새로운 이벤트 기반 뷰 모드. (2026-02-09)
- Tracing을 위한 수정된 출력: Fine-tuning 데이터셋 구축을 위해 Tracing 뷰에서 직접 개선된 LLM 출력 버전을 캡처. (2026-01-14)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 타임라인 뷰를 통해 중첩된 스팬, 비용 및 지연 시간에 대한 깊은 가시성을 제공하는 강력한 핵심 Tracing 기능. |
| 에이전트 / RAG Observability | ●●● | 그래프 시각화, 추론 Tracing 렌더링 및 도구 호출 분석을 포함한 현대적인 에이전트 패턴에 대한 탁월한 지원. |
| Eval 통합 | ●●● | 자동화된 LLM-as-a-Judge, 휴먼 어노테이션 큐 및 데이터셋 관리를 결합한 포괄적인 Eval 스위트. |
| 모니터링 및 메트릭 | ●●● | 커스터마이징 가능한 Dashboard, 지출 알림 및 상세한 비용/토큰 분석을 갖춘 강력한 모니터링 기능. |
| 실험 / 개선 루프 | ●●● | 프롬프트 버전 관리, 실험 및 데이터셋 관리를 통해 긴밀한 피드백 루프를 촉진함 (단, 트레이닝 오케스트레이션은 제외). |
| DevEx / 통합 | ●●● | 강력한 SDK, OpenTelemetry 지원 및 유연한 API 액세스를 갖춘 개발자 우선 설계. |
| 엔터프라이즈 및 보안 | ●●● | 강력한 보안 기능, 감사 로그 및 완전한 데이터 주권을 위한 셀프 호스팅 기능을 갖춘 엔터프라이즈급 솔루션. |


---

### Braintrust

**개요**: Braintrust는 Observability, Eval 및 프롬프트 관리를 결합하고 개발자 경험에 중점을 둔 포괄적인 AI 엔지니어링 플랫폼입니다. 여러 언어(Go, Java, C# 포함)에 대한 강력한 SDK 지원, Cursor와 같은 IDE와의 깊은 통합, 온라인 Scoring 및 데이터셋을 통한 지속적인 개선을 위한 엄격한 '루프' 워크플로우로 차별화됩니다.

**강점**:
- 시장에서 가장 광범위한 SDK 지원 (Python, TS, Go, Java, Ruby, C#).
- 개발자 도구(Cursor, VS Code, MCP)와의 깊은 통합.
- 데이터셋, 실험 및 프로덕션 모니터링을 연결하는 통합 워크플로우.
- 셀프 호스팅 및 RBAC를 포함한 강력한 엔터프라이즈 기능.
- 커스텀 분석을 위한 유연한 쿼리 언어(BTQL).

**약점**:
- 일반적인 스팬에 비해 RAG 검색 청크를 위한 특화된 시각화 부족.
- Fine-tuning API로 데이터를 내보내기 위한 직접적인 통합 부재.
- PII 마스킹 기능이 일부 경쟁사에 비해 덜 두드러지거나 자동화되지 않음.
- 도구 성공률 분석을 위해 기본 위젯보다는 커스텀 쿼리가 필요함.

**최근 업데이트**:
- 커스텀 뷰에서 첨부 파일 렌더링: 커스텀 Tracing 뷰에서 이미지, 비디오, 오디오 및 기타 첨부 파일을 직접 렌더링 지원. (2026-02)
- Tracing 기원 탐색: 로그의 Tracing에서 해당 Tracing이 시작된 프롬프트 또는 데이터셋 행으로 역추적. (2026-02)
- Tracing 수준 Scoring: 커스텀 코드 Scoring 도구가 전체 실행 Tracing에 액세스하여 다단계 워크플로우 평가 가능. (2026-02)
- LangSmith 통합: Tracing 및 Eval 호출을 LangSmith와 Braintrust 모두에 보내거나 Braintrust로만 라우팅하는 래퍼. (2026-02)
- Cursor 통합: Cursor에서 로그 및 실험을 쿼리하기 위해 Braintrust MCP 서버를 자동 구성하는 확장 프로그램. (2026-02)
- 이미지 렌더링 보안 제어: 이미지 URL을 통한 민감한 데이터 유출을 방지하기 위한 구성 가능한 모드(자동 로드, 클릭 로드, 차단). (2026-02)
- 집계 기능이 포함된 단일 스팬 필터: 단일 스팬 필터를 GROUP BY와 결합하여 스팬 수준 조건에 따라 Tracing 집계. (2026-02)
- 자동 Instrumentation (Python, Ruby, Go): Python, Ruby, Go 애플리케이션을 위한 코드 수정 없는 Tracing 지원. (2026-01)
- Temporal 통합: 분산 Tracing 지원을 통해 Temporal 워크플로우 및 활동을 자동으로 추적. (2026-01)
- 리뷰를 위한 칸반 레이아웃: 플래그가 지정된 스팬 및 리뷰 상태 관리를 위한 드래그 앤 드롭 인터페이스. (2026-01)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 계층적 실행에 대한 깊은 가시성과 복잡한 데이터 유형 및 Streaming에 대한 강력한 지원을 갖춘 우수한 핵심 Tracing 기능. |
| 에이전트 / RAG Observability | ●●● | 새로운 Temporal 및 Claude 에이전트 통합을 통해 에이전트 워크플로우 및 도구 사용을 강력하게 지원함 (단, RAG 전용 시각화는 덜 강조됨). |
| Eval 통합 | ●●● | 프로덕션 Tracing, 데이터셋, 엄격한 자동 또는 수동 Scoring 사이의 긴밀한 루프를 제공하는 Eval 통합의 시장 리더. |
| 모니터링 및 메트릭 | ●●● | BTQL을 기반으로 표준 비용/성능 메트릭과 함께 고도로 커스터마이징 가능한 Dashboard 및 알림을 제공하는 강력한 모니터링 기능. |
| 실험 / 개선 루프 | ●●● | 프롬프트 및 모델의 빠른 반복을 촉진하기 위해 강력한 버전 관리 및 실험 추적을 제공하는 '개선 루프'의 강자. |
| DevEx / 통합 | ●●● | 광범위한 SDK, 자동 Instrumentation, Cursor 및 MCP와 같은 혁신적인 통합을 갖춘 동급 최고의 개발자 경험. |
| 엔터프라이즈 및 보안 | ●●● | 셀프 호스팅 및 RBAC를 갖춘 견고한 엔터프라이즈 오퍼링 (단, 자동 PII 마스킹과 같은 특정 기능은 더 명시될 필요가 있음). |


---

### MLflow

**개요**: 강력한 Observability, Eval 및 에이전트 관리 기능을 갖춘 GenAI 분야로 크게 확장된 포괄적인 오픈 소스 MLOps 플랫폼입니다. 완전한 OpenTelemetry 호환성을 바탕으로 실험 및 프롬프트 엔지니어링부터 프로덕션 모니터링 및 배포에 이르는 전체 라이프사이클을 아우르는 올인원 솔루션을 제공합니다.

**강점**:
- 추적, 레지스트리, Eval 및 배포를 아우르는 포괄적인 '올인원' 플랫폼.
- 완전한 OpenTelemetry 호환성을 갖춘 벤더 중립적 설계.
- Judge Builder 및 MemAlign 최적화 도구를 포함한 고급 Eval 역량.
- Python 및 TypeScript SDK를 통한 강력한 에코시스템 지원.
- 조직 지원 및 RBAC와 같은 엔터프라이즈급 기능.

**약점**:
- 셀프 호스팅 시 인프라 및 데이터베이스 백엔드 관리가 필요함.
- 가벼운 니치 도구들에 비해 광범위한 기능 세트가 부담스러울 수 있음.
- UI 텔레메트리 수집(거부 가능)이 개인정보에 민감한 사용자에게 우려가 될 수 있음.

**최근 업데이트**:
- 조직 지원: 실험 및 리소스를 정리하기 위한 멀티 워크스페이스 환경 지원. (2026-02-12)
- MLflow Assistant: 에이전트 디버깅 및 문제 해결을 돕는 Claude Code 기반의 인프로덕트 챗봇. (2026-01-29)
- 에이전트 성능 Dashboard: 에이전트 지연 시간, 요청 수 및 품질 점수를 모니터링하기 위한 사전 구축된 차트. (2026-01-29)
- MemAlign Judge Optimizer: 피드백으로부터 평가 가이드라인을 학습하여 평가자 정확도를 향상시키는 알고리즘. (2026-01-29)
- Judge Builder UI: 코드 없이 LLM 평가자 프롬프트를 생성, 테스트 및 반복할 수 있는 시각적 인터페이스. (2026-01-29)
- 지속적인 온라인 모니터링: 유입되는 프로덕션 Tracing에 대해 LLM 평가자를 자동으로 실행. (2026-01-29)
- 분산 Tracing: 컨텍스트 전파를 통해 여러 서비스에 걸친 요청을 추적. (2026-01-29)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | 분산 Tracing 및 GenAI 워크플로우의 깊은 내부 조사를 처리하는 강력한 OpenTelemetry 네이티브 Tracing 시스템. |
| 에이전트 / RAG Observability | ●●● | 다회차 대화, 도구 사용 효율성 및 세션 추적을 위한 특화된 기능을 갖춘 고급 에이전트 Observability. |
| Eval 통합 | ●●● | 시각적 Judge Builder, 자동화된 평가자 최적화(MemAlign) 및 지속적인 온라인 Eval을 특징으로 하는 업계 선도적인 Eval 스위트. |
| 모니터링 및 메트릭 | ●●● | 에이전트 성능, 비용 및 품질 메트릭에 대한 실시간 통찰력을 제공하는 포괄적인 모니터링 Dashboard. |
| 실험 / 개선 루프 | ●●● | 고급 프롬프트 관리, 프로덕션에서의 지속적인 Eval 및 실험 추적을 통한 강력한 반복 루프. |
| DevEx / 통합 | ●●● | 광범위한 프레임워크 지원, AI 코딩 어시스턴트, Python 및 JS/TS용 강력한 SDK를 통한 우수한 개발자 경험. |
| 엔터프라이즈 및 보안 | ●●● | 새로운 멀티 워크스페이스 조직 지원을 통해 엔터프라이즈 준비를 마쳤으나, 셀프 호스팅 시 인프라 관리가 필요함. |


---

### Arize Phoenix

**개요**: Arize Phoenix는 실험과 프로덕션 모니터링 사이의 간극을 메우는 오픈 소스 AI Observability 및 Eval 플랫폼입니다. OpenTelemetry를 통한 강력한 Tracing, 도구 사용 메트릭을 포함한 고급 에이전트 Eval 역량, 프로덕션 Tracing을 Eval 데이터셋으로 변환하는 원활한 워크플로우를 제공합니다.

**강점**:
- 강력한 셀프 호스팅 옵션(Docker/Kubernetes)을 갖춘 견고한 오픈 소스 기반.
- 특화된 도구 선택 및 호출 메트릭을 포함한 고급 에이전트 Eval 역량.
- 프로덕션 Tracing을 선별된 Eval 데이터셋으로 변환하는 원활한 워크플로우.
- 기능이 풍부한 CLI, SDK 및 프롬프트 Playground를 통한 포괄적인 개발자 경험.
- 주요 LLM 프레임워크(LangChain, LlamaIndex) 및 제공업체와의 깊은 통합.

**약점**:
- 제공된 문서 내에 명시적인 PII 마스킹 및 데이터 편집 기능 부족.
- 감사 로깅 역량이 명시적으로 상세히 설명되지 않음.
- 데이터 내보내기 이외의 강화 학습(RL) 워크플로우에 대한 네이티브 지원 제한적.
- 도구 및 검색 Tracing에 비해 메모리 상태 시각화가 덜 강조됨.

**최근 업데이트**:
- 데이터셋 평가자: 실험 중 서버 측에서 자동 실행되도록 데이터셋에 평가자를 직접 연결. (2026-02-12)
- OpenAI Responses API 유형 지원: OpenAI 모델에 대해 Chat Completions와 Responses API 유형 중 선택 지원. (2026-02-12)
- Playground용 커스텀 제공업체: Playground와 프롬프트 전반에서 재사용할 수 있는 커스텀 제공업체의 중앙 집중식 구성. (2026-02-11)
- Claude Opus 4.6 모델 지원: 확장된 사고(thinking) 파라미터 지원을 포함한 Anthropic의 Claude Opus 4.6 지원. (2026-02-09)
- 도구 선택 및 호출 평가자: 에이전트의 도구 선택 정확도 및 파라미터 포맷팅을 평가하는 새로운 평가자. (2026-01-31)
- 구성 가능한 이메일 추출: JMESPath를 사용하여 OAuth2 제공업체로부터 커스텀 이메일 추출 지원. (2026-01-28)
- Phoenix CLI 명령: 터미널에서 프롬프트, 데이터셋 및 실험을 관리하기 위한 CLI 명령. (2026-01-22)
- 스팬 연관 기능이 포함된 Tracing-to-Dataset: 소스 스팬에 대한 양방향 링크를 유지하면서 Tracing을 데이터셋으로 변환. (2026-01-21)
- Tracing과 함께 어노테이션 내보내기: 오프라인 분석을 위해 어노테이션과 함께 Tracing을 내보내는 CLI 지원. (2026-01-19)
- AI 어시스턴트를 위한 CLI 터미널 액세스: AI 코딩 어시스턴트가 CLI를 통해 Phoenix 데이터를 직접 쿼리할 수 있도록 허용. (2026-01-17)

| 카테고리 | 등급 | 요약 |
|---|---|---|
| 핵심 Observability | ●●● | Phoenix는 OpenTelemetry에 기반한 성숙한 Tracing 환경을 제공하며, 강력한 재생 기능을 통해 실행 단계, 비용 및 지연 시간에 대한 깊은 가시성을 제공함. |
| 에이전트 / RAG Observability | ●●● | 도구 선택 Eval에 대한 최근 업데이트와 추론 모델 지원을 통해 에이전트 Observability에서 탁월하며, 복잡한 에이전트 워크플로우에 매우 적합함. |
| Eval 통합 | ●●● | Tracing과 데이터셋 사이의 긴밀한 루프, 광범위한 LLM-as-a-judge 역량 및 회귀 테스트를 위한 강력한 도구를 갖춘 핵심 강점. |
| 모니터링 및 메트릭 | ●●● | 커스터마이징 가능한 메트릭 정의를 지원하며, 특히 토큰 경제성 및 도구 사용 성능에 대한 심도 있는 포괄적 모니터링 메트릭을 제공함. |
| 실험 / 개선 루프 | ●●● | 사용자가 프롬프트 및 데이터셋의 버전을 관리하고, 체계적인 실험을 수행하며, 성능을 지속적으로 평가할 수 있는 완전한 개선 루프를 제공함. |
| DevEx / 통합 | ●●● | 최근 출시된 포괄적인 CLI, 강력한 SDK 지원 및 광범위한 프레임워크 통합에서 알 수 있듯이 개발자 경험이 최우선 순위임. |
| 엔터프라이즈 및 보안 | ●●○ | 셀프 호스팅 및 액세스 제어(RBAC/LDAP)는 강력하지만, 문서상에 PII 마스킹 및 감사 로깅 기능에 대한 명시적인 세부 정보가 부족함. |


---