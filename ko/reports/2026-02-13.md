---
layout: default
title: LLM Observability 시장 조사 - 2026-02-13
---

# 주간 LLM Observability 시장 조사 보고서
**날짜**: 2026-02-13 | **모델**: google/gemini-3-pro-preview | **데이터 수집일**: 2026-02-13

## 1. 요약 (Executive Summary)

- Langfuse는 추론 단계를 시각화하기 위한 'thinking' Tracing 렌더링 지원을 도입했으며, Arize Phoenix는 에이전트 워크플로우에서 도구 선택 및 충실도(faithfulness)를 평가하기 위한 전용 지표를 출시했습니다.
- MLflow는 버전 3.10을 출시하며 대규모 엔터프라이즈 환경 내에서 멀티 워크스페이스 관리 및 액세스 제어를 가능하게 하는 Organization Support를 도입했습니다.
- LangSmith는 Self-Hosted v0.13을 출시하여 온프레미스 배포의 인프라 안정성을 개선하는 동시에 Streaming 지원 및 에이전트 실행 그래프 시각화 기능을 유지했습니다.
- Braintrust는 기존의 'Loop' AI Eval 도우미와 더불어, 휴먼 인 더 루프(human-in-the-loop) 품질 관리 워크플로우를 구조화하기 위해 전용 'Review' 스팬(span) 유형을 추가했습니다.
- W&B Weave는 VPC 옵션에 대해 SOC 2 Type II 및 HIPAA 준수를 확인했으며, 네이티브 Model Context Protocol (MCP) 통합을 통해 에이전트 Observability 역량을 차별화했습니다.

> **시장 인사이트**: Arize Phoenix의 전문화된 에이전트 지표 출시와 Langfuse의 'thinking' Trace 지원은 Weave의 에이전트 Observability 깊이에 직접적인 도전이 되고 있습니다. 기술적 차별성을 유지하기 위해 Weave 독점의 Model Context Protocol (MCP) 통합을 지속적으로 활용할 필요가 있습니다.


## 2. 신규 기능 (최근 30일)

### [W&B Weave](https://app.getbeamer.com/wandb/en)
- **Audio Monitors**: 텍스트와 함께 오디오 출력을 관찰하고 판단하는 모니터를 생성하여 보이스 에이전트의 Eval을 가능하게 합니다. (2026-02-01, Eval & 품질)
- **Dynamic Leaderboards**: 수동 설정 대신 필터링 및 커스터마이징 기능이 포함된 Eval 결과 기반 리더보드를 자동 생성합니다. (2026-01-29, Eval & 품질)
- **Playground 내 커스텀 LoRA 지원**: Weave Playground에서 직접 Fine-tuning된 커스텀 LoRA 가중치를 테스트하고 평가할 수 있도록 지원합니다. (2026-01-16, 개발 라이프사이클)

### [LangSmith](https://changelog.langchain.com)
- **Trace 미리보기 커스터마이징**: LangSmith UI에서 Trace가 미리 표시되는 방식을 커스터마이징하는 기능입니다. (2026-02-06, 핵심 Tracing & 로깅)
- **Non-otel Google ADK 래퍼**: OpenTelemetry 의존성 없이 Google ADK 통합을 위한 새로운 래퍼를 제공합니다. (2026-02-02, 통합 & DX)
- **Google Gen AI 래퍼**: Google Generative AI 통합을 위해 내보내기 가능한 래퍼입니다. (2026-01-31, 통합 & DX)
- **Gemini TS 래퍼**: Gemini 모델을 위한 베타 버전의 TypeScript 래퍼입니다. (2026-01-26, 통합 & DX)
- **LangSmith Self-Hosted v0.13**: 플랫폼의 셀프 호스팅 버전 업데이트입니다. (2026-01-16, 엔터프라이즈 & 인프라)

### [Langfuse](https://langfuse.com/changelog)
- **Observation 기반 LLM-as-a-Judge**: 더 세밀한 품질 관리를 위해 특정 Observation에서 직접 LLM-as-a-judge Eval을 실행하는 기능을 추가했습니다. (2026-02-13, Eval & 품질)
- **Thinking/Reasoning Trace 렌더링**: DeepSeek과 같은 Chain-of-Thought 모델을 지원하기 위해 'thinking' 및 'reasoning' 부분에 대한 새로운 Trace 상세 렌더링을 지원합니다. (2026-02-05, 핵심 Tracing & 로깅)
- **인라인 Trace 댓글**: 사용자가 Trace 내의 IO 데이터 일부에 인라인으로 댓글을 추가할 수 있게 하여 협업 효율을 높였습니다. (2026-01-25, 통합 & DX)
- **단일 Observation Eval**: 전체 Trace뿐만 아니라 단일 Observation 단위로 Eval을 실행할 수 있습니다. (2026-02-08, Eval & 품질)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **Thread Retrieval API**: Python SDK에서 프로그래밍 방식으로 스레드를 검색하는 기능을 추가했습니다. (2026-02-12, 통합 & DX)
- **서브 에이전트 중첩(Nesting)**: Claude 에이전트 SDK 래퍼에서 서브 에이전트 중첩 지원을 추가했습니다. (2026-02-12, 에이전트 & RAG 특화)
- **Review 스팬 유형**: 휴먼 리뷰 워크플로우를 지원하기 위해 특정 'Review' 스팬 유형을 도입했습니다. (2026-02-05, Eval & 품질)
- **Classifications 필드**: 향상된 메타데이터 태깅을 위해 SDK에 classifications 필드를 추가했습니다. (2026-01-31, 핵심 Tracing & 로깅)
- **Trace Scoring 후보**: Python SDK 내에서 직접 Trace에 Scoring을 수행하는 새로운 기능을 추가했습니다. (2026-01-21, Eval & 품질)

### [MLflow](https://mlflow.org/releases)
- **Organization Support**: 여러 워크스페이스에 걸쳐 실험과 리소스를 관리할 수 있는 멀티 워크스페이스 환경을 지원합니다. (2026-02-12, 엔터프라이즈 & 인프라)
- **MLflow Assistant**: UI 내에서 직접 문제를 식별, 진단 및 수정할 수 있도록 돕는 Claude Code 기반의 인프로덕트 챗봇입니다. (2026-01-29, 통합 & DX)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **Claude Opus 4.6 지원**: Playground에서 Claude Opus 4.6 모델 지원을 추가했습니다. (2026-02-09, 개발 라이프사이클)
- **도구 선택 Eval 도구**: 에이전트 워크플로우에서 도구 선택의 품질을 평가하는 새로운 Eval 도구를 추가했습니다. (2026-02-06, Eval & 품질)
- **충실도(Faithfulness) Eval 도구**: 근거 제시 능력 확인을 위해 FaithfulnessEvaluator를 도입했습니다 (HallucinationEvaluator는 지원 중단 예정). (2026-02-02, Eval & 품질)
- **도구 호출 정확도 지표**: 도구 호출의 정확도를 추적하는 새로운 지표를 추가했습니다. (2026-02-02, Eval & 품질)
- **구성 가능한 이메일 추출**: OAuth2에서 이메일 추출 설정을 위한 EMAIL_ATTRIBUTE_PATH를 추가했습니다. (2026-01-28, 엔터프라이즈 & 인프라)
- **지표용 Cursor Rule**: 새로운 내장 지표(LLM 분류 Eval 도구) 생성을 위한 Cursor Rule을 추가했습니다. (2026-01-21, Eval & 품질)

## 3. 포지셔닝 변화

| 제품 | 현재 | 향후 방향 | 신호 |
|---|---|---|---|
| W&B Weave | 복잡한 에이전트 시스템을 구축하는 개발자를 위한 코드 우선의 엄격한 Eval 및 Observability 플랫폼. | 멀티모달 지원을 확장하고 오프라인 실험과 온라인 프로덕션 모니터링 간의 간극을 해소. | 최근 Audio Monitors 및 Dynamic Leaderboards 출시는 다양한 모달리티에 걸친 포괄적이고 자동화된 Eval에 대한 집중을 강화함. |
| LangSmith | LangChain 생태계 및 복잡한 에이전트 애플리케이션을 위한 결정적인 Observability 및 Eval 플랫폼. | LangChain을 넘어 더 넓은 모델 지원(Google/Gemini)과 강화된 엔터프라이즈 셀프 호스팅을 갖춘 범용 LLM DevOps 플랫폼으로 확장. | 특정 프레임워크에 의존하지 않는 Google Gen AI 래퍼 출시 및 셀프 호스팅 엔터프라이즈 버전의 지속적인 업데이트. |
| Langfuse | 강력한 프레임워크 통합 및 셀프 호스팅 기능으로 선호되는 개발자 중심의 오픈 소스 Observability 및 Eval 플랫폼. | 고급 에이전트 워크플로우에 대응하기 위해 Eval 단위를 세분화하고 복잡한 추론 모델(CoT) 지원을 심화. | 'thinking' Trace 렌더링 및 세밀한 'observation 수준' Eval에 집중한 최근 업데이트. |
| Braintrust | 엔터프라이즈 엔지니어링 팀을 위한 최고의 'Eval 중심' 개발 플랫폼으로 포지셔닝. | 복잡한 에이전트 워크플로우 및 휴먼 인 더 루프 리뷰 프로세스에 대한 지원을 심화. | 서브 에이전트 중첩, Thread Retrieval API 및 전용 'Review' 스팬 유형을 추가한 최근 업데이트. |
| MLflow | GenAI Tracing 및 Eval을 위한 경쟁력 있고 통합된 스위트를 제공하는 MLOps의 오픈 소스 표준. | 멀티 워크스페이스 지원으로 엔터프라이즈 준비성을 심화하고 AI 지원 디버깅을 통해 개발자 경험을 향상. | 2026년 초 Organization Support(v3.10) 및 MLflow Assistant(v3.9) 출시. |
| Arize Phoenix | 복잡한 RAG 및 에이전트 애플리케이션을 구축하는 AI 엔지니어를 위한 최고의 오픈 소스, 코드 우선 Observability 플랫폼. | 비기술적 CMS가 아닌 기술적 워크벤치로서의 역할을 강화하며, 에이전트 및 도구에 대한 더 깊고 전문화된 Eval 역량으로 이동. | 도구 선택, 충실도 및 도구 호출 정확도를 위한 전문 Eval 도구의 최근 출시는 복잡한 에이전트 신뢰성 문제를 해결하는 데 명확히 집중하고 있음을 보여줌. |

## 4. 엔터프라이즈 신호

- MLflow는 대규모 팀을 위한 멀티 워크스페이스 관리를 가능하게 하는 Organization Support(v3.10)를 도입했습니다.
- LangSmith는 Self-Hosted v0.13을 출시하여 온프레미스 엔터프라이즈 안정성에 대한 의지를 강화했습니다.
- Braintrust는 엔터프라이즈 품질 관리를 위한 휴먼 인 더 루프 워크플로우를 공식화하기 위해 특정 'Review' 스팬 유형을 추가했습니다.
- W&B Weave는 VPC 배포 옵션과 함께 SOC 2 Type II, HIPAA 및 GDPR 준수를 확인했습니다.
- Langfuse는 완전한 데이터 주권을 요구하는 기업에 매력적인, 완전 셀프 호스팅 가능한 MIT 라이선스 버전을 지속적으로 제공하고 있습니다.

---

## 방법론

데이터는 2026-02-13에 GitHub/PyPI 피드 및 문서 스크래핑을 통해 수집되었습니다.
카테고리 분석은 Perplexity Sonar(웹 검색 + 분석)를 사용하여 수행되었습니다. 종합 분석은 OpenRouter를 통해 google/gemini-3-pro-preview 모델을 사용하여 수행되었습니다.