---
layout: default
title: LLM Observability 시장 조사 - 2026-02-25
---

# 주간 LLM Observability 시장 조사 보고서
**날짜**: 2026-02-25 | **모델**: google/gemini-3-pro-preview | **데이터 수집일**: 2026-02-25

## 1. 요약 (Executive Summary)

- W&B Weave는 네이티브 오디오 모니터와 동적 리더보드를 출시하며 기능 격차를 빠르게 좁혔으며, 최상위권 멀티모달 플랫폼으로 자리매김하고 있습니다.
- LangSmith는 에이전트형(agentic) Observability 분야에서 우위를 유지하고 있으며, 최근 LangGraph 사용자를 위한 강화된 Sandbox와 맞춤형 Tracing 미리보기를 통해 플랫폼을 개선했습니다.
- Langfuse는 오픈소스 리더로서의 입지를 공고히 하며, 복잡한 Tracing 내에서 세밀한 품질 체크가 가능한 'Single Span Evals'를 도입했습니다.
- Braintrust는 자동화된 Scorer 생성을 위한 'Loop' AI 어시스턴트와 보안을 위한 새로운 AI Proxy를 통해 개발 라이프사이클 시장을 공격적으로 공략하고 있습니다.
- MLflow는 멀티 워크스페이스를 지원하는 Organization Support를 추가하고 프롬프트 최적화를 위해 DSPy와 깊게 통합함으로써 엔터프라이즈 유틸리티를 강화했습니다.
- Arize Phoenix는 임베딩 공간 시각화(UMAP) 기능에서 독보적인 위치를 유지하고 있으며, 최근 네이티브 Model Context Protocol (MCP) 통합을 추가했습니다.

> **시장 인사이트**: Weave는 가벼운 Tracing 도구에서 최상위권 멀티모달 플랫폼으로 빠르게 진화하고 있으며, W&B의 학습 에코시스템을 활용해 기존 전문 업체들을 위협하고 있습니다.


## 2. 신규 기능 (최근 30일)

### [W&B Weave](https://app.getbeamer.com/wandb/en)
- **Tracing 분석 개요**: 요청 수, Latency 백분위수, 토큰 사용량 및 비용을 보여주는 프로젝트 개요 기능. (2026-02-23, Analytics)
- **Tracing 비교 요약**: 집계된 도구 사용량, Score 및 비용을 바탕으로 Tracing을 비교할 수 있는 플랫 뷰(Flattened views). (2026-02-23, Evaluation)
- **오디오 모니터**: LLM Judge를 사용하여 오디오 입력을 관찰하고 판별하는 모니터 생성 지원. (2026-02-01, Evaluation)
- **동적 리더보드**: Eval 결과로부터 자동 생성되는 리더보드로, 영구적인 커스터마이징 및 CSV 내보내기 지원. (2026-01-29, Evaluation)

### [LangSmith](https://changelog.langchain.com)
- **Sandbox 예외 유형 및 구조**: 에이전트 Sandbox의 에러 핸들링 개선을 위해 Sandbox 예외 유형 및 클라이언트 구조 추가. (2026-02-21, Development Lifecycle)
- **Google Gen AI Wrapper 내보내기**: Google Gen AI Wrapper 내보내기 기능 및 non-otel wrapper 지원 추가. (2026-02-02, Integration & DX)
- **Tracing 미리보기 커스터마이징**: LangSmith UI 내에서 Tracing 미리보기가 표시되는 방식을 맞춤 설정하는 기능. (2026-02-06, Core Tracing & Logging)

### [Langfuse](https://langfuse.com/changelog)
- **Single Span Evals**: 개별 Span에 대해 Eval을 실행하는 기능(Beta)을 도입하여 품질 체크의 정밀도 향상. (2026-02-15, Evaluation & Quality)
- **Observation 대상 LLM-as-a-Judge**: Tracing 내의 특정 Observation을 타겟팅하여 더 정밀한 자동 피드백을 제공하도록 LLM-as-a-judge 기능 확장. (2026-02-10, Evaluation & Quality)
- **이벤트 기반 Tracing 테이블**: 성능 및 필터링 개선을 위해 이벤트 기반 아키텍처를 활용하도록 Tracing/Observation 테이블 최적화. (2026-02-05, Analytics & Dashboard)
- **Bloom Filter 인덱스**: 대규모 데이터셋에서 검색 속도를 대폭 높이기 위해 user_id 및 session_id 쿼리에 Bloom Filter 인덱스 추가. (2026-02-20, Infrastructure)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **공개 Span Name 속성**: Tracing 식별을 개선하기 위해 Python SDK의 Span 인터페이스에 공개 이름 속성 추가. (2026-02-12, Integration & DX)
- **Python 스레드 검색**: Python SDK 내에서 직접 스레드 컨텍스트를 검색할 수 있는 새로운 기능. (2026-02-12, Agent & RAG Specifics)
- **Classifications 필드**: 더 풍부한 데이터 레이블링을 위해 Python SDK에 Classifications 필드 지원 도입. (2026-01-31, Core Tracing & Logging)
- **Eval 캐시 제어**: 최신 결과를 보장하기 위해 Eval 중 캐싱을 명시적으로 끌 수 있는 옵션 추가. (2026-01-29, Evaluation & Quality)
- **실험 태그**: 더 나은 조직화를 위해 실험 생성 시 태그를 전달할 수 있도록 허용. (2026-02-25, Development Lifecycle)

### [MLflow](https://mlflow.org/releases)
- **MLflow Tracking Server의 조직 지원**: 실험과 모델의 논리적 격리 및 조직화를 가능하게 하는 멀티 워크스페이스 환경 지원. (2026-02-20, Enterprise & Infrastructure)
- **MLflow Assistant**: UI 내에서 직접 문제를 식별, 진단 및 수정할 수 있도록 Claude Code 기반의 인프로덕트 챗봇 제공. (2026-01-29, Development Lifecycle)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **간결성 분류 Evaluator**: LLM 출력의 간결성을 평가하기 위한 새로운 Evaluator 추가. (2026-02-20, Evaluation & Quality)
- **AWS Bedrock 교차 리전 기본 설정**: AWS Bedrock 교차 리전 추론을 위한 모델 접두사 기본 설정 옵션. (2026-02-19, Integration & DX)
- **Evaluator 상세 정보 내 모델 표시**: Evaluator 상세 뷰에 모델 정보를 직접 추가하여 가시성 강화. (2026-02-18, Evaluation & Quality)
- **LLM Eval 프롬프트 에디터 자동 완성**: 쉬운 Eval 설정을 위해 프롬프트 에디터에 자동 완성 기능 추가. (2026-02-13, Evaluation & Quality)
- **도구 응답 처리 Evaluator**: 모델이 도구 응답을 처리하는 방식을 평가하기 위한 새로운 템플릿. (2026-02-13, Agent & RAG Specifics)

## 3. 포지셔닝 변화

| 제품 | 현재 | 향후 방향 | 신호 |
|---|---|---|---|
| W&B Weave | 프로덕션 Observability를 모델 학습 및 Fine-tuning 워크플로우와 연결하는 데 탁월한, 개발자 중심의 통합 LLM Ops 플랫폼. | 엔터프라이즈급 비용 및 성능 분석 기능을 갖춘 포괄적인 멀티모달 Eval 허브로 진화. | 고정밀 시각화 도구(Tracing 요약, 리더보드)의 빠른 출시와 텍스트 이외의 모달리티(오디오) 확장은 더 넓은 애플리케이션 지원을 향한 움직임을 나타냄. |
| LangSmith | LangChain 에코시스템 및 복잡한 에이전트형 애플리케이션을 위한 주요 Observability 및 Eval 플랫폼. | 에이전트 실행 및 신뢰성을 위한 Sandbox 환경에 집중하는 광범위한 LLMOps 인프라. | 'Sandbox' 예외 처리, 비동기 엔드포인트 및 에이전트 전용 디버깅 도구와 관련된 업데이트 빈도가 높음. |
| Langfuse | 선도적인 오픈소스 LLM 엔지니어링 플랫폼. | 엔터프라이즈급 Eval 및 라이프사이클 관리. | 최근 업데이트에서 세밀한 Eval 컨텍스트(Spans/Observations), 인프라 최적화(Bloom Filters) 및 엔터프라이즈 기능(RBAC/SSO)에 대한 대규모 투자 확인. |
| Braintrust | CI/CD 워크플로우에 깊이 내장된 엄격한 개발자 중심 Eval 및 Observability 플랫폼. | 복잡한 에이전트 아키텍처 및 엔터프라이즈급 Proxy/Gateway 요구 사항으로 지원 확대. | 최근 SDK 릴리스는 정밀한 제어(스레드, Classifications, Span 이름)와 AI Proxy와 같은 인프라 구성 요소에 집중함. |
| MLflow | 포괄적인 GenAI Tracing 및 Eval로 공격적으로 확장 중인 지배적인 오픈소스 MLOps 표준. | 엔터프라이즈급 멀티 테넌시 및 AI 지원 개발 워크플로우. | 복잡한 조직 구조로의 전환을 알리는 v3.10.0 Organization Support 출시. |
| Arize Phoenix | 복잡하고 코드 비중이 높은 LLM 에이전트 및 RAG 시스템을 구축하는 엔지니어링 팀을 위한 선도적인 오픈소스 Observability 플랫폼. | 에이전트형 Eval(도구 사용, 간결성) 지원 강화 및 프롬프트 엔지니어링을 위한 개발자 경험 개선. | 특정 에이전트형 Evaluator, 에디터 사용성(자동 완성) 및 네이티브 MCP(Model Context Protocol) 통합에 집중한 빠른 릴리스 주기(v13.0+). |

## 4. 엔터프라이즈 신호

- MLflow는 v3.10에서 Organization Support를 도입하여 대규모 엔터프라이즈 배포에 필수적인 멀티 워크스페이스 논리적 격리를 지원합니다.
- Braintrust는 모델 호출 상단에서 보안, 캐싱 및 계측을 처리하기 위한 전용 AI Proxy를 출시했습니다.
- W&B Weave는 핵심 학습 플랫폼의 컴플라이언스 표준을 반영하여 엔터프라이즈급 Audit Logs 및 RBAC를 추가했습니다.
- LangSmith는 프로덕션 환경에서 에이전트형 코드의 안정적인 실행을 지원하기 위해 새로운 예외 유형으로 Sandbox 환경을 강화했습니다.
- Langfuse는 대규모 엔터프라이즈 Tracing 데이터에 대한 쿼리 성능을 획기적으로 최적화하기 위해 Bloom Filter 인덱스를 구현했습니다.

---

## 방법론

데이터는 2026-02-25에 GitHub/PyPI 피드 및 문서 스크래핑을 통해 수집되었습니다.
카테고리 분석은 Perplexity Sonar(웹 검색 + 분석)를 사용하여 수행되었습니다. 종합 분석은 OpenRouter를 통해 google/gemini-3-pro-preview 모델을 사용하여 수행되었습니다.