---
layout: default
title: LLM Observability 시장 조사 - 2026-02-12
---

# 주간 LLM Observability 시장 조사 보고서
**날짜**: 2026-02-12 | **모델**: google/gemini-3-pro-preview | **데이터 수집일**: 2026-02-12

## 1. 요약 (Executive Summary)

- LangSmith는 온프레미스 요구 사항을 지원하기 위해 Self-Hosted v0.13을 출시했으며, 자동화된 회귀 탐지를 위한 pairwise annotation queue를 도입했습니다.
- MLflow는 멀티 워크스페이스 조직 지원으로 엔터프라이즈 기능 세트를 확장하고, MemAlign optimizer와 함께 시각적 Judge Builder를 추가했습니다.
- Langfuse는 컴플라이언스 모니터링을 강화하기 위해 Organization Audit Log Viewer를 출시했으며, 배치 데이터셋 실행을 위한 매니지드 LLM-as-a-judge 기능을 활성화했습니다.
- W&B Weave는 멀티모달 LLM-as-a-judge 워크플로우를 지원하기 위해 dynamic leaderboard와 새로운 audio monitor를 배포했습니다.
- Braintrust는 Temporal 워크플로우 및 trace-level scorer를 통한 깊은 계층적 Tracing을 지원함으로써 code-first 포지셔닝을 공고히 했습니다.
- Arize Phoenix는 에이전트 시스템에서 도구 선택 정확도와 파라미터 호출을 판단하기 위해 특별히 설계된 전문 evaluator를 도입했습니다.

**AI 시장 인사이트**:

> LangSmith와 Langfuse는 이제 에이전트 추론을 위한 전용 워크플로우 그래프 시각화를 제공합니다. 이는 메모리 및 상태 그래프에 대한 특정 뷰가 부족한 Weave의 현재 에이전트 Observability 툴킷의 공백을 부각시킵니다.
> LangSmith의 v0.13 self-hosted 버전과 Langfuse의 Audit Log Viewer 출시는 엔터프라이즈 컴플라이언스를 위한 PII 마스킹 및 감사 기능을 공개적으로 문서화해야 한다는 압박을 Weave에 가하고 있습니다.
> MLflow의 새로운 시각적 Judge Builder와 MemAlign optimizer는 Weave의 코드 중심 Eval 워크플로우에 대한 low-code 대안을 제공함으로써, Eval 통합 분야에서 Weave의 지배력에 도전하고 있습니다.


## 2. 제품 기능 비교

| 제품 | Trace Depth | Eval | 에이전트 Observability | 비용 추적 | Enterprise Ready | 종합 평가 |
|---|---|---|---|---|---|---|
| **W&B Weave** | <span title="데코레이터를 통해 중첩된 trace 트리와 실행 흐름을 자동으로 캡처합니다.">●●●</span> | <span title="멀티모달 LLM-as-a-judge를 위한 dynamic leaderboard와 새로운 audio monitor를 제공합니다.">●●●</span> | <span title="기본적인 도구 Tracing을 지원하지만 에이전트 메모리나 복잡한 상태 그래프에 대한 특정 시각화가 부족합니다.">●●○</span> | <span title="사용자 정의 뷰와 이상치에 대한 색상 설정을 통해 비용을 추적합니다.">●●●</span> | <span title="온프레미스/VPC 배포를 제공하지만 PII 마스킹 및 감사 로그에 대한 상세한 공개 문서가 부족합니다.">●●○</span> | <span title="W&B 에코시스템 내에서 실험 추적 및 Eval 통합이 뛰어난 개발자 중심 툴킷입니다.">●●●</span> |
| **LangSmith** | <span title="중간 추론 단계 및 Streaming 청크를 포함한 모든 단계에 대한 깊은 가시성을 제공합니다.">●●●</span> | <span title="회귀 탐지를 위한 pairwise annotation queue와 자동화된 evaluator를 포함합니다.">●●●</span> | <span title="다단계 추론 및 워크플로우 그래프 시각화를 통해 에이전트 워크플로우에 고도로 특화되어 있습니다.">●●●</span> | <span title="LLM, 도구, 검색에 대한 통합 비용 추적과 세부 인사이트를 제공합니다.">●●●</span> | <span title="강력한 self-hosted 버전(v0.13), RBAC 및 감사 로그를 제공합니다.">●●●</span> | <span title="Observability, Eval, 배포를 통합하는 포괄적인 플랫폼으로, 특히 LangChain 사용자에게 강력합니다.">●●●</span> |
| **Langfuse** | <span title="OpenTelemetry를 통해 중첩된 trace로 모든 LLM 및 비 LLM 호출을 캡처합니다.">●●●</span> | <span title="Dashboard에서 직접 매니지드 LLM-as-a-judge 및 배치 데이터셋 실행을 지원합니다.">●●●</span> | <span title="에이전트 그래프를 시각화하고 trace 상세 정보에서 내부 추론 단계를 렌더링합니다.">●●●</span> | <span title="사용자 정의 가격 책정 계층을 지원하는 상세한 비용 추적을 제공합니다.">●●●</span> | <span title="RBAC 및 조직 감사 로그를 갖춘 완전 오픈 소스이며 self-host 가능합니다.">●●●</span> | <span title="강력한 커뮤니티 지원과 함께 전체 엔지니어링 라이프사이클을 아우르는 선도적인 오픈 소스 솔루션입니다.">●●●</span> |
| **Braintrust** | <span title="Raw JSON 뷰 및 Temporal 워크플로우 지원을 통한 깊은 계층적 Tracing을 제공합니다.">●●●</span> | <span title="Trace-level scorer와 trace, 데이터셋, playground 간의 원활한 루프가 특징입니다.">●●●</span> | <span title="도구 호출 Tracing 및 다단계 추론 Eval을 명시적으로 지원합니다.">●●●</span> | <span title="캐시 읽기/쓰기 비용을 포함한 상세 추적을 제공합니다.">●●●</span> | <span title="Self-hosting 및 RBAC를 지원하지만 멀티 리전 지원은 덜 강조됩니다.">●●●</span> | <span title="코드 퍼스트 워크플로우와 광범위한 SDK를 갖춘 AI 엔지니어용 IDE로 포지셔닝합니다.">●●●</span> |
| **MLflow** | <span title="서비스 간 컨텍스트 전파를 통한 분산 Tracing을 지원합니다.">●●●</span> | <span title="시각적 Judge Builder, MemAlign optimizer 및 지속적인 온라인 모니터링을 포함합니다.">●●●</span> | <span title="전용 에이전트 성능 Dashboard에서 지연 시간, 도구 사용량, 오류율을 추적합니다.">●●●</span> | <span title="다양한 제공업체에 걸친 네이티브 토큰 카운팅 및 비용 추적을 지원합니다.">●●●</span> | <span title="멀티 워크스페이스 조직 지원을 도입했으며 완전히 self-host 가능합니다.">●●●</span> | <span title="풀스택 GenAI 운영 체제로 성공적으로 확장 중인 업계 표준 MLOps 플랫폼입니다.">●●●</span> |
| **Arize Phoenix** | <span title="타임라인 뷰 및 span 재생 기능이 있는 OpenTelemetry 기반 Tracing을 제공합니다.">●●●</span> | <span title="실험 중에 자동으로 실행되는 데이터셋 evaluator를 통합합니다.">●●●</span> | <span title="새로운 evaluator가 에이전트 도구 선택 정확도와 파라미터 호출을 구체적으로 판단합니다.">●●●</span> | <span title="최신 모델 지원과 함께 자동 비용 및 토큰 계산을 제공합니다.">●●●</span> | <span title="강력한 self-hosting 옵션을 제공하지만 PII 마스킹 및 감사 로그에 대한 명시적 세부 정보가 부족합니다.">●●○</span> | <span title="로컬 개발과 서버 측 Eval을 연결하는 엄격한 엔지니어링 루프에 집중합니다.">●●●</span> |

## 3. 신규 기능 (최근 30일)

### [W&B Weave](https://app.getbeamer.com/wandb/en)
- **Audio Monitors**: LLM judge를 사용하여 오디오 출력(MP3/WAV)을 관찰하고 판단하는 모니터 생성 지원. (2026-02-01, Eval 통합)
- **Dynamic Leaderboards**: 영구적인 커스터마이징 및 CSV 내보내기 기능이 있는 Eval 기반 자동 생성 리더보드. (2026-01-29, Eval 통합)
- **Playground 내 커스텀 LoRA**: W&B Artifacts의 커스텀 Fine-tuning LoRA 가중치를 Weave Playground에서 직접 사용 가능. (2026-01-16, 실험 / 개선 루프)

### [LangSmith](https://changelog.langchain.com)
- **Client Library v0.7.1**: 플랫폼 연결을 위한 Python 및 JS 클라이언트 라이브러리 업데이트. (2026-02-10, DevEx / 통합)
- **Trace 미리보기 커스터마이징**: UI에서 trace 미리보기가 표시되는 방식을 커스터마이징하는 새로운 기능. (2026-02-06, 핵심 Observability)
- **Google Gen AI Wrapper**: SDK에서 Google Gen AI 래퍼 내보내기 및 지원. (2026-01-31, DevEx / 통합)
- **Self-Hosted v0.13**: self-hosted 배포 옵션을 위한 신규 버전 출시. (2026-01-16, 엔터프라이즈 및 보안)

### [Langfuse](https://langfuse.com/changelog)
- **버전 관리된 데이터셋에서 실험 실행**: 특정 타임스탬프의 데이터셋을 가져오고 재현성을 위해 과거 버전에서 실험 실행. (2026-02-11, 실험 / 개선 루프)
- **단일 관찰 Eval**: 단일 관찰(observation)에 직접 Eval을 추가하는 기능. (2026-02-05, Eval 통합)
- **사고/추론 부분 렌더링**: trace 상세 정보에서 chain-of-thought/추론 단계 시각화. (2026-01-30, 에이전트 / RAG Observability)
- **조직 감사 로그 뷰어**: 조직 수준의 감사 로그를 확인하기 위한 UI. (2026-01-30, 엔터프라이즈 및 보안)
- **Trace에 대한 수정된 출력**: Fine-tuning 데이터셋 구축을 위해 trace 뷰에서 개선된 버전의 LLM 출력을 캡처. (2026-01-14, 실험 / 개선 루프)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **Trace-level scorers**: 커스텀 코드 scorer가 이제 전체 실행 trace에 접근하여 다단계 워크플로우 및 에이전트 동작을 평가 가능. (2026-02-01, Eval 통합)
- **LangSmith 통합**: Tracing 및 Eval 호출을 LangSmith와 Braintrust 모두에 보내거나 Braintrust로만 라우팅하는 래퍼. (2026-02-01, DevEx / 통합)
- **Cursor 통합**: MCP 서버를 통해 Cursor IDE와 통합하여 에디터에서 직접 로그를 쿼리하고 실험 결과를 가져옴. (2026-02-01, DevEx / 통합)
- **커스텀 뷰에서 첨부 파일 렌더링**: 커스텀 trace 뷰에서 이미지, 비디오, 오디오를 직접 렌더링 지원. (2026-02-01, 핵심 Observability)
- **Auto-instrumentation**: Python, Ruby, Go 애플리케이션을 위한 제로 코드 Tracing 지원. (2026-01-29, DevEx / 통합)
- **Temporal 통합**: 부모-자식 관계 매핑을 통한 Temporal 워크플로우 및 액티비티의 자동 Tracing. (2026-01-21, DevEx / 통합)
- **TrueFoundry 통합**: OpenTelemetry를 통해 TrueFoundry AI Gateway에서 LLM trace를 내보내는 통합. (2026-01-21, DevEx / 통합)
- **리뷰용 칸반 레이아웃**: 플래그가 지정된 span 및 리뷰 상태 관리를 위한 새로운 칸반 보드 뷰. (2026-01-21, Eval 통합)
- **Trace 페이지의 Loop**: 분석 및 디버깅을 위해 개별 trace 뷰에서 AI 어시스턴트 'Loop'를 직접 사용 가능. (2026-01-21, 핵심 Observability)
- **Raw Trace 데이터 보기**: 개별 span 또는 trace의 완전한 JSON 표현을 보고 검색하는 기능. (2026-01-21, 핵심 Observability)

### [MLflow](https://mlflow.org/releases)
- **조직 지원**: 실험 및 리소스를 관리하기 위한 멀티 워크스페이스 환경 지원. (2026-02-12, 엔터프라이즈 및 보안)
- **MLflow 어시스턴트**: 컨텍스트 인식을 통해 문제를 디버깅하고 해결하는 Claude Code 기반의 인제품 챗봇. (2026-01-29, DevEx / 통합)
- **에이전트 성능 Dashboard**: 지연 시간, 요청 수, 품질 점수, 도구 사용량을 모니터링하기 위한 사전 구축된 차트. (2026-01-29, 모니터링 및 메트릭)
- **MemAlign Judge Optimizer**: 피드백으로부터 Eval 가이드라인을 학습하여 judge 정확도를 향상시키는 알고리즘. (2026-01-29, Eval 통합)
- **Judge Builder UI**: 코드 없이 커스텀 LLM judge 프롬프트를 생성, 테스트 및 내보낼 수 있는 시각적 인터페이스. (2026-01-29, Eval 통합)
- **지속적인 온라인 모니터링**: 실시간 품질 평가를 위해 프로덕션의 유입 trace에 대해 LLM judge를 자동으로 실행. (2026-01-29, Eval 통합)
- **분산 Tracing**: 엔드 투 엔드 가시성을 위해 컨텍스트 전파를 통해 여러 서비스에 걸친 요청을 추적. (2026-01-29, 핵심 Observability)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **OpenAI Responses API 타입 지원**: Playground에서 Chat Completions와 Responses API 타입 중 선택 지원. (2026-02-12, DevEx / 통합)
- **데이터셋 Evaluator**: 데이터셋에 evaluator를 직접 연결하여 실험 중에 서버 측에서 자동으로 실행. (2026-02-12, Eval 통합)
- **Playground용 커스텀 제공업체**: Playground 전체에서 재사용 가능한 커스텀 AI 제공업체(OpenAI, Azure, Anthropic 등)의 중앙 집중식 구성. (2026-02-11, DevEx / 통합)
- **Claude Opus 4.6 지원**: 확장된 사고 파라미터 및 비용 추적을 포함한 Claude Opus 4.6의 Playground 지원. (2026-02-09, 핵심 Observability)
- **도구 선택 및 호출 Evaluator**: 에이전트 도구 선택 정확도와 파라미터 호출 정확성을 판단하는 전문 evaluator. (2026-01-31, 에이전트 / RAG Observability)
- **Phoenix CLI 명령**: 터미널에서 프롬프트, 데이터셋, 실험을 관리하는 새로운 CLI 명령. (2026-01-22, DevEx / 통합)
- **Span ID를 포함한 Trace의 데이터셋화**: 소스 span에 대한 양방향 링크를 유지하면서 trace를 데이터셋으로 변환. (2026-01-21, Eval 통합)
- **Trace와 함께 어노테이션 내보내기**: 수동 및 자동 어노테이션과 함께 trace를 내보내기 위한 CLI 지원. (2026-01-19, Eval 통합)
- **CLI 터미널 액세스**: AI 코딩 어시스턴트가 터미널 명령을 통해 Phoenix 데이터에 직접 쿼리할 수 있도록 지원. (2026-01-17, DevEx / 통합)

## 4. 포지셔닝 변화

| 제품 | 현재 | 향후 방향 | 신호 |
|---|---|---|---|
| W&B Weave | ML 실험 추적 워크플로우와 깊게 통합된 개발자 우선 LLM 엔지니어링 툴킷. | 멀티모달 Eval(오디오) 및 자동화된 지속적 개선 루프로 확장. | Audio Monitors 및 Dynamic Leaderboards의 출시는 복잡하고 자동화된 Eval 워크플로우에 대한 집중을 나타냄. |
| LangSmith | LangChain 에코시스템의 기본 Observability 및 Eval 플랫폼이자 일반 LLM 엔지니어링의 주요 경쟁자. | 개발, 배포, 모니터링을 통합하는 완전한 에이전트 엔지니어링 플랫폼으로 진화. | 배포를 위한 'Agent Servers' 및 디버깅을 위한 'Polly' AI 어시스턴트의 최근 출시는 단순한 수동적 Observability를 넘어선 변화를 시사함. |
| Langfuse | Observability에서 Eval까지 전체 라이프사이클을 아우르는 선도적인 오픈 소스 LLM 엔지니어링 플랫폼. | 복잡한 에이전트 워크플로우 및 엔터프라이즈 규모의 데이터 관리 지원 심화. | 에이전트 추론 시각화, 데이터셋 버전 관리, ClickHouse 통합의 최근 추가. |
| Braintrust | Eval, Observability, 데이터셋 관리를 통합하는 코드 중심 플랫폼인 'AI 엔지니어용 IDE'로 자처함. | Cursor 통합, MCP 서버, 깊은 auto-instrumentation과 같은 기능을 갖춘 AI용 완전 통합 개발 환경으로 이동. | Cursor 통합, MCP 서버 개선, 광범위한 SDK auto-instrumentation의 최근 출시. |
| MLflow | 벤더 중립적인 GenAI 스택을 제공하는 업계 표준 오픈 소스 MLOps 플랫폼. | 깊은 Observability, 지속적인 Eval, 자동화된 최적화를 통합하여 에이전트 AI의 기본 운영 체제가 됨. | v3.9.0에서 Agent Server, 분산 Tracing, MemAlign 출시. |
| Arize Phoenix | Tracing을 Eval 및 실험과 긴밀하게 결합하는 개발자 우선 오픈 소스 Observability 플랫폼. | 로컬 개발(CLI, SDK)과 서버 측 Eval(데이터셋, 실험) 사이의 간극을 메우는 AI 엔지니어를 위한 보다 통합된 에코시스템으로 이동. | 포괄적인 CLI, 데이터셋 연결 evaluator, 에이전트 도구 Eval에 대한 깊은 지원의 최근 출시가 이러한 변화를 입증함. |

## 5. 엔터프라이즈 신호

- LangSmith는 Self-Hosted v0.13을 출시하여 온프레미스 배포 옵션에 대한 수요를 강화했습니다.
- MLflow는 엔터프라이즈 리소스 및 액세스를 더 잘 관리하기 위해 멀티 워크스페이스 조직 지원을 도입했습니다.
- Langfuse는 Organization Audit Log Viewer를 추가하여 컴플라이언스 및 보안 모니터링 기능을 강화했습니다.
- Braintrust와 MLflow는 보안이 중요한 환경에 대응하여 self-hosting 및 VPC 배포를 강조했습니다.

---

## 방법론

데이터는 2026-02-12에 Serper.dev 웹 검색, 공식 문서 스크래핑, GitHub/PyPI 피드를 통해 수집되었습니다.
분석은 OpenRouter를 통해 google/gemini-3-pro-preview 모델을 사용하여 수행되었습니다.