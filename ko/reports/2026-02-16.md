---
layout: default
title: LLM Observability 시장 조사 - 2026-02-16
---

# 주간 LLM Observability 시장 조사 보고서
**날짜**: 2026-02-16 | **모델**: google/gemini-3-pro-preview | **데이터 수집일**: 2026-02-16

## 1. 요약 (Executive Summary)

- W&B Weave는 멀티모달 보이스 에이전트의 온라인 Eval을 지원하기 위해 Audio Monitors를 출시했으며, Model Context Protocol (MCP)에 대한 Tracing 지원을 추가했습니다.
- LangSmith는 독립형 Google Gen AI 및 Gemini 래퍼(wrapper)를 출시하여, 핵심 LangChain 생태계를 넘어 통합 역량을 확장했습니다.
- Langfuse는 셀프 호스팅 인스턴스의 거버넌스 강화를 위해 Organization Audit Log Viewer를 도입하고, Chain-of-Thought 추론 렌더링 기능을 추가했습니다.
- MLflow는 리소스 격리 개선을 위한 멀티 워크스페이스 환경을 지원하는 Organization Support가 포함된 버전 3.10을 출시했습니다.
- Arize Phoenix는 코드 중심 Eval 프레임워크를 강화하기 위해 도구 선택(tool selection) 및 충실도(faithfulness) 측정을 위한 전용 Eval 도구를 배포했습니다.
- Braintrust는 기존 AI Scoring 마법사를 보완하여, Tracing 내에서 human-in-the-loop 워크플로우를 정형화하기 위한 'Review' 스팬(span) 유형을 추가했습니다.

> **시장 인사이트**: Weave의 Audio Monitors 출시로 멀티모달 Tracing 분야의 차별화가 강화된 반면, Arize Phoenix의 새로운 도구 선택 Eval 도구들은 세밀한 에이전트 Eval 시장의 경쟁을 심화시키고 있습니다.


## 2. 신규 기능 (최근 30일)

### [W&B Weave](https://app.getbeamer.com/wandb/en)
- **Audio Monitors**: 온라인 Eval 모니터가 이제 오디오 입력/출력을 지원하여, LLM judge가 보이스 에이전트 대화를 평가할 수 있습니다. (2026-02-01, Evaluation & Quality)
- **Dynamic Leaderboards**: 필터링 및 커스터마이징 옵션을 갖춘 Eval 결과 기반 자동 생성 리더보드입니다. (2026-01-29, Evaluation & Quality)

### [LangSmith](https://changelog.langchain.com)
- **Trace 미리보기 커스텀**: LangSmith Dashboard UI에서 Trace 미리보기를 커스터마이징하는 기능입니다. (2026-02-06, Analytics & Dashboard)
- **Google Gen AI / Gemini 래퍼**: Python 및 JS SDK에서 Google Gen AI 및 Gemini를 위한 새로운 래퍼를 지원합니다. (2026-02-02, Integration & DX)
- **Python Async Sandbox 엔드포인트**: 샌드박스 내 Python 비동기 지원을 위한 엔드포인트가 추가되었습니다. (2026-02-05, Development Lifecycle)

### [Langfuse](https://langfuse.com/changelog)
- **Observation 기반 LLM-as-a-Judge**: 특정 Observation에서 직접 LLM-as-a-judge Eval을 실행하는 기능이 추가되었습니다. (2026-02-16, Evaluation & Quality)
- **단일 Observation Eval**: 개별 Observation에 대한 Eval 생성이 가능해졌습니다. (2026-02-10, Evaluation & Quality)
- **이벤트 기반 Trace 테이블**: Observation 및 Trace 테이블에 이벤트 중심 뷰를 도입했습니다. (2026-02-05, Core Tracing & Logging)
- **사고/추론 과정 렌더링**: Trace 상세 정보에서 사고 및 추론 과정(CoT) 렌더링 지원을 추가했습니다. (2026-02-01, Core Tracing & Logging)
- **Org Audit Log Viewer**: 조직 수준의 감사 로그를 위한 새로운 뷰어입니다. (2026-02-01, Enterprise & Infrastructure)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **Thread Retrieval API**: Python SDK에서 프로그래밍 방식으로 스레드를 가져오는 기능이 추가되었습니다. (2026-02-12, Core Tracing & Logging)
- **Review 스팬 유형**: 휴먼 리뷰 워크플로우를 지원하기 위한 새로운 'review' 스팬 유형을 도입했습니다. (2026-02-05, Evaluation & Quality)
- **OpenAI 에이전트 통합**: OpenAI 에이전트 통합을 위해 모든 스팬 유형을 처리하도록 SDK를 강화했습니다. (2026-02-05, Integration & DX)
- **Classifications 필드**: Tracing 내 분류(classifications) 필드 지원을 추가했습니다. (2026-01-31, Core Tracing & Logging)
- **Eval 캐시 제어**: Eval 중 캐싱을 끌 수 있는 옵션을 추가했습니다. (2026-01-29, Evaluation & Quality)
- **Python Trace Scoring**: Python SDK에 Trace Scoring 후보 기능을 추가했습니다. (2026-01-21, Evaluation & Quality)

### [MLflow](https://mlflow.org/releases)
- **Organization 지원**: MLflow Tracking Server에서 멀티 워크스페이스 환경을 지원하여 더 나은 리소스 조직화가 가능해졌습니다. (2026-02-12, Enterprise & Infrastructure)
- **MLflow Assistant**: 앱과 에이전트의 문제를 식별, 진단 및 수정하는 데 도움을 주는 Claude Code 기반의 인프로덕트 챗봇입니다. (2026-01-29, Integration & DX)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **LLM Eval 프롬프트 에디터 자동 완성**: LLM-as-a-judge 프롬프트 정의에 사용되는 에디터에 자동 완성 기능을 추가했습니다. (2026-02-13, Evaluation & Quality)
- **도구 응답 처리 Eval 도구**: 에이전트가 도구 응답을 어떻게 처리하는지 평가하기 위한 전용 Eval 템플릿입니다. (2026-02-13, Agent & RAG Specifics)
- **Claude Opus 4.6 지원**: 플레이그라운드 환경 내에서 Claude Opus 4.6 모델 지원을 추가했습니다. (2026-02-09, Development Lifecycle)
- **도구 선택 Eval 도구**: 에이전트 워크플로우에서 도구 선택의 정확도를 평가하기 위한 Eval 도구를 추가했습니다. (2026-02-06, Agent & RAG Specifics)
- **충실도(Faithfulness) Eval 도구**: 정확도 향상을 위해 기존의 HallucinationEvaluator를 대체하는 FaithfulnessEvaluator를 도입했습니다. (2026-02-02, Guardrails & Safety)

## 3. 포지셔닝 변화

| 제품 | 현재 | 변화 방향 | 신호 |
|---|---|---|---|
| W&B Weave | 기존 W&B 생태계를 활용하여 엄격한 코드 중심 Eval 및 Tracing을 제공하는 개발자 우선 Observability 플랫폼. | 오프라인 실험에서 포괄적인 온라인 프로덕션 모니터링 및 멀티모달 에이전트 지원으로 확장. | 최근 Audio Monitors 및 Dynamic Leaderboards 출시는 복잡한 멀티모달 프로덕션 유스케이스로의 확장을 의미함. |
| LangSmith | LangChain 생태계의 기본 Observability 및 Eval 플랫폼에서 범용 LLM DevOps 솔루션으로 확장 중. | LangChain 코어와 독립적으로 복잡한 에이전트 워크플로우 및 광범위한 모델 제공자 통합 지원 심화. | 독립형 Google/Gemini 래퍼 및 LangSmith Fetch와 같은 전문 에이전트 디버깅 도구의 최근 출시. |
| Langfuse | 심층 Tracing을 Eval 및 프롬프트 관리 워크플로우와 결합한 선도적인 오픈 소스 LLM 엔지니어링 플랫폼. | 단순 Tracing에서 통합 'LLM Ops' 스위트로 진화하며, Eval 자동화 및 엔터프라이즈 거버넌스에 집중. | 최근 릴리스에서 고급 Eval 기능(Observation 기반 LLM-as-a-judge) 및 엔터프라이즈 컴플라이언스 도구(Audit Log Viewer) 강조. |
| Braintrust | 엄격한 테스트 및 회귀 분석을 통해 AI 제품의 안정적인 배포에 집중하는 개발자 중심 Eval 및 Observability 플랫폼. | 에이전트 워크플로우 및 human-in-the-loop 리뷰 프로세스 지원 확장. | 최근 'Review' 스팬 유형 추가 및 OpenAI, Claude 에이전트를 위한 강화된 래퍼 도입. |
| MLflow | 오픈 소스 ML 라이프사이클 관리의 업계 표준에서 GenAI Observability로 공격적으로 확장 중. | 네이티브 프롬프트 관리, 에이전트 디버깅 어시스턴트, 멀티 워크스페이스 기능을 통합한 통합 GenAI 플랫폼으로 변모. | 프롬프트 관리 UI(v3.7/3.8), MLflow Assistant(v3.9), Organization Support(v3.10)의 최근 출시. |
| Arize Phoenix | RAG 및 에이전트 애플리케이션을 구축하는 개발자를 위한 선도적인 오픈 소스 코드 중심 Observability 플랫폼. | 복잡한 에이전트 Eval(도구 사용, 충실도) 지원 심화 및 개발자 실험 워크플로우 고도화. | 플레이그라운드 업데이트와 함께 도구 선택, 응답 처리, 충실도에 특화된 Eval 도구에 집중된 최근 릴리스. |

## 4. 엔터프라이즈 신호

- Langfuse는 Organization Audit Log Viewer를 도입하여 셀프 호스팅 및 엔터프라이즈 팀의 거버넌스를 강화했습니다.
- MLflow는 리소스 격리를 개선하기 위해 멀티 워크스페이스 환경을 지원하는 Organization Support(v3.10)를 출시했습니다.
- W&B Weave는 Audio Monitors를 출시하여 온라인 Eval 역량을 멀티모달 보이스 에이전트로 확장했습니다.
- Braintrust는 Tracing 내에서 human-in-the-loop 리뷰 워크플로우를 정형화하기 위해 'Review' 스팬 유형을 추가했습니다.
- LangSmith는 독립형 Google Gen AI 및 Gemini 래퍼를 출시하여 LangChain 이외의 엔터프라이즈 통합 범위를 넓혔습니다.

---

## 방법론

데이터는 2026-02-16에 GitHub/PyPI 피드 및 문서 스크래핑을 통해 수집되었습니다.
카테고리 분석은 Perplexity Sonar(웹 검색 + 분석)를 사용하여 수행되었습니다. 종합 분석은 OpenRouter를 통해 google/gemini-3-pro-preview 모델을 사용하여 수행되었습니다.