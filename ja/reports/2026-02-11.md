---
layout: default
title: 競合インテリジェンスレポート - 2026-02-11
---

# W&B Weave — 週刊競合インテリジェンスレポート
**日付**: 2026-02-11 | **モデル**: google/gemini-3-pro-preview | **データ収集日**: 2026-02-11

[詳細比較](../comparison) · [製品詳細](../competitor-detail)

## 1. エグゼクティブサマリー

- Weave は、2月1日の **Audio Monitors** のリリースにより、マルチモーダル評価における先行者利益を確立しました。一方で **LangSmith** や **Braintrust** は、依然として主にテキストに焦点を当てています。
- 1月29日にローンチされた **Dynamic Leaderboards** は、モデル比較のための優れた自動更新ビジュアライゼーションを提供することで、**MLflow** の新しい「Judge Builder」に対抗しています。ただし、MLflow の「MemAlign」は、評価者（Judge）の改善においてより深い自動化を提供しています。
- **Weave** の Playground における **Custom LoRAs** サポート（1月16日）は、トレーニング（W&B）と推論を接続する独自のポジションを強化しました。これは、トレーニングインフラを持たない **Langfuse** や **Braintrust** には真似できない機能です。
- **Weave** がバックエンドのトレース機能を改善する一方で、**LangSmith** (LangGraph Studio) や **Arize Phoenix** (Tool Selection Evaluators) は、エージェントワークフロー向けの視覚的デバッグや特定のメトリクスの進化において、より速いペースで進んでいます。
- **Braintrust** は SDK サポート（Go, Java, C#, Ruby）を積極的に拡大しており、Python/JS 以外のエンタープライズ環境における **Weave** の採用を脅かしています。
- **LangSmith**、**Langfuse**、**Braintrust** はいずれも、構造化された人間によるレビューのための成熟した「Annotation Queues（アノテーションキュー）」を備えています。**Weave** には、大規模な手動ラベル付けのための同等の専用ワークフローが不足しています。

> **一行判定**: Weave はマルチモーダル評価とトレーニングから推論への統合においてリードしていますが、視覚的なエージェントデバッグでは LangSmith から、エンタープライズ言語サポートでは Braintrust からの圧力が増しています。

### Weave の主な強み

- マルチモーダル評価: Audio Monitors (MP3/WAV) のネイティブサポートにより、音声エージェントの評価が可能です。これは現在、ほとんどの競合他社に欠けている機能です。
- トレーニングから推論へのリネージ: W&B Artifacts からの Custom LoRAs を Weave Playground にシームレスに統合し、即座にテストできます。
- プログラマブルなレポート機能: Dynamic Leaderboards は、自動更新され高度にカスタマイズ可能なビューを提供し、Langfuse や Braintrust の静的なダッシュボードを凌駕します。
- データ探索: 「Boards」は、MLflow の硬直的なダッシュボードよりも強力で、アドホックな分析のための柔軟なキャンバスを提供します。

### Weave の改善が必要な領域

- 視覚的なエージェントデバッグ: LangSmith の LangGraph Studio や Langfuse の Agent Graphs に匹敵する、エージェントトポロジーのための専用のインタラクティブなグラフビューが不足しています。
- 構造化されたアノテーションワークフロー: 大規模な人間によるラベル付けチームを管理するための専用の「Annotation Queue」機能がありません。これは LangSmith や Braintrust の核心的な強みです。
- SDK エコシステム: Python/TypeScript に限定されています。一方、Braintrust や MLflow は Java、Go、C# をサポートしており、より幅広いエンタープライズ採用を可能にしています。
- 評価者（Judge）の最適化: 評価者のプロンプトを自動的に改善する MLflow の MemAlign のような自動「Judge Optimizer」機能が不足しています。

## 2. ベンダー機能比較

| ベンダー | トレースの深さ | 評価 (Eval) | エージェント観測性 | コスト追跡 | エンタープライズ対応 | 総合評価 |
|---|---|---|---|---|---|---|
| **Weave** | ●●● | ●●● | ●●○ | ●●● | ●●● | ●●● |
| **LangSmith** | ●●● | ●●● | ●●● | ●●● | ●●● | ●●● |
| **Langfuse** | ●●● | ●●● | ●●● | ●●● | ●●● | ●●● |
| **Braintrust** | ●●● | ●●● | ●●○ | ●●● | ●●● | ●●● |
| **MLflow** | ●●● | ●●● | ●●● | ●●● | ●●● | ●●● |
| **Arize Phoenix** | ●●● | ●●● | ●●● | ●●● | ●●○ | ●●○ |

## 3. 新機能 (過去30日間)

### [Weave](https://app.getbeamer.com/wandb/en)
- **Audio Monitors**: テキストと並んで音声の入出力 (MP3/WAV) を監視・判定するモニターの作成をサポート。(2026-02-01, コア観測性)
- **Dynamic Leaderboards**: 評価から自動生成され、新しい実行が到着すると即座に更新されるカスタマイズ可能なリーダーボード。(2026-01-29, 評価統合)
- **Custom LoRAs in Playground**: W&B Artifacts からファインチューニングされた LoRA 重みを直接 Weave Playground にロードして推論する機能。(2026-01-16, 実験 / 改善ループ)

### [LangSmith](https://changelog.langchain.com)
- **Client Library v0.7.1**: 安定性の向上と OIDC サポートのための Python/JS クライアントライブラリのアップデート。(2026-02-10, DevEx / 統合)
- **Customize Trace Previews**: トレースリストビューで表示する列やデータをユーザーがカスタマイズできる UI アップデート。(2026-02-06, コア観測性)
- **Self-Hosted v0.13**: エンタープライズ導入向けのセルフホスト型インフラコンポーネントの新バージョン。(2026-01-16, エンタープライズ & セキュリティ)

### [Langfuse](https://langfuse.com/changelog)
- **Corrected Outputs for Traces**: トレースビューで LLM 出力の修正版を直接キャプチャし、ファインチューニング用データセットを構築。(2026-01-14, コア観測性)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **Trace-level Scorers**: カスタムコードスコアラーが実行トレース全体にアクセスし、マルチステップのワークフローやエージェントの動作を評価可能に。(2026-02, 評価統合)
- **Navigate to Trace Origins**: 本番環境のトレースから、元のプロンプトバージョンやデータセットの行へ直接移動。(2026-02, コア観測性)
- **LangSmith Integration**: トレースを LangSmith と Braintrust の両方にルーティング、またはトラフィックを Braintrust に移行するためのラッパー。(2026-02, DevEx / 統合)
- **Auto-instrumentation (Python/Ruby/Go)**: Python、Ruby、Go SDK における主要プロバイダー向けのゼロコードトレース。(2026-01, DevEx / 統合)
- **Temporal Integration**: 耐久性のあるエージェント実行のための Temporal ワークフローとアクティビティの自動トレース。(2026-01, DevEx / 統合)

### [MLflow](https://mlflow.org/releases)
- **MLflow Assistant**: エラーのデバッグやコード生成を支援する、AI 搭載の製品内チャットボット (Claude Code を採用)。(2026-01-29, DevEx / 統合)
- **Agent Performance Dashboards**: レイテンシ、リクエスト数、ツール使用状況のサマリーを可視化するプリセットの「Overview」タブ。(2026-01-29, モニタリング & メトリクス)
- **MemAlign Judge Optimizer**: フィードバックから学習し、LLM 評価者のプロンプトを自動的に最適化するアルゴリズム。(2026-01-29, 評価統合)
- **Judge Builder UI**: コードなしでカスタム LLM 評価者を作成、テスト、検証するためのビジュアルインターフェース。(2026-01-29, 評価統合)
- **Continuous Online Monitoring**: 入ってくる本番トレースに対して LLM 評価者を自動的に実行。(2026-01-29, モニタリング & メトリクス)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **Claude Opus 4.6 Support**: 自動コスト追跡と「thinking」パラメータをサポートした Anthropic の最新モデルへの対応。(2026-02-09, コア観測性)
- **Tool Selection & Invocation Evaluators**: エージェントが適切なツールを選択したか、正しいパラメータで呼び出したかを判定する新しい専用評価者。(2026-01-31, エージェント / RAG 観測性)
- **Configurable OAuth2 Email Extraction**: 非標準の IDP クレーム (Azure AD など) からユーザー ID を抽出するためのカスタム JMESPath 式のサポート。(2026-01-28, エンタープライズ & セキュリティ)
- **CLI for Prompts & Datasets**: ターミナルからプロンプト、データセット、実験を直接管理し、AI アシスタント統合を可能にする包括的な CLI コマンド。(2026-01-22, DevEx / 統合)
- **Trace-to-Dataset with Span Links**: リネージのためにソーススパンへの双方向リンクを維持したまま、トレースからデータセットを作成する機能。(2026-01-21, 評価統合)

## 4. ポジショニングの変化

| ベンダー | 現在 | 今後の方向性 | シグナル |
|---|---|---|---|
| **Weave** | W&B エコシステムを既に利用している ML エンジニアに好まれる観測ツール。深いモデル検査と実験に焦点を当てている。 | 研究（トレーニング/ファインチューニング）と本番エージェントのギャップを埋める、マルチモーダルで包括的な AI 評価プラットフォーム。 | 「Audio Monitors」と「Custom LoRAs」のリリースは、本番のモダリティとアーティファクトを実験フェーズに明示的に結びつけている。 |
| LangSmith | LangChain や LangGraph で構築するチームにとっての、デフォルトで高度に統合された観測スタック。 | 単なる観測を超え、デプロイ、テスト、プロンプト管理を網羅する完全な「AI エンジニアリングプラットフォーム」。 | 最近の「LangGraph Platform」（デプロイ）と「Annotation Queues」への注力は、フルライフサイクル管理への移行を示唆している。 |
| Langfuse | データの完全な主権と完全なエンジニアリングスイートを必要とするチームのための、主要なオープンソースの選択肢。 | ClickHouse を活用した分析と高度なエージェント観測性により、エンタープライズの本番ワークロードへスケール。 | 最近の ClickHouse への移行、「Agent Graphs」および「Annotation Queues」のリリースは、規模と複雑なワークフローへの注力を示している。 |
| Braintrust | 独自のプロキシベースのアーキテクチャを持つ、エンタープライズグレードの AI 観測および評価プラットフォーム。 | 言語サポート (Java/Go/C#) の拡大とエージェント評価機能の深化により、ユニバーサルな「AI オペレーティングシステム」を目指す。 | 2ヶ月間で4つの新しい SDK をリリースし、複雑なエージェント評価のための「Trace-level scorers」を導入。 |
| MLflow | MLOps の「標準ライブラリ」。現在は特化型の観測ツールに匹敵する、機能の揃った GenAI スタックを提供。 | 評価ループの自動化 (MemAlign) とエージェントデバッグの簡素化 (Assistant) により、GenAI エンジニアリングのデフォルト OS に。 | 「MemAlign」と「Judge Builder」を含む v3.9 のリリースは、単なるメトリクス追跡から、ユーザーがモデル品質を積極的に向上させるのを支援する方向への転換を示している。 |
| Arize Phoenix | OpenTelemetry とローカルファーストのワークフローを優先する開発者にとっての、事実上のオープンソース標準。 | エージェントワークフロー（ツール評価）の機能深化と、ターミナルベースの開発者エクスペリエンスの向上。 | 2026年1月に Tool Selection 評価者と、ターミナルベース管理のための豊富な CLI を同時にリリース。 |

## 5. エンタープライズシグナル

- Braintrust の積極的な SDK 拡大 (Java/Go/C#) は、レガシーなエンタープライズスタックをターゲットにしています。
- MLflow の「Judge Builder」と「MemAlign」は、深いプロンプトエンジニアリングのスキルを欠くエンタープライズチームの障壁を下げます。
- Langfuse の ClickHouse への移行は、大規模なエンタープライズデータの取り込みをサポートする動きを示しています。

---

## 調査手法

データは 2026-02-11 に Serper.dev ウェブ検索、公式ドキュメントのスクレイピング、および GitHub/PyPI フィードを通じて収集されました。
分析は OpenRouter 経由で google/gemini-3-pro-preview モデルを使用して行われました。