---
layout: default
title: LLM Observability 市場調査 - 2026-02-13
---

# Weekly LLM Observability 市場調査レポート
**日付**: 2026-02-13 | **モデル**: google/gemini-3-pro-preview | **収集データ**: 2026-02-13

## 1. エグゼクティブ・サマリー

- Langfuse は、推論ステップを可視化するための「thinking」Tracing のレンダリング・サポートを導入しました。一方、Arize Phoenix は、エージェント・ワークフローにおけるツール選択と Faithfulness（誠実性）を評価するための専用メトリクスをリリースしました。
- MLflow はバージョン 3.10 をローンチし、大規模なエンタープライズ環境内でのマルチワークスペース管理とアクセス制御を可能にする Organization Support を導入しました。
- LangSmith は Self-Hosted v0.13 をリリースし、Streaming サポートとエージェント実行グラフの可視化を維持しつつ、オンプレミス展開のインフラ安定性を向上させました。
- Braintrust は、既存の「Loop」AI Eval アシスタントに加え、ヒューマン・イン・ザ・ループの品質管理ワークフローを構造化するための専用の「Review」スパンタイプを追加しました。
- W&B Weave は、VPC オプションにおける SOC 2 Type II および HIPAA への準拠を確認し、ネイティブな Model Context Protocol (MCP) 統合によってエージェントの Observability 機能を差別化しました。

> **マーケット・インサイト**: Arize Phoenix による特化型エージェント・メトリクスのリリースと、Langfuse による「thinking」トレース・サポートは、Weave のエージェント Observability の深みに直接挑戦するものです。技術的な差別化を維持するためには、Weave 独自の Model Context Protocol (MCP) 統合を引き続き活用する必要があります。


## 2. 新機能 (直近 30 日間)

### [W&B Weave](https://app.getbeamer.com/wandb/en)
- **Audio Monitors**: テキストと並行して音声出力を監視・判定するモニターを作成し、ボイスエージェントの Eval を可能にしました。(2026-02-01, Evaluation & Quality)
- **Dynamic Leaderboards**: 手動設定に代わり、フィルタリングやカスタマイズが可能な Eval 結果からのリーダーボード自動生成機能。(2026-01-29, Evaluation & Quality)
- **Custom LoRAs in Playground**: Weave Playground 内で直接、カスタム Fine-tuning された LoRA 重みのテストと Eval をサポート。(2026-01-16, Development Lifecycle)

### [LangSmith](https://changelog.langchain.com)
- **Customize trace previews**: LangSmith UI での Tracing プレビュー方法をカスタマイズする機能。(2026-02-06, Core Tracing & Logging)
- **Non-otel Google ADK wrapper**: OpenTelemetry への依存なしで Google ADK 統合を可能にする新しいラッパー。(2026-02-02, Integration & DX)
- **Google Gen AI wrapper**: Google Generative AI 統合用のエクスポート済みラッパー。(2026-01-31, Integration & DX)
- **Gemini TS wrapper**: Gemini モデル用のベータ版 TypeScript ラッパー。(2026-01-26, Integration & DX)
- **LangSmith Self-Hosted v0.13**: プラットフォームのセルフホスト版のアップデート。(2026-01-16, Enterprise & Infrastructure)

### [Langfuse](https://langfuse.com/changelog)
- **LLM-as-a-Judge on Observations**: よりきめ細かい品質管理のために、特定の Observation に対して直接 LLM-as-a-judge Eval を実行するサポートを追加。(2026-02-13, Evaluation & Quality)
- **Thinking/Reasoning Trace Rendering**: DeepSeek のような Chain-of-Thought モデルをサポートする、「thinking」および「reasoning」部分の新しいトレース詳細レンダリング。(2026-02-05, Core Tracing & Logging)
- **Inline Trace Comments**: Tracing 内の IO データの一部に対してインラインでコメントを追加できるようにし、コラボレーションを改善。(2026-01-25, Integration & DX)
- **Single Observation Evals**: フル Tracing だけでなく、単一の Observation に対して Eval を実行可能に。(2026-02-08, Evaluation & Quality)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **Thread Retrieval API**: Python SDK でプログラムによってスレッドを取得する機能を追加。(2026-02-12, Integration & DX)
- **Sub-agent Nesting**: Claude Agent SDK ラッパーにおけるサブエージェントのネスト・サポートを追加。(2026-02-12, Agent & RAG Specifics)
- **Review Span Type**: 人間によるレビュー・ワークフローをサポートするための特定の「Review」スパンタイプを導入。(2026-02-05, Evaluation & Quality)
- **Classifications Field**: メタデータ・タギングを強化するため、SDK に classifications フィールドを追加。(2026-01-31, Core Tracing & Logging)
- **Trace Scoring Candidate**: Python SDK 内で直接 Tracing を Scoring するための新機能。(2026-01-21, Evaluation & Quality)

### [MLflow](https://mlflow.org/releases)
- **Organization Support**: 異なるワークスペース間で実験やリソースを整理できる、マルチワークスペース環境のサポート。(2026-02-12, Enterprise & Infrastructure)
- **MLflow Assistant**: UI 内で直接問題を特定、診断、修正するのを支援する、Claude Code をバックエンドとした製品内チャットボット。(2026-01-29, Integration & DX)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **Claude Opus 4.6 Support**: Playground における Claude Opus 4.6 モデルのサポートを追加。(2026-02-09, Development Lifecycle)
- **Tool Selection Evaluator**: エージェント・ワークフローにおけるツール選択の品質を評価するための新しい Eval を追加。(2026-02-06, Evaluation & Quality)
- **Faithfulness Evaluator**: Groundedness（根拠性）を確認するための FaithfulnessEvaluator を導入（HallucinationEvaluator は非推奨化）。(2026-02-02, Evaluation & Quality)
- **Tool Invocation Accuracy Metric**: ツール呼び出しの正確性を追跡するための新しいメトリクス。(2026-02-02, Evaluation & Quality)
- **Configurable Email Extraction**: OAuth2 における設定可能なメール抽出のための EMAIL_ATTRIBUTE_PATH を追加。(2026-01-28, Enterprise & Infrastructure)
- **Cursor Rule for Metrics**: 新しい組み込みメトリクス（LLM 分類 Eval）を作成するための Cursor ルールを追加。(2026-01-21, Evaluation & Quality)

## 3. ポジショニングの変化

| 製品 | 現状 | 今後の方向性 | シグナル |
|---|---|---|---|
| W&B Weave | 複雑なエージェント・システムを構築する開発者向けの、コードファーストで厳格な Eval および Observability プラットフォーム。 | マルチモーダル・サポートを拡大し、オフラインの実験とオンラインの本番環境モニタリングのギャップを埋める。 | Audio Monitors と Dynamic Leaderboards の最近のリリースは、モダリティを越えた包括的で自動化された Eval への注力を強化している。 |
| LangSmith | LangChain エコシステムおよび複雑なエージェント・アプリケーションのための決定的な Observability および Eval プラットフォーム。 | LangChain を超えて、より広範なモデル・サポート (Google/Gemini) と強化されたエンタープライズ・セルフホスティングを備えたユニバーサルな LLM DevOps プラットフォームを目指す。 | 非依存の Google Gen AI ラッパーの最近のリリースと、セルフホスト・エンタープライズ版の継続的なアップデート。 |
| Langfuse | 強力なフレームワーク統合とセルフホスティング機能で好まれる、開発者中心のオープンソース Observability および Eval プラットフォーム。 | Eval の粒度を深め、高度なエージェント・ワークフローに対応するために複雑な推論モデル (CoT) をサポートする。 | 「thinking」トレース・レンダリングと粒度の細かい「Observation レベル」の Eval に焦点を当てた最近のアップデート。 |
| Braintrust | エンタープライズ・エンジニアリング・チーム向けの最高の「Eval 中心」開発プラットフォームとして位置づけ。 | 複雑なエージェント・ワークフローとヒューマン・イン・ザ・ループのレビュー・プロセスのサポートを深めている。 | サブエージェントのネスト、Thread Retrieval API、および専用の「Review」スパンタイプを追加した最近のアップデート。 |
| MLflow | MLOps のオープンソース標準であり、現在は GenAI の Tracing と Eval のための競争力のある統合スイートを提供。 | マルチワークスペース・サポートによるエンタープライズ対応の深化と、AI 支援デバッグによる開発者体験の向上。 | 2026 年初頭の Organization Support (v3.10) と MLflow Assistant (v3.9) のリリース。 |
| Arize Phoenix | 複雑な RAG やエージェント・アプリケーションを構築する AI エンジニア向けの、最高のオープンソースかつコードファーストな Observability プラットフォーム。 | エージェントとツールのための、より深く専門化された Eval 機能へと移行し、非技術的な CMS ではなく技術的なワークベンチとしての役割を強化。 | ツール選択、Faithfulness、ツール呼び出しの正確性のための専用 Eval の最近のリリースは、複雑なエージェントの信頼性課題の解決に明確に焦点を当てていることを示している。 |

## 4. エンタープライズ・シグナル

- MLflow は、大規模チーム向けのマルチワークスペース管理を可能にする Organization Support (v3.10) を導入しました。
- LangSmith は Self-Hosted v0.13 をリリースし、オンプレミス・エンタープライズの安定性へのコミットメントを強化しました。
- Braintrust は、エンタープライズの品質管理のためのヒューマン・イン・ザ・ループ・ワークフローを形式化するために、特定の「Review」スパンタイプを追加しました。
- W&B Weave は、VPC 展開オプションとともに SOC 2 Type II、HIPAA、および GDPR への準拠を確認しました。
- Langfuse は、完全なデータ主権を必要とする企業向けに、完全にセルフホスト可能な MIT ライセンス版の提供を継続しています。

---

## 調査手法

データは 2026-02-13 に GitHub/PyPI フィードおよびドキュメントのスクレイピングを通じて収集されました。
カテゴリ分析は Perplexity Sonar (ウェブ検索 + 分析) を使用して実施されました。統合・要約は OpenRouter 経由で google/gemini-3-pro-preview モデルを使用して行われました。