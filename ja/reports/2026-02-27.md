---
layout: default
title: LLM Observability 市場調査 - 2026-02-27
---

# 週刊 LLM Observability 市場調査レポート
**日付**: 2026-02-27 | **モデル**: google/gemini-3.1-pro-preview

## 1. AI コメント

### 製品ハイライト

- **LangSmith**: LangChain および LangGraph ワークフローにネイティブ対応した、卓越したエコシステム統合と詳細な実行 Tracing を提供し続けており、強力なエンタープライズ向けデプロイオプションを誇ります。
- **Arize Phoenix**: 直感的な Prompt サンドボックスと多様な LLM-as-a-judge フレームワークを通じて、生成 AI のトラッキングと Eval パイプラインを最適化する、強力な OpenTelemetry ネイティブソリューションです。
- **Langfuse**: 今週、Versioned Datasets を導入することで堅牢な Eval ツールキットを拡張しました。高度にスケーラブルなオープンソースの基盤を維持しつつ、テストの再現性を向上させています。
- **Braintrust**: 今週、ログの自動フィルタリングとグループ化を行う AI 駆動の Topic Maps を追加し、運用上の可視性を強化しました。コードファーストなエンタープライズ向け Eval エンジンを補完する機能です。
- **W&B Weave**: 包括的なマルチモーダルサポートを提供し、Weights & Biases の ML レジストリとシームレスに結合された、深く統合された実験のロールバック機能を提供します。
- **MLflow**: 今週、大規模なアップデートをリリースしました。Distributed Tracing、新しい Judge Builder UI、MemAlign Optimizer、Multi-Workspace Support、および Agent Performance Dashboards をネイティブに導入しました。

### 市場トレンド

市場は、特化型の Agent フロー Tracing とスケーラブルなノーコード Eval ビルダーへと急速にシフトしています。各プラットフォームは、自動化された AI 駆動の Judge 最適化と、標準化された OpenTelemetry アーキテクチャを積極的に採用しています。

## 2. 最近のアップデート

### [Langfuse](https://langfuse.com/changelog)
- **Langfuse CLI** (2026年2月17日) — CLI から Langfuse をフル活用可能に。AI Agent およびパワーユーザー向けに構築。
- **個別オペレーションの評価: より高速で精密な LLM-as-a-Judge** (2026年2月13日) — Observation レベルの Eval により、本番環境のモニタリングにおいて特定のオペレーションに対する精密な Scoring が可能になりました。
- **Versioned Datasets での実験実行** (2026年2月11日) — 特定のバージョンのタイムスタンプでデータセットを取得し、UI、API、SDK を通じて過去のデータセットバージョンで実験を実行できるようになり、完全な再現性を実現しました。

### [Braintrust](https://braintrust.dev/docs/changelog)
- **自動ログインサイトのための Topics** (2026年2月) — Topics は、手動での確認なしにパターンやインサイトを抽出するために、ログを自動的に分析・分類します。プリプロセッサ（Trace データの変換）と AI Prompt（サマリーの抽出）を組み合わせた Topic Maps を作成してログを分析できます。サマリーは機械学習を使用して意味のあるトピックにクラスタリングされ、新規および既存の Trace を自動的に分類するために使用されます。組み込みの Topic Maps には、Task（ユーザーの意図）、Sentiment（感情的なトーン）、Issues（Agent の問題）が含まれます。カスタム Topic Maps により、ドメイン固有の分析も可能です。Topics は Pro および Enterprise プランでベータ版として提供されています。

### [MLflow](https://mlflow.org/releases)
- **MLflow 3.10.0 リリース: Multi-Workspace Support、Multi-Turn Evaluation、および UI 強化** (2026年2月23日) — MLflow 3.10.0 では、単一のトラッキングサーバー内で実験やモデルをより粗い粒度で整理するための Multi-workspace support が導入されました。新しい Multi-turn Eval と会話シミュレーション機能により、個々のレスポンスではなく会話全体を Scoring できるようになり、チャットボットのワークフローにおける不完全な回答やコンテキストの喪失を検出できます。Trace のコストトラッキング機能は、モデル情報を自動的に抽出し、UI 上の可視化とともに LLM の支出を計算します。ナビゲーションバーは、機能の発見性を高めるために新しいサイドバーを備えたデザインに刷新されました。AI Gateway エンドポイントを詳細な分析で監視するための Gateway 使用状況トラッキングが追加されました。UI 内での Trace Eval により、コードなしで Trace から直接カスタムまたはプリセットの LLM Judge を実行できます。Tracing、Eval、Prompt 管理をワンクリックで試せる MLflow デモ実験が追加されました。
- **MLflow 3.9.0 リリース: AI Assistant、Agent Performance Dashboards、Judge Optimization、および継続的モニタリング** (2026年1月30日) — MLflow 3.9.0 は AI Observability と Eval に焦点を当てており、ローカルのコードベースを理解し LLMOps のベストプラクティスに基づいたコンテキスト豊かな推奨事項を提供する Claude Code 搭載の MLflow Assistant が含まれています。新しい「Overview」タブでは、レイテンシ、リクエスト数、品質スコア、ツール呼び出しのサマリーなどの Agent パフォーマンスメトリクス用のプリセット Dashboard が提供されます。LLM-as-a-Judge の Eval 品質を向上させるための MemAlign Judge Optimizer アルゴリズムが導入されました。Judge builder UI により、カスタム評価器の作成が可能になります。LLM Judge による継続的モニタリングにより、本番環境の Trace を自動評価できます。複雑なマルチステップの AI ワークフロー向けに Distributed Tracing サポートが追加されました。

## 3. 機能比較 (要約)

> O(強力) / △(中程度) / X(なし)

| カテゴリ | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| コア Tracing & Logging | O (7/8) | O (8/8) | O (7/8) | △ (4/8) |
| Agent & RAG 特化機能 | O (5/7) | △ (4/7) | △ (3/7) | △ (4/7) |
| Eval & 品質管理 | O (5/8) | O (7/8) | O (6/8) | △ (4/8) |
| Guardrails & 安全性 | △ (1/4) | X (0/4) | O (4/4) | △ (2/4) |
| Analytics & Dashboard | O (5/6) | O (4/6) | O (5/6) | O (4/6) |
| 開発ライフサイクル | O (4/5) | O (4/5) | O (5/5) | △ (2/5) |
| 統合 & DX | O (3/5) | O (4/5) | O (3/5) | △ (2/5) |
| エンタープライズ & インフラ | O (6/6) | △ (2/6) | O (6/6) | △ (3/6) |

## 4. 詳細機能比較

> O(強力) / △(中程度) / X(なし)

### コア Tracing & Logging

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| 完全な Request/Response Tracing | O | O | O | O |
| ネストされた Span & ツリー表示 | O | O | O | △ |
| Streaming サポート | △ | O | △ | X |
| マルチモーダル Tracing | O | O | O | △ |
| Auto-Instrumentation | O | O | O | O |
| メタデータ & タグフィルタリング | O | O | O | O |
| トークンカウント & 推定 | O | O | O | △ |
| OpenTelemetry 標準 | O | O | O | O |

### Agent & RAG 特化機能

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| RAG Retrieval Visualizer | △ | △ | X | △ |
| Tool/Function Call レンダリング | O | O | O | O |
| Agent 実行グラフ | O | △ | △ | X |
| 中間ステップの状態保持 | O | O | O | O |
| Session/Thread リプレイ | O | △ | X | O |
| 失敗ステップのハイライト | △ | O | △ | △ |
| MCP 統合 | O | O | O | O |

### Eval & 品質管理

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| LLM-as-a-Judge ウィザード | △ | O | O | O |
| カスタム Eval Scorers | O | O | O | O |
| データセット管理 & キュレーション | O | O | O | △ |
| Prompt 最適化 / DSPy サポート | △ | O | X | O |
| 回帰テスト | O | O | O | △ |
| 比較表示 (Side-by-side) | △ | O | O | X |
| アノテーションキュー | O | △ | △ | X |
| オンライン Eval | O | O | O | O |

### Guardrails & 安全性

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| PII/機密データのマスキング | O | △ | O | O |
| ハルシネーション検出 | X | △ | O | O |
| トピック/ジェイルブレイク Guardrails | △ | △ | O | X |
| Policy Management as Code | X | X | O | △ |

### Analytics & Dashboard

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| コスト分析 & 属性付与 | O | O | O | O |
| トークン使用量 Analytics | O | O | O | O |
| レイテンシヒートマップ & P99 | O | △ | O | △ |
| エラー率モニタリング | O | O | O | O |
| Embedding 空間の可視化 | X | X | X | X |
| カスタムメトリクス & Dashboard | O | O | O | O |

### 開発ライフサイクル

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| Prompt 管理 (CMS) | O | O | O | △ |
| Playground & サンドボックス | O | O | O | X |
| 実験トラッキング | O | O | O | O |
| Fine-tuning 統合 | X | X | O | △ |
| バージョン管理 & ロールバック | O | O | O | O |

### 統合 & DX

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| SDK サポート (Py/JS/Go) | O | △ | △ | △ |
| Gateway/Proxy モード | △ | O | X | O |
| 主要フレームワーク対応 | O | O | O | O |
| API & Webhooks | O | O | O | △ |
| CI/CD 統合 | △ | O | O | △ |

### エンタープライズ & インフラ

| 機能 | Langfuse | Braintrust | W&B Weave | MLflow |
|---|---|---|---|---|
| デプロイオプション | O | △ | O | O |
| オープンソース | O | △ | O | O |
| データ主権 & コンプライアンス | O | △ | O | △ |
| RBAC & SSO | O | O | O | X |
| 監査ログ | O | △ | O | X |
| データウェアハウスへのエクスポート | O | O | O | O |

---

## 調査手法

データは3つの Agent パイプラインを介して収集されました。UpdateCollector (Perplexity Sonar) が変更ログとウェブ検索を担当し、BaselineAnalyzer (Gemini Pro) がベースラインの比較と更新を行い、ReportWriter (Gemini Pro) が製品間の比較とコメントを作成しました。