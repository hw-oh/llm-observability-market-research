---
layout: default
title: LLM Observability 市場調査 - 2026-02-16
---

# 週刊 LLM Observability 市場調査レポート
**日付**: 2026-02-16 | **モデル**: google/gemini-3-pro-preview | **データ収集日**: 2026-02-16

## 1. エグゼクティブ・サマリー

- W&B Weave は、マルチモーダルな音声エージェントのオンライン Eval をサポートする Audio Monitors をリリースし、Model Context Protocol (MCP) の Tracing サポートを追加しました。
- LangSmith は、スタンドアロンの Google Gen AI および Gemini ラッパーをリリースし、コアとなる LangChain エコシステムを超えて統合機能を拡張しました。
- Langfuse は、セルフホストインスタンスのガバナンスを強化するために Organization Audit Log Viewer を導入し、Chain-of-Thought 推論のレンダリング機能を追加しました。
- MLflow は、リソースの分離を改善するためのマルチワークスペース環境を可能にする Organization Support を含むバージョン 3.10 をリリースしました。
- Arize Phoenix は、コードファーストの Eval フレームワークを強化するため、ツール選択と Faithfulness（誠実性）に特化した Evaluator をデプロイしました。
- Braintrust は、既存の AI Scorer ウィザードを補完するものとして、Trace 内でヒューマン・イン・ザ・ループのワークフローを形式化するための「Review」スパンタイプを追加しました。

> **マーケットインサイト**: Weave による Audio Monitors のリリースは、マルチモーダル Tracing における差別化を強化しています。一方、Arize Phoenix の新しいツール選択 Evaluator は、きめ細かなエージェント Eval における競争を激化させています。


## 2. 新機能 (直近30日間)

### [W&B Weave](https://app.getbeamer.com/wandb/en)
- **Audio Monitors**: オンライン Eval モニターが音声の入力/出力をサポートし、LLM Judge が音声エージェントの会話を評価できるようになりました。(2026-02-01, Evaluation & Quality)
- **Dynamic Leaderboards**: フィルタリングおよびカスタマイズオプションを備えた、Eval 結果からのリーダーボード自動生成機能。(2026-01-29, Evaluation & Quality)

### [LangSmith](https://changelog.langchain.com)
- **Trace プレビューのカスタマイズ**: LangSmith UI で Trace プレビューをカスタマイズする機能。(2026-02-06, Analytics & Dashboard)
- **Google Gen AI / Gemini ラッパー**: Python および JS SDK における Google Gen AI と Gemini 用の新しいラッパー。(2026-02-02, Integration & DX)
- **Python Async Sandbox エンドポイント**: Sandbox 内での Python 非同期サポート用エンドポイントの追加。(2026-02-05, Development Lifecycle)

### [Langfuse](https://langfuse.com/changelog)
- **Observation に対する LLM-as-a-Judge**: 特定の Observation に対して直接 LLM-as-a-judge Eval を実行する機能を追加。(2026-02-16, Evaluation & Quality)
- **単一 Observation の Eval**: 単一の Observation に対する Eval 作成を有効化。(2026-02-10, Evaluation & Quality)
- **イベントベースの Trace テーブル**: Observation および Trace テーブルにイベントベースのビューを導入。(2026-02-05, Core Tracing & Logging)
- **思考/推論のレンダリング**: Trace 詳細における思考および推論プロセス (CoT) のレンダリングサポートを追加。(2026-02-01, Core Tracing & Logging)
- **Org Audit Log Viewer**: 組織レベルの監査ログ用の新しいビューア。(2026-02-01, Enterprise & Infrastructure)

### [Braintrust](https://braintrust.dev/docs/changelog)
- **Thread Retrieval API**: Python SDK でプログラムからスレッドを取得する機能を追加。(2026-02-12, Core Tracing & Logging)
- **Review スパンタイプ**: 人間によるレビューワークフローをサポートする新しい「review」スパンタイプを導入。(2026-02-05, Evaluation & Quality)
- **OpenAI Agents 統合**: OpenAI エージェント統合のすべてのスパンタイプを処理できるように SDK を強化。(2026-02-05, Integration & DX)
- **Classifications フィールド**: Trace における分類フィールドのサポートを追加。(2026-01-31, Core Tracing & Logging)
- **Eval キャッシュ制御**: Eval 中にキャッシュをオフにするオプションを追加。(2026-01-29, Evaluation & Quality)
- **Python Trace Scoring**: Python SDK に Trace Scoring 候補機能を追加。(2026-01-21, Evaluation & Quality)

### [MLflow](https://mlflow.org/releases)
- **Organization Support**: MLflow Tracking Server におけるマルチワークスペース環境のサポート。リソース管理の効率化を実現。(2026-02-12, Enterprise & Infrastructure)
- **MLflow Assistant**: アプリやエージェントの問題を特定、診断、修正するのを支援する、Claude Code を活用した製品内チャットボット。(2026-01-29, Integration & DX)

### [Arize Phoenix](https://arize.com/docs/phoenix/release-notes)
- **LLM Eval プロンプトエディタのオートコンプリート**: LLM-as-a-judge プロンプトの定義に使用するエディタにオートコンプリート機能を追加。(2026-02-13, Evaluation & Quality)
- **ツールレスポンス処理 Evaluator**: エージェントがツールのレスポンスをどのように処理するかを評価するための新しい Evaluator テンプレート。(2026-02-13, Agent & RAG Specifics)
- **Claude Opus 4.6 サポート**: Playground 環境内での Claude Opus 4.6 モデルのサポートを追加。(2026-02-09, Development Lifecycle)
- **ツール選択 Evaluator**: エージェントのワークフローにおけるツール選択の正確性を評価するための Evaluator を追加。(2026-02-06, Agent & RAG Specifics)
- **Faithfulness Evaluator**: 精度向上のため、非推奨となった HallucinationEvaluator に代わる FaithfulnessEvaluator を導入。(2026-02-02, Guardrails & Safety)

## 3. ポジショニングの変化

| 製品 | 現状 | 今後の方向性 | シグナル |
|---|---|---|---|
| W&B Weave | 確立された W&B エコシステムを活用し、厳格なコード中心の Eval と Tracing を提供する開発者優先の Observability プラットフォーム。 | オフラインの実験から、包括的なオンラインの本番環境モニタリングおよびマルチモーダルエージェントのサポートへと拡張。 | Audio Monitors と Dynamic Leaderboards の最近のリリースは、複雑でマルチモーダルな本番ユースケースへの進出を示唆。 |
| LangSmith | LangChain エコシステムのデフォルトの Observability および Eval プラットフォーム。汎用的な LLM DevOps ソリューションへと拡大中。 | 複雑なエージェントワークフローのサポートを深化させ、LangChain コアから独立した広範なモデルプロバイダー統合を強化。 | スタンドアロンの Google/Gemini ラッパーや、LangSmith Fetch のような専門的なエージェントデバッグツールの最近のリリース。 |
| Langfuse | 深い Observability と Eval、プロンプト管理ワークフローを組み合わせた、主要なオープンソース LLM エンジニアリングプラットフォーム。 | 純粋な Tracing から包括的な「LLM Ops」スイートへと進化しており、Eval の自動化とエンタープライズガバナンスにますます焦点を当てている。 | 最近のリリースでは、高度な Eval 機能 (Observation に対する LLM-as-a-judge) とエンタープライズコンプライアンスツール (Audit Log Viewer) を強調。 |
| Braintrust | 厳格なテストと回帰分析を通じて、AI 製品の信頼性の高いリリースに焦点を当てた開発者中心の Eval および Observability プラットフォーム。 | エージェントワークフローとヒューマン・イン・ザ・ループのレビュープロセスのサポートを拡張。 | 「Review」スパンタイプの最近の追加と、OpenAI および Claude エージェント向けの強化されたラッパー。 |
| MLflow | オープンソースの ML ライフサイクル管理の業界標準。現在は GenAI Observability 分野へ積極的に拡大中。 | ネイティブのプロンプト管理、エージェントデバッグアシスタント、マルチワークスペースのエンタープライズ機能を統合し、包括的な GenAI プラットフォームを目指す。 | プロンプト管理 UI (v3.7/3.8)、MLflow Assistant (v3.9)、Organization Support (v3.10) の最近のリリース。 |
| Arize Phoenix | RAG やエージェントアプリケーションを構築する開発者向けの、主要なオープンソースかつコードファーストの Observability プラットフォーム。 | 複雑なエージェント Eval (ツールの使用、Faithfulness) のサポートを深め、開発者の実験ワークフローを洗練。 | 最近のリリースは、ツール選択、レスポンス処理、Faithfulness に関する特定の Evaluator と Playground のアップデートに重点を置いている。 |

## 4. エンタープライズ・シグナル

- Langfuse は Organization Audit Log Viewer を導入し、セルフホストおよびエンタープライズチームのガバナンスを強化しました。
- MLflow は、リソースの分離を改善するためのマルチワークスペース環境を可能にする Organization Support (v3.10) をリリースしました。
- W&B Weave は Audio Monitors を開始し、オンライン Eval 機能をマルチモーダル音声エージェントに拡張しました。
- Braintrust は、Trace 内でヒューマン・イン・ザ・ループのレビューワークフローを形式化するために「Review」スパンタイプを追加しました。
- LangSmith はスタンドアロンの Google Gen AI および Gemini ラッパーをリリースし、LangChain を超えたエンタープライズ統合を拡大しました。

---

## 調査手法

データは 2026-02-16 に GitHub/PyPI フィードおよびドキュメントのスクレイピングを通じて収集されました。
カテゴリ分析は Perplexity Sonar (ウェブ検索 + 分析) を使用して実施されました。統合分析は OpenRouter 経由で google/gemini-3-pro-preview モデルを使用して行われました。