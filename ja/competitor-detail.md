---
layout: default
title: LLM Observability — 製品詳細
---

# LLM Observability — 製品詳細
**日付**: 2026-02-12 | **モデル**: google/gemini-3-pro-preview

### W&B Weave

**概要**: W&B Weaveは、LLMアプリケーションの構築、Eval、Monitoringのための開発者中心のツールキットであり、広範なWeights & Biases MLプラットフォームと深く統合されています。コードファーストのインストルメンテーション、LLM-as-a-judgeによる堅牢なEvalワークフロー、エンタープライズグレードのインフラストラクチャに優れていますが、現在は深いCI/CD統合や高度なドリフト分析機能が不足しています。

**強み**:
- 確立されたW&BのMLトレーニングおよびモデルレジストリエコシステムとの深い統合。
- 堅牢なPythonおよびTypeScript SDKによる強力な「コードファースト」の開発者体験。
- VPC、セルフホスティング、SOC 2コンプライアンスを含むエンタープライズグレードのインフラストラクチャ。
- LLM-as-a-judgeと動的なリーダーボードを備えた柔軟なEvalシステム。

**弱み**:
- 自動テストゲートのためのネイティブなCI/CDパイプライン統合の欠如。
- ドリフト検出やエンベディング分析などの高度な分析機能が限定的。
- Weaveリソースを管理するための専用CLIツールの不在。
- PII機能が検出のみに限定されており、自動マスキング機能がない。

**最近のアップデート**:
- Audio Monitors: LLM judgeを使用して、テキストと共にオーディオ出力を監視・判定できるオンラインEvalモニター。(2026-02-01)
- Dynamic Leaderboards: フィルター、メトリクス、表示設定の永続的なカスタマイズが可能な自動生成リーダーボード。(2026-01-29)
- Custom LoRAs in Playground: Weave Playground内でカスタムLoRAウェイトを直接テストおよび比較するためのサポート。(2026-01-16)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | Weaveは、優れた自動インストルメンテーションとネイティブなOpenTelemetryサポートにより、強力なコアTracing機能を提供します。レイテンシやトークン使用量などの基本メトリクスには優れていますが、コスト見積もり手法やリアルタイムStreamingの可視化に関するドキュメントは不十分です。 |
| Agent & RAG Observability | ●●● | トレースツリーやフレームグラフなどの強力な可視化ツールを備え、AgentやRAGシステムに対して堅牢なObservabilityを提供します。Agentフレームワークとの統合は良好ですが、プロトコルTracingや自動エラーハイライトなどの特定機能は発展途上です。 |
| Evaluation & Quality | ●●● | LLM-as-a-Judge、カスタムScoring、動的リーダーボードにより、Evalに強みを持っています。Tracingからのデータセット作成を簡素化しますが、現在はネイティブなCI/CD統合や自動回帰アラートが不足しています。 |
| Guardrails & Safety | ●●● | 組み込みのセーフティScoringとリアルタイム介入のための柔軟なフックを備えた、堅牢なGuardrailsフレームワークを提供します。PII検出はサポートされていますが、自動マスキングの欠如は専門的なセーフティツールと比較して顕著なギャップです。 |
| Monitoring & Analytics | ●●○ | コスト、レイテンシ、エラーに関する運用Monitoringを、設定可能なアラート機能と共に提供します。しかし、ドリフト検出やエンベディング空間分析などの高度なデータサイエンスMonitoring機能が不足しています。 |
| Experiment & Improvement Loop | ●●○ | モデルのバージョニングとトレーニング統合におけるW&Bの伝統を活かし、実験ループにおいて優れています。Playgroundや失敗抽出機能は強力ですが、Weave内でのプロンプトやデータセットのバージョニングはより明示的である必要があります。 |
| Developer Experience & Integration | ●●○ | 堅牢なPythonおよびTypeScript SDKと幅広いフレームワークサポートにより、強力な開発者体験を提供します。カスタムモデルに対して柔軟に設計されていますが、専用のCLIや深いネイティブなノートブック可視化ウィジェットが不足しています。 |
| Infrastructure & Enterprise | ●●● | W&Bの成熟したエンタープライズインフラの恩恵を大きく受けており、最高水準のセキュリティ、コンプライアンス、デプロイの柔軟性（SaaS、VPC、オンプレミス）を提供します。RBAC、SSO、SOC 2コンプライアンスなどの機能を継承し、設計段階からエンタープライズ対応となっています。 |


---

### LangSmith

**概要**: LangSmithは、LangChainエコシステムと深く統合された包括的なObservabilityおよびEvalプラットフォームであり、LLMアプリケーション開発のフルライフサイクルを促進するように設計されています。きめ細かなTracing、LLM-as-a-judge Eval、反復的な実験に優れていますが、現在はGuardrailsを外部統合に依存しており、一部のネイティブなエンタープライズガバナンス機能が不足しています。

**強み**:
- シームレスなAgent TracingのためのLangChainおよびLangGraphとの深いネイティブ統合。
- LLM-as-a-judgeと人間によるアノテーションをサポートする堅牢なEvalフレームワーク。
- プロンプト/モデルのバージョニングとA/Bテストを備えた強力な実験トラッキング。
- Streamingやネストされたスパンを含む包括的なTracing機能。

**弱み**:
- ドキュメント化されたデータにおける限定的なエンタープライズガバナンス機能（RBAC、SSO、監査ログ）。
- 組み込みのGuardrailsの欠如（外部統合に依存）。
- 従来のML実験トラッキングツールやDatabricksに対するネイティブサポートの欠如。
- ネイティブ統合と比較して、LangChain以外のフレームワークに対するサポートが限定的。

**最近のアップデート**:
- トレースプレビューのカスタマイズ: LangSmithインターフェースでトレースプレビューをカスタマイズする機能。(2026-02-06)
- LangSmith Self-Hosted v0.13: プラットフォームのセルフホスト版のアップデート。(2026-01-16)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | LangSmithは、特にLangChainアプリケーションにおいて、ネストされたスパン、Streamingレスポンス、トークン使用量に対する深い可視性を備えた堅牢なコアTracing機能を提供します。 |
| Agent & RAG Observability | ●●● | ツール呼び出し、検索ステップ、マルチターン推論に関する詳細なインサイトを提供し、AgentおよびRAGのObservabilityに優れていますが、MCPのネイティブプロトコルサポートは確認されていません。 |
| Evaluation & Quality | ●●● | 強力なLLM-as-a-judge機能、人間によるアノテーションワークフロー、CI/CD統合を備えた強力なEvalスイートを提供し、品質保証のリーダーとなっています。 |
| Guardrails & Safety | ●●○ | セーフティ機能は強制実行よりもMonitoringとEvalに重点を置いており、強力なカスタムエバリュエーターをサポートしていますが、アクティブなブロッキングやマスキングは統合機能に依存しています。 |
| Monitoring & Analytics | ●●● | コスト、レイテンシ、エラーなどの運用メトリクスに対するMonitoring機能は堅牢で、柔軟なDashboardによってサポートされていますが、高度なデータドリフト検出は存在しません。 |
| Experiment & Improvement Loop | ●●● | プロンプトのバージョニング、Playground、実験トラッキングにより改善ループを強力にサポートし、チームが本番データをモデルパフォーマンスの向上に活用できるようにします。 |
| Developer Experience & Integration | ●●● | 優れたSDK、CLIツール、APIアクセスにより開発者体験は非常に高いですが、エコシステムはLangChainユーザー向けに高度に最適化されています。 |
| Infrastructure & Enterprise | ●●○ | SaaSおよびセルフホストのオプションにより強力なデプロイの柔軟性を提供しますが、RBACや監査ログなどのエンタープライズガバナンス機能に関するドキュメントが不足しています。 |


---

### Langfuse

**概要**: Langfuseは、堅牢なTracingとObservabilityを、統合されたプロンプト管理およびEval機能と組み合わせた、主要なオープンソースLLMエンジニアリングプラットフォームです。開発者第一の姿勢が特徴で、優れたセルフホスティングオプションと包括的なSDKを提供していますが、セーフティGuardrailsや高度なドリフト検出については統合機能に依存しています。

**強み**:
- 柔軟なセルフホスティングとVPCデプロイオプションを備えた強力なオープンソースコア。
- ネストされたスパンやAgentの推論ステップを含む包括的なTracing機能。
- 迅速な反復のための統合されたプロンプト管理とPlayground。
- カスタムメトリクスをサポートする堅牢なコストおよびトークン使用量分析。
- 開発者フレンドリーなSDKとAPIファーストの設計。

**弱み**:
- ネイティブな組み込みGuardrailsの欠如（外部統合に依存）。
- 自動化された分布ドリフト検出やエンベディング分析がない。
- 基本的なAPIアクセス以外のCI/CD専用ツールの不足。
- ネイティブなCLIツールやノートブック専用の可視化機能の不在。
- MLflowのような従来のML実験トラッキングツールのサポートなし。

**最近のアップデート**:
- Single Observation Evals: フル・トレースだけでなく、単一のオブザベーションに対してEvalを実行する機能のサポート。(2026-02)
- Events-based Trace Table: より細かい粒度のための、イベントに基づいたトレースおよびオブザベーションの新しいテーブルビュー。(2026-02)
- Thinking/Reasoning Trace Rendering: トレース詳細における「思考」または推論部分の視覚的レンダリング（例：DeepSeek R1用）。(2026-01)
- Org Audit Log Viewer: ユーザーのアクションやセキュリティイベントを追跡するための、組織レベルの監査ログ用の新しいビューアー。(2026-01)
- Inline Trace Comments: コラボレーションのために、トレース内のIOデータの一部にインラインでコメントを追加する機能。(2026-01)
- Trace Corrections: ヒューマンフィードバックループのために、トレースおよびオブザベーションのプレビューに修正を提供する機能を追加。(2026-01)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | ネストされたスパン、自動インストルメンテーション、プロンプト/レスポンスのキャプチャ、トークン、レイテンシ、コスト、メタデータ、OpenTelemetryを強力にサポートし、堅牢なコアTracingとロギングを提供します。Streamingトレースはサポートされていますが、リアルタイムの可視化には制限がある場合があります。 |
| Agent & RAG Observability | ●●● | ツール呼び出し、検索、マルチステップ推論、ワークフローグラフの強力なTracingにより、AgentおよびRAGワークフローに堅牢なObservabilityを提供します。本番環境のMonitoringとEvalに優れていますが、MCP/A2Aなどの特殊なプロトコルのサポートが不足しています。 |
| Evaluation & Quality | ●●● | LLM-as-a-Judge、カスタムScoring、人間用UI、データセット、回帰、比較、オンラインMonitoringを強力にサポートし、堅牢なEval機能を提供します。Tracingからのデータセット管理やリーダーボードには、明示的な直接変換やランキングUIがないなどの制限が見られます。 |
| Guardrails & Safety | ●●○ | 外部セキュリティツールのTracingとEvalを可能にすることでGuardrailsのObservabilityに優れていますが、ネイティブな組み込みGuardrailsが不足しています。標準のセーフティフィルターを提供するのではなく、ユーザーが実装したソリューションのMonitoringと検証に重点を置いています。 |
| Monitoring & Analytics | ●●○ | 包括的なDashboardシステムを通じて、コスト追跡、トークン分析、カスタムメトリクスにおいて強力な能力を発揮します。レイテンシとエラーのMonitoringはサポートされていますが、明示的なアラート機能が不足しており、ドリフト検出などの高度な分析もありません。 |
| Experiment & Improvement Loop | ●●○ | プロンプトのバージョニング、実験、失敗抽出に優れており、迅速な反復を可能にします。データセット管理とトレースのエクスポートは改善ループをサポートしますが、明示的なデータセットのバージョニングや継続的なスケジュールEvalが不足しています。 |
| Developer Experience & Integration | ●●○ | 柔軟なインストルメンテーションと完全なREST APIアクセスを備えた、PythonおよびTypeScript/JS用の強力な公式SDKを提供します。カスタムモデルを十分にサポートしていますが、CLIツールやノートブック可視化機能が不足しています。 |
| Infrastructure & Enterprise | ●●○ | 堅牢なセルフホスティング、オープンソースコア、VPCデプロイオプションにより、インフラとエンタープライズ対応に優れています。エンタープライズライセンスにより、RBAC、監査ログ、データ保持などの主要機能が解放されますが、従来のML統合は存在しません。 |


---

### Braintrust

**概要**: Braintrustは、本番データと開発実験の間のループを閉じることに長けた、エンタープライズグレードのAI ObservabilityおよびEvalプラットフォームです。「Evalファースト」の開発に重点を置いており、データセット管理、カスタムScoring（LLM-as-a-Judge）、および機密データを顧客の管理下に置くハイブリッドアーキテクチャのための堅牢なツールを提供することで差別化を図っています。

**強み**:
- 包括的なEvalループ: 本番環境のトレースをデータセットや実験にシームレスに接続。
- ハイブリッドエンタープライズアーキテクチャ: SaaSコントロールプレーンを使用しながら、データを顧客のクラウド内に保持可能。
- 強力な開発者体験: 高品質なSDKと、プロンプトエンジニアリングのための統合されたPlayground。
- カスタムScoring: テーラーメイドの品質評価のための柔軟な「LLM-as-a-Judge」機能。

**弱み**:
- リアルタイムGuardrailsなし: 組み込みのブロッキングやセーフティ強制メカニズムが不足。
- 限定的なフレームワーク統合: LangChainのような人気のあるフレームワークとネイティブに統合されていない。
- エンベディング分析なし: エンベディング空間のクラスタリングや可視化のためのツールがない。

**最近のアップデート**:
- サブエージェントのネスト: Claude Agent SDKラッパーにサブエージェントのネストのサポートを追加。(2026-02-12)
- Classificationsフィールド: データ分類を向上させるため、SDKに新しいClassificationsフィールドを追加。(2026-01-31)
- Eval Cache Control: 新鮮な実行を保証するため、Eval中にキャッシュをオフにする新しいオプション。(2026-01-29)
- Trace Scoring Candidate: PythonのトレースScoring機能のアップデート。(2026-01-21)
- Workflowsへの名称変更: より幅広いユースケースを反映するため、SDK内の「agents」を「workflows」に変更。(2026-01-15)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | 強力な自動インストルメンテーションとOpenTelemetryサポートにより、堅牢なTracing基盤を提供します。トークン使用量やコストなどの詳細な情報のキャプチャに優れていますが、Streamingトレースの可視化は標準的なリクエスト/レスポンスのロギングほど重視されていません。 |
| Agent & RAG Observability | ●●○ | 特にツール呼び出しやマルチステップ推論のTracingにおいて、AgentやRAGパイプラインに対して強力なObservabilityを提供します。セッションを効果的にグループ化しますが、可視化はグラフベースというよりリストベースであり、MCPなどのプロトコル固有のTracingは現在ありません。 |
| Evaluation & Quality | ●●● | EvalはBraintrustの最も強力なカテゴリであり、オフラインおよびオンラインの品質評価のための完全なエコシステムを提供します。トレースからデータセットへの変換、カスタムScoring、CI/CD統合などの機能により、継続的な改善のための緊密なフィードバックループを構築します。 |
| Guardrails & Safety | ●●○ | アクティブなランタイム保護よりも、ObservabilityとEvalに重点を置いています。組み込みのGuardrailsやPIIマスキングが不足しており、セーフティ問題の特定は事後Evalとアラートに依存しています。 |
| Monitoring & Analytics | ●●○ | コスト、トークン、カスタムメトリクスに対して確かな運用Monitoringを提供します。しかし、専用のML Monitoringツールと比較すると、エンベディング分析、ドリフト検出、詳細なレイテンシパーセンタイルなどの高度なML Monitoring機能には特化していません。 |
| Experiment & Improvement Loop | ●●● | Playgroundでのプロンプトエンジニアリングから実験トラッキング、データセット管理まで、シームレスなワークフローを提供し、改善ループにおいて優れています。本番データをトレーニング資産に効果的に変換しますが、モデルのバージョニングやFine-tuningパイプラインはそれほど発展していません。 |
| Developer Experience & Integration | ●●○ | 開発者体験は、プラットフォームのPlaygroundやEval機能と深く統合された強力なPythonおよびTypeScript SDKを中心に構成されています。しかし、LangChainのような広範なサードパーティフレームワーク統合や、CLI、ノートブックウィジェットなどの補助ツールが不足しています。 |
| Infrastructure & Enterprise | ●●○ | 強力なSaaS提供、SOC 2コンプライアンス、および顧客が自身のクラウド環境内にデータを保持できる独自のハイブリッドアーキテクチャにより、エンタープライズのニーズをターゲットにしています。完全なオンプレミスのエアギャップオプションや、従来のMLインフラとの統合は不足しています。 |


---

### MLflow

**概要**: MLflowは成熟したオープンソースのMLOpsプラットフォームであり、堅牢なTracing、Eval、実験トラッキング機能を備え、LLM Observabilityへの拡張に成功しています。DatabricksエコシステムやOpenTelemetry標準との強力な統合を通じてエンドツーエンドのライフサイクルを管理することに優れていますが、高度なGuardrailsやリアルタイムの本番Monitoringについては統合機能に依存しています。

**強み**:
- トラッキング、レジストリ、Evalをカバーする包括的なライフサイクル管理。
- 主要なライブラリの自動インストルメンテーションを備えた、強力なOpenTelemetryベースのTracing。
- カスタムScoringを備えた堅牢な「LLM-as-a-Judge」Evalフレームワーク。
- Databricksやエンタープライズエコシステムとの深い統合。
- 成熟したオープンソースコミュニティと広範なSDKサポート。

**弱み**:
- ネイティブなリアルタイムコストDashboardや高度な本番Monitoring（ドリフト/クラスタリング）の欠如。
- セーフティ、毒性、PIIのための組み込みGuardrailsがない。
- 特化したツールと比較して、複雑なAgentワークフロー（DAG）の可視化が限定的。
- ユーザーインターフェースが、ニッチな競合他社と比較して「LLM専用」ワークフローに特化していない。

**最近のアップデート**:
- トラッキングサーバーでの組織サポート: 異なるワークスペース間で実験やリソースを整理できる、マルチワークスペース環境のサポート。(2026-02-12)
- MLflow Assistant: UI内で直接問題を特定、診断、修正するのを支援する、Claude Codeを搭載した製品内チャットボット。(2026-01-29)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | OpenTelemetryを介して堅牢なコアTracing機能を提供し、自動インストルメンテーション、ネストされたスパン、トークントラッキングに優れています。ネイティブなコスト見積もりが不足しており、Streamingトレースに対する明示的なサポートも限定的です。 |
| Agent & RAG Observability | ●●○ | ツール呼び出しやマルチステップ推論のエンドツーエンドTracingにより、強力なAgent Observabilityを提供します。標準的なスパンを介してRAGをサポートしていますが、高度なワークフローグラフの可視化や特殊なAgentプロトコルが不足しています。 |
| Evaluation & Quality | ●●● | LLM-as-Judge、カスタムScoring、ヒューマンフィードバックツールを備えた包括的なEvalスイート。データセット管理やトレースベースのEvalに優れていますが、回帰検出やCI/CD統合は手動またはAPI駆動です。 |
| Guardrails & Safety | ●●○ | セーフティやPIIのためのネイティブな組み込みGuardrailsが不足しており、外部ツールと統合するためにTracingインストルメンテーションに依存しています。カスタムフックにより一部のセーフティチェックが可能ですが、プラットフォームのコア機能ではありません。 |
| Monitoring & Analytics | ●●○ | Tracingを通じたトークン分析やカスタムメトリクスのロギングに強みがあります。しかし、専用のコストDashboard、ドリフト検出、高度なエンベディング分析が不足しており、そのままの状態での本番Monitoringの有用性は限定的です。 |
| Experiment & Improvement Loop | ●●○ | プロンプト、モデル、データセットの強力なバージョニングにより、実験ループを強力にサポートします。トラッキングとEvalを通じて体系的な改善を可能にしますが、インタラクティブなPlaygroundや自動化されたRLパイプラインが不足しています。 |
| Developer Experience & Integration | ●●● | PythonおよびJSの成熟したSDK、広範なCLIツール、オートロギングによる幅広いフレームワークサポートにより、強力な開発者体験を提供します。ノートブック統合は機能的ですが、埋め込み可視化機能が不足しています。 |
| Infrastructure & Enterprise | ●●○ | 強力なオープンソースのセルフホスティングとマネージドクラウドオプション（Databricks/SageMaker）を提供する、汎用性の高いインフラの選択肢です。RBACや監査ログなどのエンタープライズ機能は、主にマネージドサービスの統合を通じて利用可能です。 |


---

### Arize Phoenix

**概要**: Arize Phoenixは、OpenTelemetryに基づいて構築された堅牢なオープンソースのObservabilityおよびEvalプラットフォームであり、特にLLM AgentやRAGパイプライン向けに設計されています。深いTracing、LLM-as-a-judge Eval、データセット管理に優れており、Arizeエンタープライズプラットフォームとの統合を通じて、ローカル開発から本番Monitoringへのシームレスな移行を提供します。

**強み**:
- ネイティブなOpenTelemetryサポートにより、ベンダーニュートラルなTracingと容易な統合を保証。
- 事前構築済みおよびカスタムのエバリュエーターを備えた、強力なLLM-as-a-Judge機能。
- ツール呼び出しやRAG検索を含む、エージェンティックなパターンの包括的なサポート。
- オープンソースのセルフホスティングからエンタープライズSaaSまで、柔軟なデプロイオプション。

**弱み**:
- 組み込みのGuardrailsの欠如（外部統合に依存）。
- オープンソース版でドキュメント化されているエンタープライズコンプライアンス機能（RBAC、監査ログ）が限定的。
- ネイティブなCI/CD品質ゲートの不在により、手動のパイプライン設定が必要。
- TypeScript SDKやPython以外のエコシステムサポートが、Python版ほど成熟していない。

**最近のアップデート**:
- PlaygroundでのClaude Opus 4.6: Playgroundインターフェース内でClaude Opus 4.6モデルのサポートを追加。(2026-02-09)
- Tool Selection Evaluator: Agent評価を向上させるため、ライブラリに不足していたtool_selectionエバリュエーターを追加。(2026-02-06)
- Faithfulness Evaluator: FaithfulnessEvaluatorを導入し、HallucinationEvaluatorを非推奨化。(2026-02-02)
- Tool Invocation Accuracy Metric: ツール呼び出しの精度を測定するための新しいメトリクスを追加。(2026-02-02)
- Configurable OAuth2 Email Extraction: OAuth2での設定可能なメール抽出のためのEMAIL_ATTRIBUTE_PATHを追加。(2026-01-28)
- Cursor Rule for Metrics: 新しい組み込みメトリクス（LLM分類エバリュエーター）を作成するためのカーソルルールを追加。(2026-01-21)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | OpenTelemetryを介して堅牢なコアTracingを提供し、主要フレームワークの強力な自動インストルメンテーションにより、ネストされたスパン、トークン、レイテンシを効果的にキャプチャします。 |
| Agent & RAG Observability | ●●● | ツール呼び出し、検索、推論ステップのTracingにおいて、AgentおよびRAGのObservabilityを強力にサポートしますが、ワークフローグラフの可視化はそれほど高度ではありません。 |
| Evaluation & Quality | ●●○ | 事前構築されたメトリクスとヒューマンフィードバックUIを備えた優れたLLM-as-judge機能を提供しますが、組み込みのCI/CD統合や自動回帰ゲートが不足しています。 |
| Guardrails & Safety | ●●● | 独立したプロバイダーとしてではなく、主に外部Guardrails（Guardrails AIなど）のObservabilityレイヤーとして機能し、強力なフックとカスタムサポートを提供します。 |
| Monitoring & Analytics | ●●○ | アラートインフラを備えたトークン使用量、レイテンシ、ドリフトの強力なMonitoringを提供しますが、専用のコストDashboardや深いエラー率分析が不足しています。 |
| Experiment & Improvement Loop | ●●○ | プロンプトやデータセットの強力な実験トラッキングとバージョニングにより反復的な改善を可能にしますが、インタラクティブなPlayground機能は最近追加されたばかりのようです。 |
| Developer Experience & Integration | ●●○ | モジュール式SDKとREST APIによりPythonユーザーに優れた開発者体験を提供しますが、TypeScriptサポートやCLIツールはそれほど発展していません。 |
| Infrastructure & Enterprise | ●●○ | オープンソース、セルフホスト、SaaSモデルによる強力なインフラオプションを提供しますが、RBACやSOC 2などのエンタープライズコンプライアンス機能に関する明示的なドキュメントが不足しています。 |


---