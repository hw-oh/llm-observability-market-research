---
layout: default
title: LLM Observability — 製品詳細
---

# LLM Observability — 製品詳細
**日付**: 2026-02-12 | **モデル**: google/gemini-3-pro-preview

### W&B Weave

**概要**: W&B Weaveは、Weights & Biasesの機械学習プラットフォームと深く統合された、生成AIアプリケーションの構築、Eval、モニタリングのための包括的なツールキットです。実験から本番環境への厳格なループを重視しており、Tracing、バージョニング、LLMエージェントのEvalのための堅牢な機能を提供します。最近ではマルチモーダル（オーディオ）モニタリングもサポートされました。

**強み**:
- W&Bのモデル管理およびトレーニング機能との深い統合による、シームレスな Fine-tuning ループ
- マルチモーダル（オーディオ）Judgeを含む高度な Eval 機能
- プロンプト、データセット、モデルの強力なバージョニング
- 自動化されたモデル比較のための動的なリーダーボード

**弱み**:
- 提供されたデータ内では、エンタープライズ向けセキュリティ機能（PIIマスキング、監査ログ）が不足
- Streaming Traceのサポートに関する具体的な言及がない
- エージェントのメモリ Tracing に関する詳細が限定的

**最新のアップデート**:
- オーディオモニター: LLM Judgeを使用して、テキストと共にオーディオ出力を監視・評価するモニター。(2026-02-01)
- 動的リーダーボード: Eval から自動生成されるリーダーボード。永続的なカスタマイズとCSVエクスポートが可能。(2026-01-29)
- Playground でのカスタム LoRA: Weave Playground で直接、Fine-tuning されたカスタム LoRA 重みのテストと Eval をサポート。(2026-01-16)

| カテゴリ | レーティング | サマリー |
|---|---|---|
| Core Observability | ●●● | Weaveはデコレータベースの Tracing を通じて強固なコア Observability を提供し、デバッグのための階層的な実行フロー、レイテンシ、コストを効果的にキャプチャします。 |
| Agent / RAG Observability | ●●○ | プラットフォームはエージェントとRAGのワークフローを十分にサポートしており、検索品質やツール利用のための特定の機能を備えていますが、メモリ Tracing は明示的に強調されていません。 |
| Evaluation Integration | ●●● | Eval は際立ったカテゴリであり、動的なリーダーボード、マルチモーダル Judge（オーディオ/テキスト）、および厳格なテストのためのデータセットとの緊密な統合を特徴としています。 |
| Monitoring & Metrics | ●●○ | モニタリング機能はコストやレイテンシなどの主要なメトリクスをカバーしており、カスタマイズ可能なビューやリーダーボードを備えていますが、ツールの成功率などの特定のエージェントメトリクスは欠けています。 |
| Experiment / Improvement Loop | ●●● | これは製品の最も強力な領域であり、W&Bの実績を活かして、実験やバージョニングから継続的な Eval や Fine-tuning に至る完全なループを提供します。 |
| DevEx / Integration | ●●● | 2つの SDK と強力なモデル統合により開発者体験は十分にサポートされていますが、Streaming Tracing の詳細は不明です。 |
| Enterprise & Security | ●●○ | エンタープライズ向けのデプロイオプション（オンプレミス/VPC）は強力ですが、PIIマスキングや監査ログなどの特定のコンプライアンス機能は公開リリースノートに詳述されていません。 |


---

### LangSmith

**概要**: AIエージェントおよびLLMアプリケーションの開発、デバッグ、デプロイのための、フレームワークに依存しない包括的なプラットフォームです。Tracing によるエンドツーエンドの可視性、ペア比較などの高度な Eval 機能、セルフホスティングやSSOを含む堅牢なエンタープライズ機能を提供します。

**強み**:
- 複雑なエージェント Tracing のための LangChain および LangGraph との深いネイティブ統合
- ペア比較や人間によるアノテーションキューを含む包括的な Eval スイート
- セルフホスティング/ハイブリッドデプロイオプションとSSOを備えた強力なエンタープライズ提供
- 頻繁な SDK アップデートと新しい統合による迅速な機能開発

**弱み**:
- シート数と Trace 数に基づく料金モデルは、高ボリュームのコンシューマー向けアプリでは高価になる可能性がある
- プラットフォームの複雑さは、単純なシングルプロンプトのアプリケーションには過剰な場合がある
- フレームワークに依存しない機能があるにもかかわらず、LangChain へのベンダーロックインの懸念がある

**最新のアップデート**:
- Trace プレビューのカスタマイズ: UI での Trace プレビュー方法をカスタマイズする機能。(2026-02-06)
- Google Gen AI Wrapper エクスポート: SDK における Google Gen AI ラッパーのエクスポート機能。(2026-01-31)
- LangSmith セルフホスト v0.13: アップデートされたセルフホスト版のリリース。(2026-01-16)

| カテゴリ | レーティング | サマリー |
|---|---|---|
| Core Observability | ●●● | 複雑で階層的なエージェントワークフローを処理し、詳細なコスト/トークンの可視性を提供する深い Tracing 機能により、業界をリードする Observability を提供します。 |
| Agent / RAG Observability | ●●● | エージェントおよびRAGアーキテクチャに高度に特化しており、ツールの使用状況、検索コスト、多段階の推論ループに対する特定の可視性を提供します。 |
| Evaluation Integration | ●●● | 自動化された LLM-as-a-judge 機能と、人間によるアノテーションワークフローおよびデータセット管理を組み合わせた堅牢な Eval スイートです。 |
| Monitoring & Metrics | ●●● | すべてのコンポーネントにわたって、技術的メトリクス（レイテンシ、エラー）とビジネスメトリクス（コスト、トークン使用量）を統合する包括的なモニタリング Dashboard を提供します。 |
| Experiment / Improvement Loop | ●●● | 特にプロンプトエンジニアリングとデータセット管理において強力なイテレーションループを持ち、実験を通じた継続的な改善を可能にします。 |
| DevEx / Integration | ●●● | 幅広いフレームワークのサポート、活発な SDK 開発、ターミナルベースのデバッグ用 CLI ツールにより、優れた開発者体験を提供します。 |
| Enterprise & Security | ●●● | 堅牢なセキュリティ認証、セルフホスティングオプション、大規模組織に適したきめ細かなアクセス制御を備えたエンタープライズ対応製品です。 |


---

### Langfuse

**概要**: Langfuse は、オープンソースで開発者優先の LLM エンジニアリングプラットフォームであり、Observability、プロンプト管理、Eval を統合されたワークフローに結びつけます。強力なセルフホスティング機能、包括的なエージェント Tracing（グラフやツールコールを含む）、および継続的な改善のための堅牢な実験フレームワークが特徴です。

**強み**:
- オープンソース & セルフホスト可能: 完全なデータ制御とオンプレミスデプロイのオプションを提供。
- 統合されたライフサイクル: Tracing、プロンプト管理、Eval（データセット/実験）をシームレスに接続。
- 強力なエージェントサポート: エージェントグラフ、ツールコール、推論ステップの専門的な可視化。
- コスト & トークン経済学: 料金体系と支出アラートを備えた詳細なトラッキング。
- 開発者体験: 高品質な SDK と幅広いフレームワーク統合（LangChain, LlamaIndex）。

**弱み**:
- Fine-tuning のオーケストレーション: トレーニングジョブを実行するネイティブ機能がなく、データ準備のみに焦点を当てている。
- 視覚的な根本原因分析: Tracing は深いが、複雑な失敗に対する自動化された視覚的根本原因分析はあまり強調されていない。
- モバイルエコシステム: Web/Python と比較して、モバイルネイティブ（iOS/Android）のインスツルメンテーションに対する専門的なサポートが少ない。

**最新のアップデート**:
- バージョン付きデータセットでの実験実行: 特定のタイムスタンプでデータセットを取得し、再現性のために過去のバージョンで実験を実行。(2026-02-11)
- Trace の修正済み出力: Fine-tuning データセットを構築するために、Trace ビューで LLM 出力の改善版を直接キャプチャ。(2026-01-14)
- 単一 Observation の Eval: 単一の Observation に対して Eval を実行するサポート。(2026-02-05)
- イベントベースの Observation テーブル: イベントに基づく Trace/Observation の新しいテーブルビュー。(2026-02-05)
- 推論/思考プロセスの Trace レンダリング: Trace 詳細における思考/推論部分の視覚的レンダリング。(2026-01-30)
- 組織監査ログビューアー: 組織の監査ログを表示するための UI。(2026-01-30)

| カテゴリ | レーティング | サマリー |
|---|---|---|
| Core Observability | ●●● | ネイティブ SDK と OpenTelemetry 統合に支えられた、複雑なワークフローへの深い可視性を持つ堅牢なコア Tracing 機能。 |
| Agent / RAG Observability | ●●● | グラフ、ツール使用、推論ステップの専門的な可視化を備えた、非常に有能なエージェント Observability。 |
| Evaluation Integration | ●●● | データセットと Judge を使用して、本番モニタリング（オンライン）と開発テスト（オフライン）を橋渡しする包括的な Eval スイート。 |
| Monitoring & Metrics | ●●● | カスタマイズ可能な Dashboard と、コストおよびトークン経済学への特別な焦点を当てた強力な分析機能。 |
| Experiment / Improvement Loop | ●●● | プロンプト管理とデータセットを Trace データに直接リンクさせ、継続的な改善を実現する優れたイテレーションループ。 |
| DevEx / Integration | ●●● | 幅広いエコシステムサポートとオープン API を備えた開発者中心の設計。 |
| Enterprise & Security | ●●● | 特にセルフホスティングと厳格なデータ制御を必要とする組織にとって、強力なエンタープライズ姿勢。 |


---

### Braintrust

**概要**: Braintrust は、継続的な改善のためのクローズドループワークフロー（計測、観察、アノテーション、Eval、デプロイ）を強調する包括的な AI Observability および Eval プラットフォームです。幅広い SDK サポート（Python、TypeScript、Go、Java、Ruby、C# を含む）と、データクエリおよび分析を容易にする AI アシスタント（'Loop'）の深い統合が特徴です。

**強み**:
- 最も幅広い SDK エコシステム（Python, TS, Go, Java, Ruby, C#）と自動インスツルメンテーション機能。
- 自然言語クエリとデータ分析のための統合 AI アシスタント 'Loop'。
- 柔軟なカスタムメトリクスと集計のための強力な SQL/BTQL クエリエンジン。
- 本番 Trace をデータセット、Playground、実験に直接接続するシームレスなワークフロー。
- セルフホスティングときめ細かな RBAC を含む強力なエンタープライズ機能。

**弱み**:
- ネイティブな Fine-tuning ジョブのオーケストレーションの欠如（エクスポートに依存）。
- RAG 特有の可視化（例：埋め込み空間）は、一般的な Trace ツリーほど専門化されていない。
- 組み込みの PII 墨消しパイプラインは、一部のセキュリティ重視の競合他社ほど目立たない。

**最新のアップデート**:
- Trace レベルの Scoring: カスタムコード Scoring が実行 Trace 全体にアクセスできるようになり、多段階ワークフローやエージェントの動作を評価可能に。(2026-02-01)
- カスタムビューでの添付ファイルレンダリング: カスタム Trace ビューで画像、ビデオ、オーディオを直接レンダリングするサポート。(2026-02-01)
- LangSmith 統合: LangSmith と Braintrust の両方に Trace を送信するか、Braintrust のみにルーティングするための実験的ラッパー。(2026-02-01)
- Cursor 統合: MCP サーバーを介した Cursor エディタとの統合により、ログのクエリや実験の取得が可能に。(2026-02-01)
- 集計を伴う単一 Span フィルタ: 単一 Span フィルタと GROUP BY を組み合わせて、集計された Trace 分析を行う機能。(2026-02-01)
- 自動インスツルメンテーション (Python, Ruby, Go): Python、Ruby、Go アプリケーション向けのコード改変不要な Tracing サポート。(2026-01-29)
- Temporal 統合: 親子関係を持つ Temporal ワークフローとアクティビティの自動 Tracing。(2026-01-21)
- レビュー用カンバンレイアウト: フラグが立てられた Span やレビューワークフローを管理するための新しいカンバンビュー。(2026-01-20)
- Trace ページでの Loop: AI アシスタント 'Loop' が個別の Trace ページで直接分析に利用可能に。(2026-01-20)
- TrueFoundry 統合: OpenTelemetry を介した TrueFoundry AI Gateway との統合。(2026-01-20)

| カテゴリ | レーティング | サマリー |
|---|---|---|
| Core Observability | ●●● | 堅牢な Tracing、詳細なロギング、および Trace の再生とイテレーションのための Playground 統合を備えた強力なコア Observability。 |
| Agent / RAG Observability | ●●● | エージェントワークフローとツール利用の優れたサポート。ただし、RAG 特有の可視化は一般的な Trace ビューほど専門化されていません。 |
| Evaluation Integration | ●●● | 本番 Trace、データセット、および厳格なオフライン/オンライン Scoring の間の緊密なループを提供する、Eval 統合のマーケットリーダー。 |
| Monitoring & Metrics | ●●● | 柔軟な SQL ベースのクエリ (BTQL) によって提供される堅牢なモニタリング機能により、詳細なカスタムメトリクスと Dashboard が可能です。 |
| Experiment / Improvement Loop | ●●● | すべてのアセット（プロンプト、データセット、実験）のバージョニングと継続的な Eval による改善ループに重点を置いています。 |
| DevEx / Integration | ●●● | 市場で最も幅広いネイティブ SDK と強力な IDE/フレームワーク統合による、卓越した開発者体験。 |
| Enterprise & Security | ●●● | セルフホスティングと RBAC を備えた堅実なエンタープライズ提供。ただし、自動 PII 墨消しなどの一部の高度なコンプライアンス機能はあまり目立ちません。 |


---

### MLflow

**概要**: MLflow は、GenAI のライフサイクル全体を管理する包括的なオープンソースプラットフォームであり、深い Observability と Eval を従来の MLOps 機能と統合しています。OpenTelemetry 互換の分散 Tracing、継続的モニタリングを備えた高度な 'LLM-as-a-Judge' フレームワーク、およびエンタープライズグレードのエージェント開発のための広範なフレームワークサポート（LangChain, DSPy など）を備えています。

**強み**:
- 従来の MLOps と GenAI/エージェントのライフサイクルの両方を扱う統合プラットフォーム。
- ビジュアルビルダーと自動最適化を備えた 'LLM-as-a-Judge' の深い統合。
- ベンダーニュートラルで OpenTelemetry 互換、ロックインを防止。
- 30 以上のフレームワーク統合による広範なエコシステムサポート。
- 新しいマルチワークスペース組織サポートによる強力なエンタープライズデプロイオプション。

**弱み**:
- 幅広い機能セットは、軽量で特化したツールと比較して設定が複雑になる可能性がある。
- 純粋な SaaS の代替案とは異なり、セルフホスティングにはインフラ（サーバー、DB）の管理が必要。
- 人間によるフィードバック機能は実用的だが、専用の豊富なラベリングスタジオ UI が不足している。
- コストモニタリングは、包括的な FinOps よりも技術的メトリクス（トークン/Judge コスト）に焦点を当てている。

**最新のアップデート**:
- 組織サポート: 実験やリソースを整理するためのマルチワークスペース環境のサポート。(2026-02-12)
- MLflow Assistant: アプリやエージェントのデバッグ、問題解決を支援する Claude Code ベースの製品内チャットボット。(2026-01-29)
- エージェントパフォーマンス Dashboard: レイテンシ、リクエスト数、品質スコアを監視するための構築済みチャート。(2026-01-29)
- MemAlign Judge Optimizer: フィードバックから Eval ガイドラインを学習し、Judge の精度を向上させるアルゴリズム。(2026-01-29)
- Judge Builder UI: コードなしでカスタム LLM Judge プロンプトを作成・テストするためのビジュアルインターフェース。(2026-01-29)
- 継続的オンラインモニタリング: リアルタイムの品質評価のために、流入する Trace に対して LLM Judge を自動的に実行。(2026-01-29)
- 分散 Tracing: コンテキスト伝播を使用して、複数のサービスにわたるリクエストを追跡。(2026-01-29)

| カテゴリ | レーティング | サマリー |
|---|---|---|
| Core Observability | ●●● | OpenTelemetry 上に構築された堅牢な Observability。分散システムや複雑なエージェントワークフローへの深い可視性と、リアルタイムの進行中 Trace 表示を提供します。 |
| Agent / RAG Observability | ●●● | セッション、ツール利用効率、マルチターンの会話のための専門的なビューを備えた、エージェントワークフローの強力なサポート。 |
| Evaluation Integration | ●●● | ビジュアルビルダー、継続的オンラインモニタリング、自動最適化アルゴリズムを特徴とする 'LLM-as-a-Judge' に焦点を当てた、業界をリードする Eval 機能。 |
| Monitoring & Metrics | ●●● | エージェントパフォーマンスのための構築済み Dashboard を備えた強固なモニタリング基盤。ただし、コスト分析は総所有コストよりも Eval/トークンに重点を置いています。 |
| Experiment / Improvement Loop | ●●● | 本番 Trace をプロンプトエンジニアリング、データセットキュレーション、継続的 Eval に結びつける、優れたループ閉鎖機能。 |
| DevEx / Integration | ●●● | 幅広いフレームワークサポート、堅牢な SDK、およびデバッグ用の新しい AI 駆動型アシスタントツールにより、非常に開発者フレンドリーです。 |
| Enterprise & Security | ●●● | 新しいマルチワークスペースサポートと柔軟なデプロイオプションを備えたエンタープライズ対応。ただし、一部の高度なコンプライアンス機能にはマネージドサービスが必要な場合があります。 |


---

### Arize Phoenix

**概要**: Arize Phoenix は、Tracing、Eval、実験を通じて LLM アプリケーションにエンドツーエンドの可視性を提供する、オープンソースの AI Observability および Eval プラットフォームです。CLI、ローカルホスティング機能、および専門的なツールエバリュエーターやデータセット管理を介したエージェントワークフローとの深い統合を含む、強力な開発者ツールを備えています。

**強み**:
- 包括的な CLI とローカルクライアントサポートによる強力な開発者体験
- 開発ループ（Trace -> データセット -> 実験）への Eval の深い統合
- ツール選択および呼び出しエバリュエーターによるエージェント向けの専門的な Observability
- セルフホストの Docker/Kubernetes を含む柔軟なデプロイオプション
- 主要な LLM フレームワークに対する広範な自動インスツルメンテーションサポート

**弱み**:
- 提供されたドキュメント内に明示的な PII マスキング機能がない
- 監査ログ機能の詳細が明示されていない
- ワークフローグラフの可視化が、静的な定義ではなく Trace タイムラインに限定されている
- リージョンサポートは、プラットフォーム全体のデータレジデンシ制御ではなく、主に特定のモデル識別子の文脈で言及されている

**最新のアップデート**:
- OpenAI Responses API タイプのサポート: Playground で OpenAI および Azure OpenAI の Chat Completions と Responses API タイプの選択をサポート。(2026-02-12)
- データセットエバリュエーター: 実験中にサーバー側で自動的に実行されるよう、エバリュエーターをデータセットに直接添付。(2026-02-12)
- Playground およびプロンプト用のカスタムプロバイダー: Playground とプロンプトバージョン間で再利用可能なカスタム AI プロバイダーの集中設定。(2026-02-11)
- Claude Opus 4.6 モデルサポート: 自動コストトラッキングを備えた Playground での Anthropic Claude Opus 4.6 モデルのサポート。(2026-02-09)
- ツール選択およびツール呼び出しエバリュエーター: エージェントのツール選択の正確性と呼び出しパラメータの正しさを評価する専門的なエバリュエーター。(2026-01-31)
- OAuth2 用の構成可能なメール抽出: Azure AD などの OAuth2 プロバイダー向けのカスタムメール抽出パス（例：preferred_username）のサポート。(2026-01-28)
- プロンプト、データセット、実験用の CLI コマンド: ターミナルからプロンプト、データセットを管理し、実験を実行するための新しい CLI コマンド。(2026-01-22)
- Span 関連付けを伴う Trace からのデータセット作成: ソース Span への双方向リンクを保持したまま、Trace をデータセットに変換。(2026-01-21)
- Trace と共にアノテーションをエクスポート: オフライン分析のために Trace と共にアノテーションをエクスポートするための CLI サポート。(2026-01-19)
- AI コーディングアシスタント用の CLI ターミナルアクセス: AI コーディングアシスタント（Cursor, Windsurf）が Phoenix インスタンスをクエリできるようにするための CLI 強化。(2026-01-17)

| カテゴリ | レーティング | サマリー |
|---|---|---|
| Core Observability | ●●● | Phoenix は OpenTelemetry 上に構築された包括的な Tracing 機能を提供し、再生によるデバッグや詳細なタイムラインの可視化を強力にサポートします。 |
| Agent / RAG Observability | ●●● | ツール選択と呼び出しのための専用エバリュエーターに加え、多段階の推論と検索のための堅牢な Tracing を備え、エージェント Observability に優れています。 |
| Evaluation Integration | ●●● | LLM-as-a-judge、カスタムメトリクス、本番トラフィックからのシームレスなデータセット作成を特徴とし、Trace と Eval の間の緊密なループを提供します。 |
| Monitoring & Metrics | ●●● | モニタリング機能は堅牢で、コスト、トークン使用量、およびエージェントのツール利用精度に関する専門的なメトリクスに焦点を当てています。 |
| Experiment / Improvement Loop | ●●● | プロンプトバージョニング、データセット管理、および実験ワークフローに統合された継続的 Eval 機能により、強力な改善ループを可能にします。 |
| DevEx / Integration | ●●● | 強力な CLI、広範なフレームワーク自動インスツルメンテーション、Python および TypeScript 用の柔軟な SDK により、開発者体験が際立っています。 |
| Enterprise & Security | ●●○ | セルフホスティングと RBAC により強固なエンタープライズ基盤を提供していますが、PII マスキングや監査ログなどの特定のコンプライアンス機能は提供されたテキストに詳述されていません。 |


---