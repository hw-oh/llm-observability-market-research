---
layout: default
title: LLM Observability — 製品詳細
---

# LLM Observability — 製品詳細
**日付**: 2026-02-12 | **モデル**: google/gemini-3-pro-preview

### W&B Weave

**概要**: W&B Weaveは、生成AIアプリケーションの構築、デバッグ、Evalのための包括的なツールキットであり、広範な Weights & Biases MLプラットフォームと深く統合されています。実験から本番環境への厳格なループを重視しており、オーディオなどの新しいモダリティにも対応する強力な Tracing、バージョニング、自動 Eval 機能（LLM-as-a-judgeを含む）を提供します。

**強み**:
- W&Bエコシステム（モデル、RL、トレーニング）との深い統合による、完全なMLライフサイクルの実現。
- Dynamic LeaderboardsやAudio Monitorsを含む高度な Eval 機能。
- プロンプト、モデル、データセットのバージョニングに対する強力なサポート。
- Playgroundでカスタム LoRA や Fine-tuning 済みモデルを直接テストできる機能。

**弱み**:
- エンタープライズ向けの競合他社と比較して、PIIマスキングなどの特定のセキュリティ機能に関するドキュメントが少ない。
- メモリ Tracing やリプレイ機能は、特化型のエージェント Observability ツールほど強調されていない。
- 提供されたマーケティングデータでは、Streaming の Tracing 機能が明示的に強調されていない。

**最新のアップデート**:
- Audio Monitors: テキストに加えてオーディオ出力（MP3/WAV）を監視し、オーディオ対応のLLMジャッジを使用して評価するモニター。(2026-02-01)
- Dynamic Leaderboards: 永続的なカスタマイズ、フィルタリング、CSVエクスポート機能を備えた、Eval 結果からのリーダーボード自動生成。(2026-01-29)
- Playgroundでのカスタム LoRA: W&B Artifactsのカスタム Fine-tuning 済み LoRA 重みを、推論や Eval のために Weave Playground で直接使用可能に。(2026-01-16)

| カテゴリ | 評価 | 概要 |
|---|---|---|
| Core Observability | ●●● | Weaveは、ネストされた Tracing、入力、出力、およびレイテンシやトークンなどのパフォーマンスメトリクスの自動キャプチャにより、堅牢なコア Observability を提供します。 |
| Agent / RAG Observability | ●●● | RAGやエージェントのワークフローを強力にサポートし、検索品質の測定や、複雑なマルチステップの実行パスを可視化するための特定の機能を備えています。 |
| Evaluation Integration | ●●● | Weaveの際立ったカテゴリであり、Dynamic Leaderboards、広範な LLM-as-a-judge 機能（オーディオを含む）、およびデータセットとの深い統合を特徴としています。 |
| Monitoring & Metrics | ●●● | コスト、レイテンシ、品質メトリクスを追跡する包括的なモニタリングスイートを提供し、Monitorsを介してオンライン Eval を実行できます。 |
| Experiment / Improvement Loop | ●●● | Weaveは改善ループに優れており、W&Bの成熟したバージョニングと実験管理インフラを活用して、継続的なイテレーションと Fine-tuning をサポートします。 |
| DevEx / Integration | ●●● | 多言語 SDK や、Playground でカスタム LoRA を直接テストできる独自の機能など、優れた開発者体験を提供します。 |
| Enterprise & Security | ●●○ | エンタープライズグレードのデプロイオプション（SaaS、専用、顧客管理型）を提供していますが、PIIマスキングなどの特定のコンプライアンス機能については、今回のアップデートでの記載が少ないです。 |


---

### LangSmith

**概要**: LangSmithは、LLMアプリケーションのライフサイクル全体（開発、デバッグ、デプロイ、モニタリング）に対応する、フレームワークに依存しない包括的なプラットフォームです。LangChain や LangGraph と深く統合しつつ、他のフレームワークもサポートしており、Tracing、Eval、エンタープライズグレードのコラボレーションのための堅牢なツールを提供します。

**強み**:
- 複雑なエージェントワークフローのための LangChain および LangGraph との深い統合。
- ペアワイズ比較や人間によるアノテーションキューを備えた包括的な Eval スイート。
- 強固なエンタープライズコンプライアンス（HIPAA、SOC 2）とセルフホスティングオプション。
- プロンプトエンジニアリング、テスト、デプロイを含むライフサイクル全体のサポート。

**弱み**:
- 料金体系（シート単位 + 使用量）が、大規模なチームや高ボリュームの利用では高価になる可能性がある。
- 機能が豊富なため、LangChain を使用していないユーザーにとっては学習コストがかかる場合がある。
- モデルレジストリや Fine-tuning との直接的な統合は、プロンプト/データセット機能に比べて明示的ではない。

**最新のアップデート**:
- Trace プレビューのカスタマイズ: UIでの Trace プレビューの表示方法をカスタマイズする機能。(2026-02-06)
- Google Gen AI ラッパー: SDKにおける Google Gen AI の新しいラッパーサポート。(2026-01-31)
- LangSmith セルフホスト v0.13: アップデートされたセルフホスト版のリリース。(2026-01-16)

| カテゴリ | 評価 | 概要 |
|---|---|---|
| Core Observability | ●●● | 詳細な階層型 Tracing、コスト/トークン追跡、Playground などの統合デバッグツールにより、優れたコア Observability を提供します。 |
| Agent / RAG Observability | ●●● | エージェントおよび RAG の Observability に特に強みがあり、ツール呼び出し、検索コスト、複雑なマルチステップワークフロー専用のビューを提供します。 |
| Evaluation Integration | ●●● | 自動化されたLLMジャッジ、ペアワイズ比較、人間によるアノテーションとフィードバックのための専用ワークフローを備えた堅牢な Eval スイート。 |
| Monitoring & Metrics | ●●● | コスト、レイテンシ、品質メトリクスに焦点を当てた包括的なモニタリング Dashboard。LLMスタックの異なるコンポーネントごとの詳細な内訳を表示。 |
| Experiment / Improvement Loop | ●●● | プロンプトエンジニアリングとデータセット管理を強力にサポートし、密接なフィードバックループを可能にしますが、直接的なモデルバージョニングや Fine-tuning との連携はそれほど強調されていません。 |
| DevEx / Integration | ●●● | 幅広いフレームワークサポート、堅牢な SDK、CLIツールにより、優れた開発者体験を提供し、様々な開発ワークフローに適応可能です。 |
| Enterprise & Security | ●●● | セルフホスティングオプション、厳格なコンプライアンス認証（HIPAA、SOC 2）、きめ細かなアクセス制御を備えたエンタープライズ対応。 |


---

### Langfuse

**概要**: Langfuseは、オープンソースで開発者優先のLLMエンジニアリングプラットフォームであり、Observability、プロンプト管理、Eval を統合されたワークフローに統合します。深い Tracing 機能で複雑なエージェントシステムをサポートし、エンタープライズのデータ制御のために堅牢なセルフホスティングオプションを提供します。

**強み**:
- 完全にオープンソースでセルフホスト可能であり、最大限のデータプライバシーと制御を提供。
- LLM-as-a-judge、人間によるアノテーションキュー、回帰テストを含む包括的な Eval スイート。
- ツール呼び出し、推論ステップ、セッションメモリを専門的にサポートする深いエージェント Observability。
- バージョニング、Playground、デプロイラベルを備えた統合プロンプト管理システム。
- SSO、RBAC、監査ログを含む強力なエンタープライズ機能セット。

**弱み**:
- 大規模なセルフホスティングには、複雑なインフラ（ClickHouseなど）の管理が必要。
- RLHFワークフローは、完全に管理されたトレーニングループではなく、データセットの収集に限定されている。
- Python/JSのWeb/バックエンドに焦点を当てているため、モバイル専用の SDK サポートはあまり強調されていない。

**最新のアップデート**:
- バージョン管理されたデータセットでの実験実行: 特定のタイムスタンプでデータセットを取得し、再現性のために過去のバージョンで実験を実行。(2026-02-11)
- 単一 Observation の Eval: Trace 内の単一の Observation に対して Eval を追加する機能のサポート。(2026-02-09)
- イベントベースの Trace テーブル: イベント/Observation に基づく新しい Trace テーブルビュー。(2026-02-09)
- 推論/思考 Trace のレンダリング: Trace 詳細における思考および推論部分の視覚的レンダリング。(2026-02-05)
- 組織監査ログビューア: 組織レベルの監査ログを表示するための UI。(2026-02-05)
- 修正済み出力: Fine-tuning データセットを構築するために、Trace ビューでLLM出力の改善バージョンを直接キャプチャ。(2026-01-14)

| カテゴリ | 評価 | 概要 |
|---|---|---|
| Core Observability | ●●● | OpenTelemetryに基づいた包括的な Tracing エンジン。詳細なコストとレイテンシの追跡により、複雑なチェーンを深く可視化。 |
| Agent / RAG Observability | ●●● | エージェントワークフローへの高度なサポート。推論ステップ、ツール使用、セッションメモリの専用の可視化機能を搭載。 |
| Evaluation Integration | ●●● | 自動化されたLLMジャッジ、人間によるアノテーションキュー、回帰テスト用のデータセットベースの実験を組み合わせた堅牢な Eval スイート。 |
| Monitoring & Metrics | ●●● | ClickHouseを搭載したフル機能の分析 Dashboard。コスト、品質、システムパフォーマンスに関するリアルタイムのインサイトを提供。 |
| Experiment / Improvement Loop | ●●● | バージョン管理されたプロンプトとデータセットによる強力なライフサイクル管理。体系的な実験と継続的な改善を可能にします。 |
| DevEx / Integration | ●●● | 幅広い SDK サポート、容易なフレームワーク統合、OpenTelemetryなどのオープンスタンダードへの注力を備えた開発者中心の設計。 |
| Enterprise & Security | ●●● | SSO、RBAC、監査ログ、コンプライアンスのためのセルフホスト機能など、堅牢なセキュリティ機能を備えたエンタープライズ対応。 |


---

### Braintrust

**概要**: Braintrustは、深い Tracing、厳格な Eval（LLM-as-a-judge）、および継続的な改善ループを統合した、包括的なAI Observability および Eval プラットフォームです。広範な SDK サポート、SQLベースのクエリ（BTQL）、Temporal や Cursor といったモダンなワークフローとの統合など、強力な開発者ツールで差別化を図っています。

**強み**:
- 包括的な Eval エコシステム（Playground、LLM-as-a-Judge、オンライン Scoring）
- 広範な SDK とフレームワークのサポート（6言語以上、Temporal、Vercel AI）
- 強力なエンタープライズ/セルフホスティング機能
- 深い開発者ツール（Cursor統合、SQL/BTQLアクセス）
- 統合されたデータセットおよびプロンプト管理

**弱み**:
- ネイティブな Fine-tuning オーケストレーション機能の欠如
- 一般的なエージェント Tracing と比較して、標準で提供される RAG 検索メトリクスが限定的
- PIIマスキングや監査ログなどのセキュリティ機能の詳細が明示されていない
- エージェントの明示的なメモリ状態の Tracing がない

**最新のアップデート**:
- Trace レベルの Scorers: カスタムコードの Scorer が実行 Trace 全体にアクセスし、マルチステップのワークフローを評価可能に。(2026-02-01)
- LangSmith 統合: LangSmith の Trace を Braintrust にルーティングするための実験的なラッパー。(2026-02-01)
- Cursor 統合: Cursor がログを照会し、実験を取得できるようにする MCP サーバー統合。(2026-02-01)
- 添付ファイルのレンダリング: カスタム Trace ビューで、署名付き URL から画像、動画、オーディオをレンダリング可能に。(2026-02-01)
- Trace オリジンへのナビゲーション: Trace から元のプロンプトまたはデータセットの行へ直接移動。(2026-02-01)
- 集計付き単一 Span フィルタ: 単一 Span フィルタと GROUP BY を組み合わせて、集計された Trace 分析を実行。(2026-02-01)
- 自動インストルメンテーション（Python, Ruby, Go）: 主要言語に対するコード記述不要の Tracing サポート。(2026-01-21)
- Temporal 統合: Temporal のワークフローとアクティビティの自動 Tracing。(2026-01-21)
- TrueFoundry 統合: OpenTelemetryを介して TrueFoundry AI Gateway から LLM Trace をエクスポート。(2026-01-21)
- レビュー用カンバンレイアウト: フラグが立てられた Span やレビューを管理するためのドラッグ＆ドロップインターフェース。(2026-01-21)

| カテゴリ | 評価 | 概要 |
|---|---|---|
| Core Observability | ●●● | 詳細な Span 階層、トークン/コスト追跡、Playground を介した開発ループへの深い統合により、堅牢なコア Tracing を提供します。 |
| Agent / RAG Observability | ●●● | エージェントワークフローとツール使用を強力にサポート。特に新しい Temporal 統合が特徴ですが、専門的な RAG 検索メトリクスはそれほど目立ちません。 |
| Evaluation Integration | ●●● | Eval における市場リーダー。Trace、データセット、Scorer（自動および人間の両方）の間の緊密な統合を提供します。 |
| Monitoring & Metrics | ●●● | SQL/BTQLを介した柔軟なカスタムメトリクスによる包括的なモニタリング。ただし、一部のエージェント固有メトリクスは手動でのクエリ構築が必要です。 |
| Experiment / Improvement Loop | ●●● | 実験ループ（プロンプト、データセット、Eval）を強力にサポートし、迅速なイテレーションを可能にしますが、モデルのトレーニング/Fine-tuning の管理まではカバーしていません。 |
| DevEx / Integration | ●●● | 幅広い言語サポート、IDE統合（Cursor）、シームレスなフレームワークフックを備えた、クラス最高の開発者体験。 |
| Enterprise & Security | ●●○ | セルフホスティングと RBAC を備えた強固なエンタープライズ基盤。ただし、監査ログや PII マスキングなどの一部のコンプライアンス機能についてはドキュメントが少ないです。 |


---

### MLflow

**概要**: MLflowは、Observability、Eval、プロンプトエンジニアリングを含む、GenAIライフサイクル全体を管理するオープンソースのオールインワンプラットフォームです。OpenTelemetry互換の Tracing、ビジュアルビルダーを備えた高度な LLM-as-a-Judge 機能、LangGraph や CrewAI などのエージェントフレームワークとの深い統合を特徴としています。

**強み**:
- 1つのプラットフォームで包括的なライフサイクル管理（追跡、レジストリ、Eval、Observability）を実現。
- ビジュアルビルダーと最適化アルゴリズムを備えた高度な LLM-as-a-Judge 機能。
- 完全な OpenTelemetry 互換性を備えた、オープンソースでベンダーニュートラルな設計。
- 人気のあるエージェントフレームワーク（LangGraph, CrewAI）やモデルとの深い統合。

**弱み**:
- オープンソース版では、Trace に対する組み込みの PII マスキング機能が明示されていない。
- Trace のリプレイ機能は、一部の特化型競合ツールほど合理化/明示されていない。
- 高度なエンタープライズコンプライアンス機能（監査ログ）は、コアの OSS 版では制限されている。

**最新のアップデート**:
- 組織サポート: 実験やリソースを整理するためのマルチワークスペース環境のサポート。(2026-02-12)
- MLflow Assistant: 問題の診断と修正を支援する、Claude Code を搭載した製品内チャットボット。(2026-01-29)
- エージェントパフォーマンス Dashboard: エージェントのレイテンシ、リクエスト数、品質スコアを監視するための構築済みチャート。(2026-01-29)
- MemAlign Judge Optimizer: 過去のフィードバックから Eval ガイドラインを学習し、ジャッジの精度を向上させるアルゴリズム。(2026-01-29)
- Judge Builder UI: カスタムLLMジャッジプロンプトを作成、テスト、エクスポートするためのビジュアルインターフェース。(2026-01-29)
- 継続的オンラインモニタリング: 本番環境の着信 Trace に対して LLM ジャッジを自動的に実行。(2026-01-29)
- 分散 Tracing: コンテキスト伝播により、複数のサービスにわたるリクエストを追跡。(2026-01-29)

| カテゴリ | 評価 | 概要 |
|---|---|---|
| Core Observability | ●●● | OpenTelemetry互換性、深い Trace キャプチャ、マイクロサービス向けの新しい分散 Tracing 機能による堅牢なコア Observability。 |
| Agent / RAG Observability | ●●● | セッション、ツール使用効率、マルチターン推論専用のビューを備えた、エージェントワークフローへの強力なサポート。 |
| Evaluation Integration | ●●● | ビジュアル Judge Builder、自動最適化アルゴリズム（MemAlign）、継続的なオンラインモニタリングを備えた包括的な Eval スイート。 |
| Monitoring & Metrics | ●●● | 新しいエージェントパフォーマンス Dashboard により、コスト、レイテンシ、品質メトリクスをすぐに可視化できます。 |
| Experiment / Improvement Loop | ●●● | 継続的な Eval、プロンプト最適化アルゴリズム、実験とレジストリ間の緊密な統合により、優れたループの閉鎖を実現。 |
| DevEx / Integration | ●●● | 新しい MLflow Assistant、幅広いフレームワークサポート、柔軟なデプロイオプションによる高い開発者体験。 |
| Enterprise & Security | ●●○ | 組織サポートや認証によりエンタープライズ機能は向上していますが、高度なコンプライアンス（PII、監査）は OSS 版ではあまり明示されていません。 |


---

### Arize Phoenix

**概要**: Arize Phoenixは、AIアプリケーションのデバッグ、テスト、モニタリングのために設計された、オープンソースの LLM Observability および Eval プラットフォームです。本番環境の Tracing をオフライン Eval、データセット管理、プロンプトエンジニアリングに接続する統合ワークフローを提供し、Python と TypeScript の両方のエコシステムをサポートしています。

**強み**:
- 柔軟なセルフホスティングオプション（Docker/K8s）を備えた強力なオープンソース基盤。
- 本番環境の Trace を Eval データセットに変換するためのシームレスなワークフロー。
- 特定のツール選択や呼び出しメトリクスを含む、高度なエージェント Eval 機能。
- 包括的な SDK、CLIツール、自動インストルメンテーションによる堅牢な開発者体験。
- 迅速なイテレーションとバージョニングのための統合 Prompt Playground。

**弱み**:
- 明示的な PII マスキングやデータサニタイズ機能の欠如。
- エンタープライズコンプライアンスのための組み込み監査ログ機能についての言及がない。
- モデルバージョニングは、完全なモデルレジストリではなく、設定の追跡に限定されている。
- 直接的な RLHF トレーニングループの統合がない（エクスポートのみ）。

**最新のアップデート**:
- OpenAI Responses API タイプのサポート: Playground およびカスタムプロバイダーでの OpenAI API タイプ（Chat Completions vs Responses）の選択をサポート。(2026-02-12)
- データセット Evaluators: 実験中にサーバー側で自動的に実行される Evaluator をデータセットに直接アタッチ。(2026-02-12)
- Playground 用カスタムプロバイダー: Playground とプロンプト全体で再利用可能なカスタムモデルプロバイダーの一元設定。(2026-02-11)
- Claude Opus 4.6 サポート: 拡張思考パラメータを備えた Anthropic の Claude Opus 4.6 モデルのサポート。(2026-02-09)
- ツール選択 & 呼び出し Evaluators: エージェントのツール選択の正確性とパラメータ形式を評価するための専用 Evaluator。(2026-01-31)
- プロンプト/データセット用 CLI コマンド: ターミナルからプロンプト、データセット、実験を管理するための新しい CLI コマンド。(2026-01-22)
- Trace からのデータセット作成: Span の関連付けを維持したまま、本番 Trace をデータセットに変換。(2026-01-21)
- Trace と共のアノテーションエクスポート: オフライン分析のために、アノテーションと共に Trace をエクスポートするための CLI サポート。(2026-01-19)

| カテゴリ | 評価 | 概要 |
|---|---|---|
| Core Observability | ●●● | OpenTelemetryに基づいた堅牢なコア Observability を提供。詳細な階層型 Tracing、レイテンシのタイムライン分析、デバッグのための Span リプレイ機能を備えています。 |
| Agent / RAG Observability | ●●● | 専用のツール選択/呼び出し Evaluator とマルチステップ推論の深い Tracing により、エージェント Observability に優れています。ただし、可視化はグラフベースではなく主に Trace ベースです。 |
| Evaluation Integration | ●●● | Eval は核心的な強みであり、Trace とデータセット間の緊密なループ、広範な LLM-as-a-judge 機能、統合された人間によるフィードバックワークフローを備えています。 |
| Monitoring & Metrics | ●●● | 自動化されたコストとトークンの追跡に加え、エージェントのツール使用やカスタム Eval スコアのための専用メトリクスを含む包括的なモニタリングを提供します。 |
| Experiment / Improvement Loop | ●●● | プロンプトエンジニアリングと実験追跡のための強力な機能により迅速なイテレーションが可能ですが、モデルバージョニングと Fine-tuning はネイティブ管理ではなく設定とエクスポートを介して行われます。 |
| DevEx / Integration | ●●● | 広範な SDK、強力な CLI、幅広いフレームワークの自動インストルメンテーションにより、既存のワークフローへの統合が容易で、優れた開発者体験を提供します。 |
| Enterprise & Security | ●●○ | 強力なセルフホスティングと基本的なアクセス制御オプションは多くのエンタープライズニーズに適していますが、PIIマスキングや監査ログなどの特定のコンプライアンス機能の詳細は不明です。 |


---