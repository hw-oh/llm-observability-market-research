---
layout: default
title: LLM Observability — 製品詳細
---

# LLM Observability — 製品詳細
**日付**: 2026-02-12 | **モデル**: google/gemini-3-pro-preview

### W&B Weave

**概要**: W&B Weaveは、Weights & Biasesのエコシステムに深く統合された、LLMアプリケーションの構築、デバッグ、Evalのための開発者中心のツールキットです。プログラムによる「LLM-as-a-Judge」Evalや複雑なエージェントワークフローのTracingに優れていますが、現在はUIベースの人間によるアノテーションや運用アラートよりも、コードベースのワークフローを優先しています。

**長所**:
- W&B Experimentsとの深い統合により、モデルバージョン、トレーニングデータ、Evalを統一して追跡可能。
- 「LLM-as-a-Judge」と動的なリーダーボードを備えた強力なプログラムEvalフレームワーク。
- ネストされたTracing、エージェントの推論、コスト追跡のための豊富なインタラクティブ可視化。
- セルフホストオプション、SOC 2コンプライアンス、監査ログを備えた強力なエンタープライズ体制。

**短所**:
- 人間によるフィードバック、アノテーション、ラベル付け（Human-in-the-loop）のための組み込みUIがない。
- エラー率やレイテンシの異常に対する運用アラート機能の欠如。
- ドリフト検出や埋め込み空間のクラスタリングなどの高度な分析機能がない。
- 専用のCLIツールや明示的なCI/CDパイプライン統合がない。

**最新のアップデート**:
- Audio Monitors: LLM Judgeを使用して、テキストと共にオーディオ出力（MP3/WAV）を監視・判定するオンラインEvalモニター。（2026-02-01）
- Dynamic Leaderboards: フィルタ、永続的なカスタマイズ、CSVエクスポート機能を備えた、Evalからの自動生成リーダーボード。（2026-01-29）
- PlaygroundでのカスタムLoRA: Fine-tuningされたLoRAの重みをPlaygroundに持ち込み、推論と比較を行うためのサポート。（2026-01-16）

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | W&B Weaveは、ネストされたTracing、デコレータによる自動インストルメンテーション、プロンプト/レスポンスの自動キャプチャ、トークン使用量、レイテンシ、コスト、メタデータ、OpenTelemetry統合を強力にサポートし、堅牢なTracingとLoggingを提供します。Traceツリーにより、詳細なデバッグと本番環境の監視が可能です。Streaming Tracingはasyncジェネレータを介して中程度にサポートされていますが、リアルタイムLLM Streamingの詳細はあまり明示されていません。 |
| Agent & RAG Observability | ●●● | W&B Weaveは、Traceツリーとインタラクティブなビューを通じて、ツール、RAGパイプライン、多段階の推論を堅牢にTracingし、エージェントとRAGのObservabilityに優れています。フレームグラフやコンポジショングラフなどの強力なワークフロー可視化を提供し、MCP統合とデバッグ機能を備えています。明示的なA2Aプロトコルサポートや詳細なセッショングループ化にはわずかなギャップがあります。 |
| Evaluation & Quality | ●●○ | W&B Weaveは、カスタムおよび構築済みのScoring、データセット、サイドバイサイド比較、リーダーボードを強力にサポートする堅牢なEvalフレームワークを提供します。ビジュアルツールは、レイテンシやトークンなどのメトリクスを含め、モデル間のEval比較に優れています。人間のUI、直接的なTrace変換、自動回帰検出、CI/CD、および明示的なオンライン監視にはギャップがあります。 |
| Guardrails & Safety | ●●● | W&B Weaveは、有害性、PII、バイアス、ハルシネーション、品質の問題をリアルタイムで検出する、構築済みおよびカスタムのScoringを通じて堅牢なGuardrailsを提供します。これらは、レスポンスの前後で安全でないコンテンツをブロックまたは修正でき、監視のために自動的にLoggingされます。PII検出はサポートされていますが、自動マスキングについては詳しく説明されていません。 |
| Monitoring & Analytics | ●●○ | W&B Weaveは、自動監視とインタラクティブなDashboardを通じて、LLMのコスト追跡、トークン使用量分析、カスタムメトリクスに優れています。強力なレイテンシ監視を提供しますが、アラート、エラー率、ドリフト検出、埋め込み分析が不足しています。全体として、デバッグとEvalのための可視化ツールを備えた、コアLLMメトリクスの堅牢なObservabilityを提供します。 |
| Experiment & Improvement Loop | ●●○ | W&B Weaveは、Tracing、Ops/オブジェクトのバージョニング、およびLLMの開発とトレーニング中の実験追跡のためのW&Bとの統合に優れています。TraceツリーとUIツールによる強力なデバッグを提供しますが、自動トレーニングデータ生成機能がありません。Fine-tuningのサポートはRun統合を通じて存在し、堅牢な失敗分析機能を備えています。 |
| Developer Experience & Integration | ●●○ | W&B Weaveは、LLMとエージェントの容易なTracingと統合を可能にする堅牢な公式PythonおよびTypeScript SDKにより、Developer Experienceに優れています。カスタムモデルや様々なフレームワークをサポートしていますが、明示的なREST/GraphQL API、CLIツール、またはノートブック統合が不足しています。全体として、シームレスなワークフロー埋め込みのためのコードベースのObservabilityを優先しています。 |
| Infrastructure & Enterprise | ●●● | W&B Weaveは、強力なSaaS、セルフホスト、SOC 2、監査ログ、およびデプロイオプション全体でのデータレジデンシサポートを備えた、堅牢なエンタープライズインフラストラクチャを提供します。SSOやPII墨消しなどのセキュリティ機能は十分にカバーされていますが、RBACやVPCの詳細は不足しています。統合面ではDatabricksよりもW&Bエコシステムが優先されています。 |


---

### LangSmith

**概要**: LangSmithは、複雑なチェーンやエージェント向けに調整された、深いObservability、Eval、コラボレーションツールを提供するLLMアプリケーション用の包括的なDevOpsプラットフォームです。堅牢なTracing、LLM-as-judge Eval機能、シームレスなデータセット管理ワークフローにより、プロトタイピングと本番環境のギャップを埋めます。

**長所**:
- フレームワークに依存しない一方で、LangChainエコシステムと深く統合。
- カスタムScoringを備えた包括的なLLM-as-judge Evalフレームワーク。
- 本番環境のTracingをEvalデータセットに変換するシームレスなワークフロー。
- 複雑なエージェントワークフローと多段階推論のデバッグを強力にサポート。
- 機能豊富なSDKとノートブック統合による堅牢なDeveloper Experience。

**短所**:
- ネイティブなブロッキングGuardrailsの欠如（監視/Evalに依存）。
- モデルの入出力に対する組み込みのドリフト検出がない。
- 従来のML実験追跡ツール（MLflow、W&Bなど）との統合がない。
- 埋め込み空間の可視化のための高度な分析機能が限定的。
- オープンソースのコアコンポーネントを持たないプロプライエタリな性質。

**最新のアップデート**:
- Client SDK Updates (v0.7.x): バグ修正と依存関係の更新を含む、PythonおよびJSクライアントライブラリのアップデート。（2026-02-10）
- Customize Trace Previews: LangSmith UI内でのTracingのプレビュー方法をカスタマイズする新機能。（2026-02-06）
- LangSmith Self-Hosted v0.13: セルフホスト型エンタープライズデプロイオプションの新しいバージョンリリース。（2026-01-16）

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | LangSmithは、LLMチェーンとエージェントに対する包括的な可視性、自動インストルメンテーション、堅牢なトークン/コスト追跡、およびOpenTelemetry統合に支えられ、コアTracingにおいて優れています。 |
| Agent & RAG Observability | ●●● | このプラットフォームは、詳細なツールと検索のTracingを特徴とし、エージェントとRAGに対して強力なObservabilityを提供しますが、明示的なワークフローグラフの可視化やニッチなプロトコルサポートは欠けています。 |
| Evaluation & Quality | ●●● | LangSmithはEvalのリーダーであり、LLM-as-judge、人間によるアノテーション、データセット管理のための堅牢なツールスイートを提供し、本番から開発への緊密なフィードバックループを促進します。 |
| Guardrails & Safety | ●●○ | 安全機能は強制よりも監視とEvalに重点を置いており、Evaluatorによるカスタム検出には優れていますが、ネイティブなブロッキングGuardrailsや自動マスキングは不足しています。 |
| Monitoring & Analytics | ●●○ | コスト、トークン、エラーに関する強力なコア監視が提供されていますが、ドリフト検出やカスタムメトリクスDashboardなどの高度な分析はあまり開発されていません。 |
| Experiment & Improvement Loop | ●●● | このプラットフォームは、強力なプロンプト/モデルバージョニングとPlayground機能を備えた堅牢な実験ループを提供し、効果的な反復改善を可能にしますが、Fine-tuning統合は欠けています。 |
| Developer Experience & Integration | ●●● | Developer Experienceは大きな特徴であり、PythonとJS用の堅牢なSDK、深いフレームワーク統合、強力なAPIサポートにより、エンジニアにとって非常にアクセスしやすくなっています。 |
| Infrastructure & Enterprise | ●●○ | LangSmithは、SaaSおよびセルフホストオプション、RBAC、監査ログを備えた堅実なエンタープライズインフラストラクチャを提供しますが、成熟したエンタープライズツールで一般的な一部の認証や統合が不足しています。 |


---

### Langfuse

**概要**: Langfuseは、Observability、Tracing、Evalに優れた、開発者中心のオープンソースLLMエンジニアリングプラットフォームです。マネージドクラウドサービスと共に堅牢なセルフホスト機能を提供し、データの主権を必要とするエンタープライズ環境に高度に適応します。エージェントやRAGパイプラインの深いTracingを強力なEvalスイートと統合していますが、安全Guardrailsや高度なドリフト検出については外部統合に依存しています。

**長所**:
- 包括的なオープンソースおよびセルフホスト機能（Docker/K8s）。
- 複雑なエージェントワークフローとRAGパイプラインのための堅牢なTracing。
- LLM-as-a-Judgeと人間によるアノテーションを備えた統合Evalスイート。
- 型定義されたSDKとプロンプト管理による強力なDeveloper Experience。

**短所**:
- 組み込みの安全Guardrails（PII、有害性）が不足しており、外部統合が必要。
- ネイティブなドリフト検出や埋め込み空間分析がない。
- 競合他社と比較して、自動コスト見積もりロジックが限定的。
- 継続的/スケジュールされたEvalトリガーの欠如。

**最新のアップデート**:
- Single Observation Evals: 単一のObservationに対してEvalを実行するサポートを追加。（2026-02-12）
- Events-based Trace Table: 可視性を高めるため、TraceおよびObservationテーブルをイベントベースにリファクタリング。（2026-02-12）
- Reasoning/Thinking Trace Rendering: Trace詳細において、思考および推論部分（推論モデルなど）のレンダリングサポートを追加。（2026-02-12）
- Org Audit Log Viewer: 組織レベルの監査ログ用の新しいビューア。（2026-02-12）
- Inline Trace Comments: Trace内のIOデータの一部にインラインでコメントを追加可能に。（2026-02-12）
- Corrections in Trace Preview: TraceおよびObservationのプレビューで修正を直接表示・管理するサポートを追加。（2026-02-12）

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | Langfuseは、ネストされたSpan、自動インストルメンテーション、OpenTelemetryを強力にサポートし、堅牢なコアTracingを提供します。レイテンシやトークンなどのテクニカルメトリクスの取得には優れていますが、ネイティブな自動コスト見積もりが不足しており、Streaming Tracingには非同期バッチ処理に依存しています。 |
| Agent & RAG Observability | ●●● | このプラットフォームは、エージェントおよびRAGアーキテクチャに対して包括的なObservabilityを提供し、ワークフロー、ツール呼び出し、多段階推論の強力な可視化を特徴としています。現在はMCPのような専門的なエージェントプロトコルのサポートが不足しており、自動化された失敗のハイライト機能も部分的です。 |
| Evaluation & Quality | ●●● | Langfuseは、LLM-as-a-Judge、カスタムScoring、人間によるアノテーションワークフローを備えた強力なEvalスイートを提供します。回帰検出とオンライン監視を効果的にサポートしていますが、CI/CD統合やリーダーボード機能はあまり形式化されていません。 |
| Guardrails & Safety | ●●○ | 安全機能は主にユーザー定義であり、カスタムGuardrails ScoringとObservationを強力にサポートしています。プラットフォームにはPIIや有害性に関するネイティブな組み込みGuardrailsが不足しており、ユーザーはこれらのチェックのために外部ライブラリを統合する必要があります。 |
| Monitoring & Analytics | ●●○ | コスト、トークン、エラーなどの運用メトリクスの監視機能は強力で、カスタマイズ可能なDashboardを備えています。しかし、ドリフト検出や埋め込み空間分析などの高度なデータサイエンス監視機能は現在ありません。 |
| Experiment & Improvement Loop | ●●○ | Langfuseは、プロンプトバージョニング、Playground、実験追跡により、堅実な実験ループをサポートしています。スケジュールされたEval、自動的な失敗抽出、直接的なFine-tuningパイプライン統合が不足しており、自動化された継続的改善の面ではまだ成熟の余地があります。 |
| Developer Experience & Integration | ●●● | このプラットフォームは、PythonおよびTypeScript用の堅牢なSDKと、シームレスなフレームワーク統合により、強力なDeveloper Experienceを提供します。APIアクセスは包括的ですが、専用のCLIツールや専門的なノートブック可視化ウィジェットが不足しています。 |
| Infrastructure & Enterprise | ●●○ | Langfuseは、強力なオープンソース、セルフホスト、SaaSオプションを備え、非常に柔軟です。RBACや監査ログ（ライセンス経由）などのエンタープライズニーズをサポートしていますが、明示的なSOC 2認証やMLflowのような従来のMLプラットフォームとの統合が不足しています。 |


---

### Braintrust

**概要**: Braintrustは、本番環境のTracingと堅牢な実験ループを緊密に統合する、エンタープライズグレードのAI ObservabilityおよびEvalプラットフォームです。強力な「Evalファースト」のアプローチで差別化を図っており、開発者が本番ログをEvalデータセットにシームレスに移行できるようにし、データプライバシーのためのハイブリッドセルフホストオプションによってサポートされています。自動インストルメンテーションとプロンプト管理のための包括的なSDKを提供し、特に複雑なエージェントワークフローを構築するエンジニアリングチームを対象としています。

**長所**:
- 本番TracingをEvalデータセットや実験に直接接続する統一されたワークフロー。
- 顧客のVPC内にデータを保持するハイブリッドセルフホストオプションによる強力なエンタープライズセキュリティ。
- LangChainやVercel AIなどの一般的なフレームワーク向けの自動インストルメンテーションを備えた堅牢なSDK。
- Evalループに統合された柔軟なカスタムScoringと「LLM-as-a-judge」機能。
- バージョニングと双方向のPlayground同期を備えた包括的なプロンプト管理。

**短所**:
- PIIや有害性のための組み込み検出器の欠如（カスタム設定に依存）。
- エンタープライズライセンスなしでのセルフホスト用のオープンソースコアやコミュニティエディションがない。
- 従来のML実験追跡ツール（MLflow、W&B）との統合が限定的。
- ドリフト検出や埋め込み分析などの高度なデータサイエンス監視機能の欠如。
- 外部データウェアハウスへのデータエクスポートのネイティブサポートがない。

**最新のアップデート**:
- Claude Agent SDKのサブエージェントネスト: Claude Agent SDKラッパー内でのネストされたサブエージェントTracingのサポートを追加。（2026-02-12）
- Review Span Type: 人間によるレビューワークフローをサポートするため、SDKに新しい「Review」Spanタイプを導入。（2026-02-12）
- Classifications Field: Spanの構造化されたカテゴリ化をサポートするため、Tracingに「Classifications」フィールドを追加。（2026-01-31）
- Disable Cache on Eval: 最新の結果を確実にするため、Eval実行中にキャッシュをオフにする新しいオプション。（2026-01-29）
- Workflow Terminology: より幅広いユースケースを反映させるため、SDKとUIで「agents」を「workflows」に名称変更。（2026-01-15）

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | Braintrustは、強力な自動インストルメンテーションと、ネストされたSpan、トークン追跡、コスト分析のネイティブサポートを備えた包括的なTracingスイートを提供します。詳細なコンテキスト（プロンプト/レスポンス）のキャプチャに優れ、OpenTelemetryのようなオープンスタンダードとうまく統合されています。 |
| Agent & RAG Observability | ●●○ | このプラットフォームは、詳細なツール呼び出しTracingと検索パイプライン向けの特定のメトリクスを特徴とし、エージェントとRAGに対して強力なObservabilityを提供します。多段階の推論をうまく処理しますが、MCPのような新しいエージェントプロトコルへの専門的なサポートは欠けています。 |
| Evaluation & Quality | ●●● | Evalは核心的な強みであり、本番Tracingからデータセット、実験までの完全なループを提供します。幅広いScoring手法（LLM-as-judge、カスタム、人間）をサポートし、CI/CDや回帰テストを通じて開発ワークフローに深く統合されています。 |
| Guardrails & Safety | ●●○ | 安全機能は、標準のフィルタよりも、設定可能な品質ゲートとカスタムScoringに重点を置いています。堅牢なカスタムGuardrailsとフックを可能にしますが、ネイティブなPIIマスキングや構築済みの有害性検出は不足しています。 |
| Monitoring & Analytics | ●●○ | コスト、トークン、エラーなどの運用メトリクスの監視機能は堅実で、カスタム品質メトリクスをサポートしています。しかし、ドリフト検出や埋め込み分析などの高度なデータサイエンス監視機能は欠けています。 |
| Experiment & Improvement Loop | ●●● | Braintrustは改善ループにおいて優れており、Playground、実験、データセット間の緊密な統合を提供します。Tracingからトレーニングデータを生成し、プロンプトをバージョニングする機能により、反復的な開発のための強力なツールとなっています。 |
| Developer Experience & Integration | ●●○ | Developer Experienceは優先度が高く、PythonおよびTypeScript/JS用の強力なSDKと効果的なCLIツールを備えています。フレームワークの統合は自動インストルメンテーションラッパーを介してうまく処理されていますが、直接的なAPIアクセスやノートブックの可視化は限定的です。 |
| Infrastructure & Enterprise | ●●○ | Braintrustは、ハイブリッドセルフホストと標準的なセキュリティコンプライアンス（SOC 2、SSO、RBAC）を強力にサポートし、安全でエンタープライズ対応のインフラストラクチャを提供します。データのプライバシーを必要とする組織に適していますが、オープンソースの選択肢や従来のデータウェアハウスとの深い統合は欠けています。 |


---

### MLflow

**概要**: MLflowは、堅牢なTracing、Eval、実験追跡機能により、GenAI分野へ大幅に拡張された成熟したオープンソースMLOpsプラットフォームです。自動インストルメンテーション、モデルバージョニング、Databricksとの統合に優れていますが、RBACや高度なGuardrailsなどのエンタープライズセキュリティ機能については外部統合に依存しています。

**長所**:
- 強力なコミュニティサポートと柔軟性を備えた広範なオープンソースエコシステム。
- LangChainなどの主要なGenAIフレームワークに対する堅牢な自動インストルメンテーション（Autolog）。
- クラス最高の実験追跡およびモデル/プロンプトバージョニング機能。
- エンタープライズ規模のデプロイメントのためのDatabricksとの深い統合。
- LLM-as-a-Judgeや人間によるフィードバックUIを含む包括的なEvalスイート。

**短所**:
- オープンソース版におけるネイティブなエンタープライズセキュリティ機能（RBAC、SSO）の欠如。
- 組み込みのGuardrailsやPII検出機能がない。
- エージェント用のワークフローグラフのような高度な可視化ツールが不足。
- プロンプトエンジニアリング用のインタラクティブなLLM Playgroundがない。
- ドリフト検出や埋め込み分析などの高度な監視機能が限定的。

**最新のアップデート**:
- MLflow Tracking Serverでの組織サポート: 異なるワークスペース間で実験やリソースを整理できる、マルチワークスペース環境のサポート。（2026-02-12）
- MLflow Assistant: UI内で直接問題を特定、診断、修正するのを支援する、Claude Codeをバックエンドとした製品内チャットボット。（2026-01-29）

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | MLflowは、堅牢な自動インストルメンテーションとOpenTelemetry互換性により、GenAI Tracingの強力な基盤を提供します。トークンやレイテンシなどの必須メトリクスを効果的にキャプチャしますが、現在は組み込みのコスト見積もりや専門的なStreaming Traceの可視化が不足しています。 |
| Agent & RAG Observability | ●●○ | このプラットフォームは、ツール呼び出しTracingと多段階推論の可視化を通じて、エージェントのObservabilityをうまくサポートしています。しかし、ワークフローグラフのような高度な可視化や、RAGドキュメント検索、新興のエージェントプロトコルに対する専門的なサポートは欠けています。 |
| Evaluation & Quality | ●●● | MLflowは、LLM-as-a-judge、カスタムScoring、人間によるフィードバックを強力にサポートする包括的なEvalスイートを提供します。データセット管理やアドホックな比較には優れていますが、自動回帰検出やCI/CD統合には改善の余地があります。 |
| Guardrails & Safety | ●●○ | 安全性とGuardrailsはMLflowのネイティブな強みではなく、これらの機能については完全に外部統合に依存しています。Tracingを通じてGuardrailsの実行に対する可視性を提供しますが、組み込みの検出や強制メカニズムは提供していません。 |
| Monitoring & Analytics | ●●○ | MLflowは、トークン使用量、エラー率、レイテンシなどの運用メトリクスに対して堅実な監視を提供します。しかし、ドリフト検出や埋め込み分析などの高度なデータサイエンス監視機能は不足しています。 |
| Experiment & Improvement Loop | ●●● | このプラットフォームは、プロンプトとモデルのクラス最高のバージョニング、および強力な実験追跡により、実験ループにおいて優れています。失敗抽出を通じて反復的な改善をうまくサポートしていますが、インタラクティブなLLM Playgroundが不足しています。 |
| Developer Experience & Integration | ●●● | MLflowは、成熟したSDK、API、CLIツールにより、強力なDeveloper Experienceを提供します。Autologgingを通じて主要なフレームワークとうまく統合されていますが、ノートブック統合は機能的であるものの、埋め込み可視化が不足しています。 |
| Infrastructure & Enterprise | ●●○ | MLflowはセルフホストおよびオープンソースインフラストラクチャの強力なツールであり、計り知れない柔軟性を提供します。しかし、オープンソース版にはRBACやSSOなどの重要なエンタープライズ機能が欠けており、これらは通常Databricksのマネージドサービスを通じて提供されます。 |


---

### Arize Phoenix

**概要**: Arize Phoenixは、LLMアプリケーション向けに設計されたオープンソースのコードファーストなObservabilityおよびEvalプラットフォームであり、TracingにOpenTelemetryを多用しています。ローカル開発ループ、実験追跡、埋め込み分析による深いトラブルシューティングに優れており、広範なArizeエコシステムとの統合を通じて本番監視へのシームレスなパスを提供します。

**長所**:
- 主要なフレームワークに対する1行の自動インストルメンテーションを備えた深いOpenTelemetry統合。
- 完全なセルフホストとデータ制御を可能にする堅牢なオープンソース基盤。
- 埋め込み分析やドリフト検出を含む高度なトラブルシューティングツール。
- 構築済みおよびカスタムメトリクスを備えた包括的なLLM-as-a-judge Evalスイート。
- モジュール式のPython SDKとAPIファーストの設計による強力なDeveloper Experience。

**短所**:
- 組み込みのGuardrailsがなく、完全に外部統合に依存。
- 自動EvalパイプラインのためのネイティブなCI/CD統合の欠如。
- 財務的な可視性のための専用コストDashboardがない。
- コアとなるオープンソース版ではエンタープライズ機能（RBAC、SOC 2）が限定的。
- ターミナルベースのワークフローのための専用CLIツールがない。

**最新のアップデート**:
- PlaygroundでのClaude Opus 4.6: Playground環境内でのClaude Opus 4.6モデルのサポートを追加。（2026-02-09）
- Tool Selection Evaluator: エージェントにおけるツール選択の正確性を評価するための新しいEvaluatorを追加。（2026-02-06）
- Faithfulness Evaluator: レスポンスの根拠（Grounding）をチェックするためのFaithfulnessEvaluatorを導入し、HallucinationEvaluatorを非推奨化。（2026-02-02）
- Tool Invocation Accuracy Metric: ツール呼び出しの精度を測定するための新しいメトリクス。（2026-02-02）
- Configurable OAuth2 Email Extraction: OAuth2の構成可能なメール抽出を可能にするEMAIL_ATTRIBUTE_PATHを追加。（2026-01-28）
- Metric CreationのCursor Rule: 新しい組み込みLLM分類Evaluatorの作成を容易にするためのCursor Ruleを追加。（2026-01-21）

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Tracing & Logging | ●●● | PhoenixはOpenTelemetry上に構築された最高水準のTracing体験を提供し、最小限のセットアップ作業でトークン、コスト、レイテンシに対する包括的な可視性を提供します。 |
| Agent & RAG Observability | ●●● | エージェントとRAGパイプラインのデバッグ、特にツールの使用状況や推論ステップのキャプチャにおいて強力な機能を備えていますが、視覚的なワークフロー表現はさらに進化させる余地があります。 |
| Evaluation & Quality | ●●○ | Phoenixは、堅牢なLLM-as-a-judge機能を備えたオフラインEvalと実験分析において輝きを放っていますが、ネイティブなCI/CD統合や自動化されたオンラインEvalワークフローは不足しています。 |
| Guardrails & Safety | ●●○ | 安全機能は、ネイティブな組み込み機能ではなく、主に統合（Guardrails AIなど）を通じて提供されるため、強制については外部ライブラリに依存しています。 |
| Monitoring & Analytics | ●●● | 深いドリフト検出と埋め込み分析を備えたテクニカルな監視には優れていますが、ハイレベルな財務/コストDashboardは不足しています。 |
| Experiment & Improvement Loop | ●●○ | 反復的な実験とプロンプトエンジニアリングのための強力なプラットフォームであり、開発者がパフォーマンスの変化を密接に追跡することを可能にしますが、継続的Evalのための自動化が不足しています。 |
| Developer Experience & Integration | ●●○ | 優れたSDKとフレームワークサポートを備えたPython開発者向けに構築されており、既存のコード中心のワークフローへの統合が容易です。 |
| Infrastructure & Enterprise | ●●○ | セルフホストとオープンソースコードを通じてデータの主権を必要とするチームには理想的ですが、SOC 2や複雑なRBACなどの標準的なエンタープライズコンプライアンス機能の一部が不足している可能性があります。 |


---