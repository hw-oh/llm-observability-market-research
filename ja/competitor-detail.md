---
layout: default
title: LLM Observability — 製品詳細
---

# LLM Observability — 製品詳細
**日付**: 2026-02-12 | **モデル**: google/gemini-3-pro-preview

### W&B Weave

**概要**: W&B Weaveは、Weights & Biasesのエコシステムと深く統合された、コンポーザブルなLLMアプリケーション構築のための開発者中心のObservabilityおよびEvalプラットフォームです。複雑なエージェントのワークフローのTracingや、LLM-as-a-judgeを使用した体系的なEvalに優れており、プロンプトやモデルの堅牢なバージョニングを提供しながら、実験と本番環境のモニタリングのギャップを埋めます。

**強み**:
- W&Bエコシステム（Models、Registry）との深い統合により、実験から本番までのフルライフサイクル管理が可能。
- LLM-as-a-judge、動的リーダーボード、ヒューマンフィードバックUIを含む強力なEval機能。
- ツール呼び出しや検索ステップを含む、複雑なエージェントワークフローに対する堅牢なTracing。
- セルフホストVPCや強力なリージョンサポートを含む、柔軟なエンタープライズデプロイメントオプション。

**弱み**:
- 直感的なエージェントのデバッグのための、視覚的なワークフローグラフやDAGの可視化の欠如。
- 会話型メモリのTracing（読み取り/書き込み）に対する明示的なサポートがない。
- 特化型のモニタリングツールと比較して、標準での自動回帰アラート機能が限定的。

**最新のアップデート**:
- Audio Monitors: LLM judgeを使用して音声出力（MP3/WAV）を評価し、会話の質を評価する機能のサポート。(2026-02-01)
- Dynamic Leaderboards: Evalから自動生成されるリーダーボード。永続的なカスタマイズとCSVエクスポートが可能。(2026-01-29)
- PlaygroundでのカスタムLoRA: Weave PlaygroundでカスタムFine-tuningされたLoRAの重みを直接使用し、推論と比較を行う機能のサポート。(2026-01-16)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Observability | ●●● | Weaveは、深いネスト構造のTracing、入力・出力・トークン使用量の自動キャプチャ、インタラクティブな可視化ツールを備えた堅牢なコアObservabilityスイートを提供します。 |
| Agent / RAG Observability | ●●○ | エージェントワークフローにおけるツール呼び出しやRAGの検索ステップのTracingを強力にサポートしていますが、視覚的なワークフローグラフや明示的なメモリTracing機能が不足しています。 |
| Evaluation Integration | ●●● | 本番環境とテストを橋渡しする包括的なEvalスイートを備え、強力なLLM-as-a-judgeサポート、ヒューマンフィードバックツール、詳細なモデル比較レポートを特徴としています。 |
| Monitoring & Metrics | ●●● | コストとトークンの分析に優れた堅牢なモニタリングスイートであり、強力なエラー追跡とカスタムメトリクス機能を備えていますが、一部の特定のアラートは明示的ではありません。 |
| Experiment / Improvement Loop | ●●● | すべてのアーティファクト（プロンプト、モデル、データ）に対する強力なバージョン管理と、Fine-tuningへの明確なパスを備え、改善ループを強力にサポートします。 |
| DevEx / Integration | ●●● | 幅広いフレームワークのサポート、公式SDK、Streaming機能により、優れた開発者体験を提供し、様々なワークフローに高度に適応可能です。 |
| Security & Governance | ●●● | 柔軟なデプロイメントオプション（VPC/オンプレミス）、強力なPII保護、包括的な監査ログを備えたエンタープライズグレードのセキュリティを提供します。 |


---

### LangSmith

**概要**: LangSmithは、LangChainエコシステムと深く統合された包括的なObservabilityおよびEvalプラットフォームであり、プロトタイピングから本番環境までLLMアプリケーションのライフサイクル全体をサポートするように設計されています。階層的なTracing、自動化されたEvalワークフロー、データセット管理に優れており、複雑なエージェントやRAGベースのアプリケーションを構築するチームにとって強力な選択肢となります。

**強み**:
- LangChainおよびLangGraphとの深い統合により、複雑なチェーンのシームレスなTracingが可能。
- LLM-as-a-judgeやヒューマンアノテーションキューを含む包括的なEvalスイート。
- 反復的な改善ループのための強力なデータセット管理とバージョニング。
- コンプライアンスのための堅牢なセルフホストおよびリージョン固有のデプロイメントオプション。

**弱み**:
- 組み込みのロールベースアクセス制御（RBAC）および監査ログに関するドキュメントが限定的。
- Observability UI内に明示的な視覚的ワークフローDAGがない（LangGraph統合以外）。
- ツール呼び出しの成功率を追跡するための特定のメトリクスやDashboardが標準で用意されていない。
- StreamingレスポンスのTracing機能について、提供されたドキュメントに明示的な詳細がない。

**最新のアップデート**:
- Client SDK v0.7.1: PythonおよびJSクライアントライブラリのアップデート。OIDCの修正と依存関係の更新を含む。(2026-02-10)
- Traceプレビューのカスタマイズ: UIでのTraceプレビューのレンダリング方法をカスタマイズできる新機能。(2026-02-06)
- LangSmith Self-Hosted v0.13: セルフホストデプロイメントオプションの新しいバージョンリリース。(2026-01-16)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Observability | ●●● | LangSmithは、深いネスト機能とプロンプト、レスポンス、トークンメトリクスの自動ロギングを備えた堅牢なコアObservabilityスイートを提供します。レイテンシ分析用のウォーターフォールグラフなどの高度な可視化ツールにより、複雑なLLMチェーンのデバッグのための包括的なソリューションとなっています。 |
| Agent / RAG Observability | ●●○ | ツール呼び出し、モデルのインタラクション、ドキュメント検索の詳細なTraceをキャプチャすることで、RAGおよびエージェントワークフローに堅牢なObservabilityを提供します。特にLangGraphオーケストレーターと統合した場合、複雑な推論チェーンの逐次的なステップのロギングに優れています。 |
| Evaluation Integration | ●●● | Traceからデータセットへのワークフローと堅牢なヒューマンインザループ機能を通じて、本番環境のObservabilityとテストをシームレスに結びつける包括的なEvalスイートを提供します。LLMベースのScoringと詳細な回帰追跡、モデルのサイドバイサイド比較を組み合わせることで、自動化された品質保証に優れています。 |
| Monitoring & Metrics | ●●● | コスト、トークン使用量、レイテンシ、エラー追跡に焦点を当てた、アラート機能統合型の堅牢なモニタリングスイートを提供します。コアとなる運用メトリクスには優れていますが、特定のツールの成功率や高度なカスタムメトリクスの可視化のサポートは、まだ発展途上のようです。 |
| Experiment / Improvement Loop | ●●● | Evalワークフローに直接統合される強力なデータセットおよびプロンプトのバージョニング機能を特徴とする、改善ループのための堅牢なスイートを提供します。実験結果の比較や、本番環境のTraceとFine-tuningパイプラインの橋渡しに優れています。 |
| DevEx / Integration | ●●○ | 公式のPythonおよびJS/TS SDK、LangChainやLlamaIndexなどの主要なLLMフレームワークとの深い統合を通じて、堅牢な開発者体験を提供します。REST APIを介した柔軟なプログラムアクセスを提供し、カスタムモデルのTracingをサポートしていますが、CLIツールやStreaming特化のTracingに関するドキュメントは見当たりませんでした。 |
| Security & Governance | ●●○ | セルフホストVPCオプションと、EU専用ホスティングを含む強力なデータレジデンシサポートを通じて、堅牢なデプロイメントの柔軟性を提供します。設定可能なデータ保持とSDKレベルのPIIマスキングを提供していますが、提供されたドキュメントには内部RBACや監査ログ機能に関する詳細が不足しています。 |


---

### Langfuse

**概要**: Langfuseは、高精度なTracingと堅牢なEval、コスト管理ツールを組み合わせたオープンソースのLLMエンジニアリングプラットフォームです。複雑なエージェントアプリケーションを構築する開発者をターゲットにしており、LangChainなどのフレームワークとの深い統合や、セキュリティを重視する企業向けの強力なセルフホスト機能を提供しています。

**強み**:
- 高セキュリティ環境に適した強力なオープンソースのセルフホスト機能。
- エージェントワークフローに特化した可視化を備えた深い階層的Tracing。
- Tracingワークフローに直接統合された包括的なEvalスイート。
- きめ細かな追跡が可能な堅牢なコストおよびトークン分析。

**弱み**:
- 明示的なメモリTracing機能の欠如。
- CLIまたはInfrastructure-as-Codeツールの不在。
- 明示的なプロアクティブアラート機能のない、リアクティブなエラー追跡（Dashboard）。

**最新のアップデート**:
- Single Observation Evals: 単一のObservationに対してEvalを実行する機能の追加。(2026-02-12)
- Events-based Trace Table: イベント/Observationに基づいたTraceの新しいUIビュー。(2026-02-12)
- Reasoning Trace Rendering: 推論モデルなどのTrace詳細において、思考/推論プロセスをレンダリングする機能のサポート。(2026-02-12)
- Org Audit Log Viewer: 組織レベルの監査ログ用の新しいビューアー。(2026-02-12)
- Inline Trace Comments: Trace内のIOデータの一部に対してインラインでコメントを追加できる機能。(2026-02-12)
- Corrections in Trace Preview: TraceおよびObservationのプレビューで修正を直接表示・管理できる機能の追加。(2026-02-12)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Observability | ●●● | Langfuseは、階層的なTracingとコスト管理に優れた堅牢なコアObservabilityスイートを提供します。デコレータによる深いネストのサポートと、エンドツーエンドのインタラクション分析のための包括的なセッションリプレイを特徴としています。 |
| Agent / RAG Observability | ●●● | ツール呼び出しや検索ステップ専用のデータモデルを備え、エージェントおよびRAGのための堅牢なスイートを提供します。Agent Graphs機能やオーケストレーションフレームワークとの統合により、多段階の推論のマッピングに優れています。 |
| Evaluation Integration | ●●● | 堅牢なデータセット管理とマルチメソッドScoringを通じて、本番環境のObservabilityと体系的なテストを橋渡しします。LLM-as-a-judge、ヒューマンアノテーション、モデルのサイドバイサイド比較のための統合ワークフローに優れています。 |
| Monitoring & Metrics | ●●● | モニタリングスイートは、コスト、トークン使用量、レイテンシ分析と深く統合されています。ツール呼び出しの追跡やAPI経由のカスタムメトリクスには優れていますが、エラーに対するプロアクティブなアラートメカニズムはそれほど目立っていません。 |
| Experiment / Improvement Loop | ●●● | プロンプト管理、データセットのバージョニング、実験のサイドバイサイド比較に優れています。修正された出力を通じてFine-tuningの基礎を提供し、主にプロンプトの反復の体系的な追跡に焦点を当てています。 |
| DevEx / Integration | ●●● | 包括的なSDKと深いフレームワーク統合により、堅牢な開発者体験を提供します。オープンなAPIとOpenTelemetryのサポートにより高い拡張性を確保していますが、インフラ特化のツールは現在欠けています。 |
| Security & Governance | ●●● | 柔軟なセルフホストオプションと包括的な管理コントロールを備えた堅牢なセキュリティスイートを提供します。PIIマスキング、設定可能な保持期間、詳細な監査ログなど、不可欠なエンタープライズ機能が含まれています。 |


---

### Braintrust

**概要**: Braintrustは、LLM ObservabilityとEvalを密接に統合したエンタープライズグレードのプラットフォームであり、本番環境のTraceとテストデータセットの間のフィードバックループを閉じることに重点を置いています。堅牢なSDKを通じて複雑でネストされたエージェントワークフローの処理に優れており、セルフホストデータプレーンなどの強力なセキュリティ機能を提供していますが、現在は視覚的なワークフローグラフビルダーやネイティブのFine-tuningパイプラインが不足しています。

**強み**:
- 本番環境のTraceをEvalデータセットへシームレスに統合（Trace-to-Dataset）。
- セルフホストデータプレーンオプションを備えた強力なエンタープライズセキュリティモデル。
- 複雑でネストされたエージェントワークフローやカスタムモデルに対する堅牢なSDKサポート。
- LLM-as-a-judgeやヒューマンレビューUIを含む包括的なEvalスイート。

**弱み**:
- 競合他社と比較して、視覚的なワークフロー/エージェントグラフビルダーが不足。
- RLHFやFine-tuningパイプラインのネイティブサポートがない。
- UI上でTraceの実行をステップごとに確認する視覚的な「リプレイ」機能がない。

**最新のアップデート**:
- OpenAI Agents統合: OpenAIエージェント統合のために、すべてのスパンタイプを処理するようにSDKを更新。(2026-02-05)
- サブエージェントのネスト: Claude Agent SDKラッパー専用のサブエージェントネストのサポートを追加。(2026-02-05)
- Reviewスパンタイプ: Trace内で直接ヒューマンレビューワークフローをサポートするための、新しい「review」スパンタイプを導入。(2026-02-05)
- Classificationsフィールド: SDKにclassificationsフィールドを追加し、構造化データのキャプチャを強化。(2026-01-31)
- Evalキャッシュ制御: Eval中およびスパンエクスポート後のキャッシュをオフにするオプションを追加。(2026-01-29)
- Python Trace Scoring: Python SDK内でのTrace Scoringの候補サポートを導入。(2026-01-21)
- Workflowへの名称変更: 一般的な実行グラフをより適切に反映させるため、SDK内の「agents」を「workflows」に名称変更。(2026-01-15)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Observability | ●●● | Braintrustは、階層的なTracingと、トークン使用量やレイテンシなどの詳細なパフォーマンスメトリクスに優れた堅牢なコアObservabilityスイートを提供します。そのSDKは、エージェントAIシステムで一般的な、複雑でネストされた実行フローを処理するために特別に構築されています。 |
| Agent / RAG Observability | ●●○ | ツール呼び出しやドキュメント検索ステップのTracingを強力にサポートし、RAGおよびエージェントワークフローに堅牢なObservabilityを提供します。詳細な多段階実行データのキャプチャには優れていますが、特化型のワークフローグラフの可視化や専用のメモリ追跡に関する明示的な言及はありません。 |
| Evaluation Integration | ●●● | 本番環境のモニタリングとオフラインテストを密接に統合する包括的なEvalスイートを提供します。本番環境のTraceをテストデータセットに変換し、自動化されたLLMベースのScoringと手動のヒューマンアノテーションの両方に堅牢なツールを提供することで、フィードバックループを閉じることに優れています。 |
| Monitoring & Metrics | ●●● | リアルタイムのコスト、トークン、レイテンシの追跡をカスタマイズ可能なDashboardに統合した包括的なモニタリングスイートを提供します。このプラットフォームは特にアラート機能に強みがあり、チームはレイテンシのパーセンタイルやエラー率全体でSLO違反を監視できます。 |
| Experiment / Improvement Loop | ●●● | プロンプト管理、データセット中心のEval、サイドバイサイドのA/Bテストに特に優れた、LLM改善ループのための堅牢な環境を提供します。そのアーキテクチャは、バージョン管理されたプロンプト、データセット、Scorerを密接に統合し、継続的なモニタリングと回帰テストを容易にします。 |
| DevEx / Integration | ●●● | PythonおよびJS/TS用の包括的なSDKと、LangChainやLlamaIndexなどの主要なAIフレームワークとの深い統合により、堅牢な開発者体験を提供します。カスタムモデルプロバイダーのサポートや、リアルタイムLLMレスポンスのためのネイティブなStreaming Tracingにより、柔軟性に優れています。 |
| Security & Governance | ●●● | セルフホストデータプレーンを中心とした堅牢なセキュリティフレームワークを提供し、機密情報が顧客のVPC内に留まることを保証します。厳格な規制要件を満たすために、RBAC、SSO統合、PIIマスキング、監査ログなどの不可欠なエンタープライズ機能が含まれています。 |


---

### MLflow

**概要**: MLflowは、成熟したオープンソースのMLOpsプラットフォームであり、堅牢なTracing、Eval、実験追跡機能を備え、LLM Observabilityへの拡張に成功しています。プロンプトエンジニアリングからモデルのバージョニングまで、フルライフサイクルの管理に優れていますが、高度なエンタープライズガバナンスについては統合機能に依存しており、ワークフローグラフのような一部の特化型エージェント可視化機能が不足しています。

**強み**:
- プロンプト、モデル、データセットをカバーする包括的なライフサイクル管理。
- カスタムメトリクスをサポートする強力な「LLM-as-a-Judge」およびEvalフレームワーク。
- LangChainやLlamaIndexなどの主要なLLMフレームワークとの深い統合。
- 強力なセルフホスト機能とPIIマスキング機能を備えたオープンソースの柔軟性。

**弱み**:
- 複雑なエージェント実行のための視覚的なワークフローグラフの欠如。
- ネイティブのコストDashboardがない（カスタム実装が必要）。
- マネージドサービスを利用しない場合、ネイティブのガバナンス（RBAC/監査）が限定的。
- Traceのステップバイステップのリプレイ機能がない。

**最新のアップデート**:
- 組織サポート: MLflow Tracking Serverにおけるマルチワークスペース環境のサポート。異なるワークスペース間での実験やリソースの整理が可能に。(2026-02-12)
- MLflow Assistant: Claude Codeをバックエンドとした製品内チャットボット。MLflow UI内で直接問題を特定、診断、修正するのを支援。(2026-01-29)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Observability | ●●● | MLflowは、深い階層的Tracingと、レイテンシやトークン使用量などの運用メトリクスの自動キャプチャを特徴とする、LLM向けの堅牢なコアObservabilityフレームワークを提供します。複雑なネストされた関数呼び出しのマッピングやプロンプトバージョンの管理に優れていますが、特定のステップバイステップのTraceリプレイ機能については詳細がありません。 |
| Agent / RAG Observability | ●●○ | OpenAI、Anthropic、LangChain、LlamaIndexとの深い統合を通じて、エージェントおよびRAGワークフローに堅牢なTracingを提供します。ツール呼び出しや検索スパンのキャプチャに優れていますが、メモリ固有の追跡やグラフベースのワークフロー可視化に関する具体的な言及はありません。 |
| Evaluation Integration | ●●● | 本番環境のTraceをデータセットに変換し、包括的なLLM-as-a-Judge機能を提供することに優れた、堅牢なEvalスイートを提供します。ヒューマンインザループのワークフローやモデル比較を強力にサポートしていますが、特定の自動回帰アラートについてはドキュメントに詳細がありません。 |
| Monitoring & Metrics | ●●● | レイテンシ、トークン使用量、ツールの成功率を追跡するTracingおよびAgents Dashboard機能を通じて、LLMアプリケーションに堅牢なモニタリングを提供します。カスタムメトリクスの定義やパフォーマンス分析には優れていますが、現在はネイティブのリアルタイムコスト追跡Dashboardがありません。 |
| Experiment / Improvement Loop | ●●● | 専用のPrompt Registryと包括的な実験追跡機能を備えた、改善ループのための堅牢なエコシステムを提供します。データセット、モデル、プロンプトのバージョニングに優れており、GenAIアプリケーションを体系的に改善するためのFine-tuningワークフローの統合サポートを提供します。 |
| DevEx / Integration | ●●○ | PythonおよびTypeScript用の堅牢なSDKサポートと、LlamaIndexなどの人気LLMフレームワークとの深い統合を通じて、強力な開発者体験を示しています。プログラムアクセス用の包括的なREST APIとカスタムモデル追跡を提供していますが、Streaming TracingやインフラレベルのCLIツールに関する詳細は見当たりませんでした。 |
| Security & Governance | ●●○ | 強力なセルフホスト機能と、GenAI Traceに対する堅牢なPIIマスキングを提供します。RBACやコンプライアンスなどのコアガバナンス機能はDatabricksのようなマネージドサービスプロバイダーに大きく依存していますが、プラットフォームは安全なエンタープライズデプロイメントに必要なフックを提供しています。 |


---

### Arize Phoenix

**概要**: Arize Phoenixは、LLMアプリケーション向けに設計されたオープンソースファーストのObservabilityおよびEvalプラットフォームであり、OpenTelemetry互換のTracingと深いフレームワーク統合を強調しています。堅牢な本番環境モニタリングと、LLM-as-a-judge機能を備えた強力なEvalスイートを組み合わせており、コード中心のデバッグと継続的な改善に焦点を当てたエンジニアリングチームに特に適しています。

**強み**:
- 深いOpenTelemetry統合により、複雑なエージェントワークフローのベンダーに依存しない階層的Tracingが可能。
- 豊富なプリセット評価器（Faithfulness、Tool Selectionなど）を備えた堅牢なLLM-as-a-Judgeフレームワーク。
- データ感度の高い環境に最適な、完全な機能パリティを備えた強力なセルフホスト機能。
- Observabilityループに直接統合された包括的なプロンプト管理と実験追跡。

**弱み**:
- ネイティブの自動PIIマスキングが不足しており、カスタムスパンプロセッサの手動設定が必要。
- プロンプトバージョニングとは区別された、モデルバージョニングや構成追跡に対する明示的なサポートがない。
- プラットフォームをプログラムで管理するための詳細なAPIアクセスやCLIツールがない。
- 会話型メモリの読み取り/書き込みをTracingするための特定の機能が欠けている。

**最新のアップデート**:
- Claude Opus 4.6サポート: PlaygroundにClaude Opus 4.6モデルを追加。(2026-02-09)
- Tool Selection評価器: ライブラリに不足していたtool_selection評価器を追加。(2026-02-06)
- Faithfulness評価器: FaithfulnessEvaluatorを追加し、HallucinationEvaluatorを非推奨化。(2026-02-02)
- Tool Invocation Accuracyメトリクス: ツール呼び出しの精度を追跡するための特定のメトリクスを追加。(2026-01-27)
- LLM Classification評価器: LLM分類用の新しい組み込みメトリクスを作成するためのカーソルルールを追加。(2026-01-21)

| カテゴリ | 評価 | サマリー |
|---|---|---|
| Core Observability | ●●● | Arize Phoenixは、階層的なスパン、入力、出力、タイミングデータをキャプチャするOpenTelemetry互換のTracingを中心とした堅牢なコアObservabilityフレームワークを提供します。トークン追跡とレイテンシ分析によるパフォーマンスモニタリングに優れており、開発者は複雑でネストされたLLMアプリケーションのフローを可視化できます。 |
| Agent / RAG Observability | ●●● | ツール呼び出しのTracing、ドキュメント検索の検査、マルチエージェントの軌跡の可視化を強力にサポートし、RAGおよびエージェントワークフローに堅牢なObservabilityを提供します。LangGraphやAutoGenなどの主要なフレームワークと統合し、複雑な多段階の推論チェーンに対する明確なインサイトを提供します。 |
| Evaluation Integration | ●●● | LLM-as-a-judge機能と統合されたヒューマンアノテーションワークフローを中心とした、堅牢なEvalスイートを提供します。本番環境のTraceを評価可能なデータポイントに変換することに優れており、品質追跡のための幅広いカスタムおよびプリセットメトリクスをサポートしています。 |
| Monitoring & Metrics | ●●● | レイテンシの分位数、エラー率、自動コスト追跡を含む、コアとなるLLMパフォーマンス指標をカバーする堅牢なモニタリングスイートを提供します。最近のアップデートにより、特定の呼び出し精度メトリクスによるツールモニタリングが強化されました。 |
| Experiment / Improvement Loop | ●●○ | 統合されたプロンプト管理と実験追跡機能を通じて、改善ループのための堅牢な環境を提供します。継続的なEvalやFine-tuningのためのデータキュレーションに優れていますが、主な焦点は依然としてObservability主導の改善にあります。 |
| DevEx / Integration | ●●○ | 包括的なSDKサポートと人気のあるLLMフレームワークとの深い統合を通じて、堅牢な開発者体験を提供します。OpenTelemetryを介したベンダーに依存しないTracingに優れていますが、プログラムによるAPIアクセスやStreaming特化のTracingの証拠は限られています。 |
| Security & Governance | ●●● | セルフホスト環境に対して堅牢なセキュリティプロファイルを提供し、完全なデータ制御、RBAC、設定可能なデータ保持を提供します。PIIマスキングはサポートされていますが、カスタムプロセッサを介した手動設定が必要です。 |


---